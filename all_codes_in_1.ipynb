{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "all_codes_in_1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMtMRllOBRXi0Vr8zz5BLpj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/purvi02/Text-to-Image/blob/main/all_codes_in_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fUdKWG7-PwQ",
        "outputId": "f5921383-63db-4f0a-9420-553b9a54b837"
      },
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\r\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\r\n",
        "!apt-get update -qq 2>&1 > /dev/null\r\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\r\n",
        "from google.colab import auth\r\n",
        "auth.authenticate_user()\r\n",
        "from oauth2client.client import GoogleCredentials\r\n",
        "creds = GoogleCredentials.get_application_default()\r\n",
        "import getpass\r\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\r\n",
        "vcode = getpass.getpass()\r\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "(Reading database ... 144865 files and directories currently installed.)\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.7.23-0ubuntu1~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.23-0ubuntu1~ubuntu18.04.1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.23-0ubuntu1~ubuntu18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2KPb2ftCFK-",
        "outputId": "931cb8af-53c2-4e4e-8f8c-1cc37c0a248d"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BWkuHHbDPiM",
        "outputId": "c987c97a-e720-4894-bcc5-a4ca144f183a"
      },
      "source": [
        "! ls\r\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gdrive\tsample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4XSIz9DDYI9",
        "outputId": "39d11498-ef64-4b8b-ee09-7c643070bcef"
      },
      "source": [
        "%cd gdrive/My Drive/project_root/Text-to-Image"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/project_root/Text-to-Image\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QU3qfIEE3jY",
        "outputId": "ab814620-356c-49bc-859f-dd16732f9838"
      },
      "source": [
        "! pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/project_root\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xT7Q56o9SRfI",
        "outputId": "ba4f5880-6045-4863-cdf7-a0e2340d2856"
      },
      "source": [
        "% cd .."
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/project_root\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ovK0qKpEPN1",
        "outputId": "56e3b2d3-120d-427d-e43e-08c449c7975a"
      },
      "source": [
        "! git clone https://github.com/purvi02/Text-to-Image.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Text-to-Image'...\n",
            "remote: Enumerating objects: 27, done.\u001b[K\n",
            "remote: Counting objects: 100% (27/27), done.\u001b[K\n",
            "remote: Compressing objects: 100% (21/21), done.\u001b[K\n",
            "remote: Total 27 (delta 7), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (27/27), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaEfjwBFVgcn",
        "outputId": "f456a5c1-145b-483f-b81b-1923a94a41f6"
      },
      "source": [
        "! ls"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " attributes.txt   logs\t\t     results2\t\t   stage1_gen.h5\n",
            " birds\t\t 'logs_epoch 1000'  'results_epoch 1000'   Text-to-Image\n",
            " CUB_200_2011\t  results\t     stage1_dis.h5\t   Untitled0.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_kgfUAl0mhH"
      },
      "source": [
        "Implementation of Stage I of StackGAN "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ih6hRf_h0-ke"
      },
      "source": [
        "import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "if8A3y0APjjN"
      },
      "source": [
        "import os\r\n",
        "import pickle\r\n",
        "import random\r\n",
        "import time\r\n",
        "\r\n",
        "import PIL\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-s1boU6imhY"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-S7CqiEigQ2",
        "outputId": "c534c92b-f4f5-408f-b7e5-55e1d201a785"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from PIL import Image\r\n",
        "from keras import Input, Model\r\n",
        "from keras import backend as K\r\n",
        "from keras.callbacks import TensorBoard\r\n",
        "from keras.layers import Dense, LeakyReLU, BatchNormalization, ReLU, Reshape, UpSampling2D, Conv2D, Activation, \\\r\n",
        "    concatenate, Flatten, Lambda, Concatenate\r\n",
        "from keras.optimizers import Adam\r\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJqfGhPRz3RH",
        "outputId": "c68b06d0-f6cc-4a70-cc47-f2a8e868815a"
      },
      "source": [
        "print(tf.version)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<module 'tensorflow._api.v1.version' from '/tensorflow-1.15.2/python3.6/tensorflow_core/_api/v1/version/__init__.py'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "2sNP8_sfjymI",
        "outputId": "69235494-f223-4e56-af99-f894b8d88933"
      },
      "source": [
        "tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkYsWqd_1IbH"
      },
      "source": [
        "functions to load dataset-"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LH-1WtRQZws"
      },
      "source": [
        "def load_class_ids(class_info_file_path):\r\n",
        "    \"\"\"\r\n",
        "    Load class ids from class_info.pickle file\r\n",
        "    \"\"\"\r\n",
        "    with open(class_info_file_path, 'rb') as f:\r\n",
        "        class_ids = pickle.load(f, encoding='latin1')\r\n",
        "        return class_ids\r\n",
        "      \r\n",
        "def load_embeddings(embeddings_file_path):\r\n",
        "    \"\"\"\r\n",
        "    Load embeddings\r\n",
        "    \"\"\"\r\n",
        "    with open(embeddings_file_path, 'rb') as f:\r\n",
        "        embeddings = pickle.load(f, encoding='latin1')\r\n",
        "        embeddings = np.array(embeddings)\r\n",
        "        print('embeddings: ', embeddings.shape)\r\n",
        "    return embeddings\r\n",
        " \r\n",
        "def load_filenames(filenames_file_path):\r\n",
        "    \"\"\"\r\n",
        "    Load filenames.pickle file and return a list of all file names\r\n",
        "    \"\"\"\r\n",
        "    with open(filenames_file_path, 'rb') as f:\r\n",
        "        filenames = pickle.load(f, encoding='latin1')\r\n",
        "    return filenames\r\n",
        " \r\n",
        "def load_bounding_boxes(dataset_dir):\r\n",
        "    \"\"\"\r\n",
        "    Load bounding boxes and return a dictionary of file names and corresponding bounding boxes\r\n",
        "    \"\"\"\r\n",
        "    # Paths\r\n",
        "    bounding_boxes_path = os.path.join(dataset_dir, 'bounding_boxes.txt')\r\n",
        "    file_paths_path = os.path.join(dataset_dir, 'images.txt')\r\n",
        "\r\n",
        "    # Read bounding_boxes.txt and images.txt file\r\n",
        "    df_bounding_boxes = pd.read_csv(bounding_boxes_path,\r\n",
        "                                    delim_whitespace=True, header=None).astype(int)\r\n",
        "    df_file_names = pd.read_csv(file_paths_path, delim_whitespace=True, header=None)\r\n",
        "\r\n",
        "    # Create a list of file names\r\n",
        "    file_names = df_file_names[1].tolist()\r\n",
        "\r\n",
        "    # Create a dictionary of file_names and bounding boxes\r\n",
        "    filename_boundingbox_dict = {img_file[:-4]: [] for img_file in file_names[:2]}\r\n",
        "\r\n",
        "    # Assign a bounding box to the corresponding image\r\n",
        "    for i in range(0, len(file_names)):\r\n",
        "        # Get the bounding box\r\n",
        "        bounding_box = df_bounding_boxes.iloc[i][1:].tolist()\r\n",
        "        key = file_names[i][:-4]\r\n",
        "        filename_boundingbox_dict[key] = bounding_box\r\n",
        "\r\n",
        "    return filename_boundingbox_dict\r\n",
        "\r\n",
        "def get_img(img_path, bbox, image_size):\r\n",
        "    \"\"\"\r\n",
        "    Load and resize image\r\n",
        "    \"\"\"\r\n",
        "    img = Image.open(img_path).convert('RGB')\r\n",
        "    width, height = img.size\r\n",
        "    if bbox is not None:\r\n",
        "        R = int(np.maximum(bbox[2], bbox[3]) * 0.75)\r\n",
        "        center_x = int((2 * bbox[0] + bbox[2]) / 2)\r\n",
        "        center_y = int((2 * bbox[1] + bbox[3]) / 2)\r\n",
        "        y1 = np.maximum(0, center_y - R)\r\n",
        "        y2 = np.minimum(height, center_y + R)\r\n",
        "        x1 = np.maximum(0, center_x - R)\r\n",
        "        x2 = np.minimum(width, center_x + R)\r\n",
        "        img = img.crop([x1, y1, x2, y2])\r\n",
        "    img = img.resize(image_size, PIL.Image.BILINEAR)\r\n",
        "    return img\r\n",
        " \r\n",
        "def load_dataset(filenames_file_path, class_info_file_path, cub_dataset_dir, embeddings_file_path, image_size):\r\n",
        "    \"\"\"\r\n",
        "    Load dataset\r\n",
        "    \"\"\"\r\n",
        "    filenames = load_filenames(filenames_file_path)\r\n",
        "    class_ids = load_class_ids(class_info_file_path)\r\n",
        "    bounding_boxes = load_bounding_boxes(cub_dataset_dir)\r\n",
        "    all_embeddings = load_embeddings(embeddings_file_path)\r\n",
        "\r\n",
        "    X, y, embeddings = [], [], []\r\n",
        "\r\n",
        "    print(\"Embeddings shape:\", all_embeddings.shape)\r\n",
        "\r\n",
        "    for index, filename in enumerate(filenames):\r\n",
        "        bounding_box = bounding_boxes[filename]\r\n",
        "\r\n",
        "        try:\r\n",
        "            # Load images\r\n",
        "            img_name = '{}/images/{}.jpg'.format(cub_dataset_dir, filename)\r\n",
        "            img = get_img(img_name, bounding_box, image_size)\r\n",
        "\r\n",
        "            all_embeddings1 = all_embeddings[index, :, :]\r\n",
        "\r\n",
        "            embedding_ix = random.randint(0, all_embeddings1.shape[0] - 1)\r\n",
        "            embedding = all_embeddings1[embedding_ix, :]\r\n",
        "\r\n",
        "            X.append(np.array(img))\r\n",
        "            y.append(class_ids[index])\r\n",
        "            embeddings.append(embedding)\r\n",
        "        except Exception as e:\r\n",
        "            print(e)\r\n",
        "\r\n",
        "    X = np.array(X)\r\n",
        "    y = np.array(y)\r\n",
        "    embeddings = np.array(embeddings)\r\n",
        "    return X, y, embeddings"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtESIvhB1XCd"
      },
      "source": [
        "Building Stage I architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtaEEBTcQpHE"
      },
      "source": [
        "def generate_c(x):\r\n",
        "    mean = x[:, :128]\r\n",
        "    log_sigma = x[:, 128:]\r\n",
        "    stddev = K.exp(log_sigma)\r\n",
        "    epsilon = K.random_normal(shape=K.constant((mean.shape[1],), dtype='int32'))\r\n",
        "    c = stddev * epsilon + mean\r\n",
        "    return c\r\n",
        "  \r\n",
        "def build_ca_model():\r\n",
        "    \"\"\"\r\n",
        "    Get conditioning augmentation model.\r\n",
        "    Takes an embedding of shape (1024,) and returns a tensor of shape (256,)\r\n",
        "    \"\"\"\r\n",
        "    input_layer = Input(shape=(1024,))\r\n",
        "    x = Dense(256)(input_layer)\r\n",
        "    x = LeakyReLU(alpha=0.2)(x)\r\n",
        "    model = Model(inputs=[input_layer], outputs=[x])\r\n",
        "    return model\r\n",
        "  \r\n",
        "def build_embedding_compressor_model():\r\n",
        "    \"\"\"\r\n",
        "    Build embedding compressor model\r\n",
        "    \"\"\"\r\n",
        "    input_layer = Input(shape=(1024,))\r\n",
        "    x = Dense(128)(input_layer)\r\n",
        "    x = ReLU()(x)\r\n",
        "\r\n",
        "    model = Model(inputs=[input_layer], outputs=[x])\r\n",
        "    return model\r\n",
        "  \r\n",
        "def build_stage1_generator():\r\n",
        "    \"\"\"\r\n",
        "    Builds a generator model used in Stage-I\r\n",
        "    \"\"\"\r\n",
        "    input_layer = Input(shape=(1024,))\r\n",
        "    x = Dense(256)(input_layer)\r\n",
        "    mean_logsigma = LeakyReLU(alpha=0.2)(x)\r\n",
        "\r\n",
        "    c = Lambda(generate_c)(mean_logsigma)\r\n",
        "\r\n",
        "    input_layer2 = Input(shape=(100,))\r\n",
        "\r\n",
        "    gen_input = Concatenate(axis=1)([c, input_layer2])\r\n",
        "\r\n",
        "    x = Dense(128 * 8 * 4 * 4, use_bias=False)(gen_input)\r\n",
        "    x = ReLU()(x)\r\n",
        "\r\n",
        "    x = Reshape((4, 4, 128 * 8), input_shape=(128 * 8 * 4 * 4,))(x)\r\n",
        "\r\n",
        "    x = UpSampling2D(size=(2, 2))(x)\r\n",
        "    x = Conv2D(512, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    x = ReLU()(x)\r\n",
        "\r\n",
        "    x = UpSampling2D(size=(2, 2))(x)\r\n",
        "    x = Conv2D(256, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    x = ReLU()(x)\r\n",
        "\r\n",
        "    x = UpSampling2D(size=(2, 2))(x)\r\n",
        "    x = Conv2D(128, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    x = ReLU()(x)\r\n",
        "\r\n",
        "    x = UpSampling2D(size=(2, 2))(x)\r\n",
        "    x = Conv2D(64, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    x = ReLU()(x)\r\n",
        "\r\n",
        "    x = Conv2D(3, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\r\n",
        "    x = Activation(activation='tanh')(x)\r\n",
        "\r\n",
        "    stage1_gen = Model(inputs=[input_layer, input_layer2], outputs=[x, mean_logsigma])\r\n",
        "    return stage1_gen\r\n",
        "\r\n",
        "def build_stage1_discriminator():\r\n",
        "    \"\"\"\r\n",
        "    Create a model which takes two inputs\r\n",
        "    1. One from above network\r\n",
        "    2. One from the embedding layer\r\n",
        "    3. Concatenate along the axis dimension and feed it to the last module which produces final logits\r\n",
        "    \"\"\"\r\n",
        "    input_layer = Input(shape=(64, 64, 3))\r\n",
        "\r\n",
        "    x = Conv2D(64, (4, 4),\r\n",
        "               padding='same', strides=2,\r\n",
        "               input_shape=(64, 64, 3), use_bias=False)(input_layer)\r\n",
        "    x = LeakyReLU(alpha=0.2)(x)\r\n",
        "\r\n",
        "    x = Conv2D(128, (4, 4), padding='same', strides=2, use_bias=False)(x)\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    x = LeakyReLU(alpha=0.2)(x)\r\n",
        "\r\n",
        "    x = Conv2D(256, (4, 4), padding='same', strides=2, use_bias=False)(x)\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    x = LeakyReLU(alpha=0.2)(x)\r\n",
        "\r\n",
        "    x = Conv2D(512, (4, 4), padding='same', strides=2, use_bias=False)(x)\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    x = LeakyReLU(alpha=0.2)(x)\r\n",
        "\r\n",
        "    input_layer2 = Input(shape=(4, 4, 128))\r\n",
        "\r\n",
        "    merged_input = concatenate([x, input_layer2])\r\n",
        "\r\n",
        "    x2 = Conv2D(64 * 8, kernel_size=1,\r\n",
        "                padding=\"same\", strides=1)(merged_input)\r\n",
        "    x2 = BatchNormalization()(x2)\r\n",
        "    x2 = LeakyReLU(alpha=0.2)(x2)\r\n",
        "    x2 = Flatten()(x2)\r\n",
        "    x2 = Dense(1)(x2)\r\n",
        "    x2 = Activation('sigmoid')(x2)\r\n",
        "\r\n",
        "    stage1_dis = Model(inputs=[input_layer, input_layer2], outputs=[x2])\r\n",
        "    return stage1_dis\r\n",
        "  \r\n",
        "def build_adversarial_model(gen_model, dis_model):\r\n",
        "    input_layer = Input(shape=(1024,))\r\n",
        "    input_layer2 = Input(shape=(100,))\r\n",
        "    input_layer3 = Input(shape=(4, 4, 128))\r\n",
        "\r\n",
        "    x, mean_logsigma = gen_model([input_layer, input_layer2])\r\n",
        "\r\n",
        "    dis_model.trainable = False\r\n",
        "    valid = dis_model([x, input_layer3])\r\n",
        "\r\n",
        "    model = Model(inputs=[input_layer, input_layer2, input_layer3], outputs=[valid, mean_logsigma])\r\n",
        "    return model"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVxqmvcA1tWh"
      },
      "source": [
        " **Function for KL loss-**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tiMjq5qQ4Bu"
      },
      "source": [
        "def KL_loss(y_true, y_pred):\r\n",
        "    mean = y_pred[:, :128]\r\n",
        "    logsigma = y_pred[:, :128]\r\n",
        "    loss = -logsigma + .5 * (-1 + K.exp(2. * logsigma) + K.square(mean))\r\n",
        "    loss = K.mean(loss)\r\n",
        "    return loss\r\n",
        "    \r\n",
        "\r\n",
        "def custom_generator_loss(y_true, y_pred):\r\n",
        "    # Calculate binary cross entropy loss\r\n",
        "    return K.binary_crossentropy(y_true, y_pred)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22v9OFxy17Bd"
      },
      "source": [
        "**Function for saving the generated image after every 2 epochs and saving the logs.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZcEvA94Q_X3"
      },
      "source": [
        "def save_rgb_img(img, path):\r\n",
        "    \"\"\"\r\n",
        "    Save an rgb image\r\n",
        "    \"\"\"\r\n",
        "    fig = plt.figure()\r\n",
        "    ax = fig.add_subplot(1, 1, 1)\r\n",
        "    ax.imshow(img)\r\n",
        "    ax.axis(\"off\")\r\n",
        "    ax.set_title(\"Image\")\r\n",
        "\r\n",
        "    plt.savefig(path)\r\n",
        "    plt.close()\r\n",
        "    \r\n",
        "def write_log(callback, name, loss, batch_no):\r\n",
        "    \"\"\"\r\n",
        "    Write training summary to TensorBoard\r\n",
        "    \"\"\"\r\n",
        "    summary = tf.Summary()\r\n",
        "    summary_value = summary.value.add()\r\n",
        "    summary_value.simple_value = loss\r\n",
        "    summary_value.tag = name\r\n",
        "    callback.writer.add_summary(summary, batch_no)\r\n",
        "    callback.writer.flush()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQyX-v6m2Ejh"
      },
      "source": [
        "**main function to initialize the hyper-parameters and train stage I StackGAN.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8avnKdQRMhF",
        "outputId": "ad26868b-1ef9-469b-8249-cf175e42c087"
      },
      "source": [
        "if __name__ == '__main__':\r\n",
        "    data_dir = \"/content/gdrive/My Drive/project_root/birds\"\r\n",
        "    train_dir = data_dir + \"/train\"\r\n",
        "    test_dir = data_dir + \"/test\"\r\n",
        "    image_size = 64\r\n",
        "    batch_size = 64\r\n",
        "    z_dim = 100\r\n",
        "    stage1_generator_lr = 0.0002\r\n",
        "    stage1_discriminator_lr = 0.0002\r\n",
        "    stage1_lr_decay_step = 600\r\n",
        "    epochs = 10\r\n",
        "    \r\n",
        "    condition_dim = 128\r\n",
        "\r\n",
        "    embeddings_file_path_train = train_dir + \"/char-CNN-RNN-embeddings.pickle\"\r\n",
        "    embeddings_file_path_test = test_dir + \"/char-CNN-RNN-embeddings.pickle\"\r\n",
        "\r\n",
        "    filenames_file_path_train = train_dir + \"/filenames.pickle\"\r\n",
        "    filenames_file_path_test = test_dir + \"/filenames.pickle\"\r\n",
        "\r\n",
        "    class_info_file_path_train = train_dir + \"/class_info.pickle\"\r\n",
        "    class_info_file_path_test = test_dir + \"/class_info.pickle\"\r\n",
        "\r\n",
        "    cub_dataset_dir = \"/content/gdrive/My Drive/project_root/CUB_200_2011\"\r\n",
        "    \r\n",
        "    # Define optimizers\r\n",
        "    dis_optimizer = Adam(lr=stage1_discriminator_lr, beta_1=0.5, beta_2=0.999)\r\n",
        "    gen_optimizer = Adam(lr=stage1_generator_lr, beta_1=0.5, beta_2=0.999)\r\n",
        "\r\n",
        "    \"\"\"\"\r\n",
        "    Load datasets\r\n",
        "    \"\"\"\r\n",
        "    X_train, y_train, embeddings_train = load_dataset(filenames_file_path=filenames_file_path_train,\r\n",
        "                                                      class_info_file_path=class_info_file_path_train,\r\n",
        "                                                      cub_dataset_dir=cub_dataset_dir,\r\n",
        "                                                      embeddings_file_path=embeddings_file_path_train,\r\n",
        "                                                      image_size=(64, 64))\r\n",
        "\r\n",
        "    X_test, y_test, embeddings_test = load_dataset(filenames_file_path=filenames_file_path_test,\r\n",
        "                                                   class_info_file_path=class_info_file_path_test,\r\n",
        "                                                   cub_dataset_dir=cub_dataset_dir,\r\n",
        "                                                   embeddings_file_path=embeddings_file_path_test,\r\n",
        "                                                   image_size=(64, 64))\r\n",
        "\r\n",
        "    \"\"\"\r\n",
        "    Build and compile networks\r\n",
        "    \"\"\"\r\n",
        "    ca_model = build_ca_model()\r\n",
        "    ca_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\r\n",
        "\r\n",
        "    stage1_dis = build_stage1_discriminator()\r\n",
        "    stage1_dis.compile(loss='binary_crossentropy', optimizer=dis_optimizer)\r\n",
        "\r\n",
        "    stage1_gen = build_stage1_generator()\r\n",
        "    stage1_gen.compile(loss=\"mse\", optimizer=gen_optimizer)\r\n",
        "\r\n",
        "    embedding_compressor_model = build_embedding_compressor_model()\r\n",
        "    embedding_compressor_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\r\n",
        "\r\n",
        "    adversarial_model = build_adversarial_model(gen_model=stage1_gen, dis_model=stage1_dis)\r\n",
        "    adversarial_model.compile(loss=['binary_crossentropy', KL_loss], loss_weights=[1, 2.0],\r\n",
        "                              optimizer=gen_optimizer, metrics=None)\r\n",
        "\r\n",
        "    tensorboard = TensorBoard(log_dir=\"logs/\".format(time.time()))\r\n",
        "    tensorboard.set_model(stage1_gen)\r\n",
        "    tensorboard.set_model(stage1_dis)\r\n",
        "    tensorboard.set_model(ca_model)\r\n",
        "    tensorboard.set_model(embedding_compressor_model)\r\n",
        "\r\n",
        "    # Generate an array containing real and fake values\r\n",
        "    # Apply label smoothing as well\r\n",
        "    real_labels = np.ones((batch_size, 1), dtype=float) * 0.9\r\n",
        "    fake_labels = np.zeros((batch_size, 1), dtype=float) * 0.1\r\n",
        "\r\n",
        "    for epoch in range(epochs):\r\n",
        "        print(\"========================================\")\r\n",
        "        print(\"Epoch is:\", epoch)\r\n",
        "        print(\"Number of batches\", int(X_train.shape[0] / batch_size))\r\n",
        "\r\n",
        "        gen_losses = []\r\n",
        "        dis_losses = []\r\n",
        "\r\n",
        "        # Load data and train model\r\n",
        "        number_of_batches = int(X_train.shape[0] / batch_size)\r\n",
        "        for index in range(number_of_batches):\r\n",
        "            print(\"Batch:{}\".format(index+1))\r\n",
        "            \r\n",
        "            \"\"\"\r\n",
        "            Train the discriminator network\r\n",
        "            \"\"\"\r\n",
        "            # Sample a batch of data\r\n",
        "            z_noise = np.random.normal(0, 1, size=(batch_size, z_dim))\r\n",
        "            image_batch = X_train[index * batch_size:(index + 1) * batch_size]\r\n",
        "            embedding_batch = embeddings_train[index * batch_size:(index + 1) * batch_size]\r\n",
        "            image_batch = (image_batch - 127.5) / 127.5\r\n",
        "\r\n",
        "            # Generate fake images\r\n",
        "            fake_images, _ = stage1_gen.predict([embedding_batch, z_noise], verbose=3)\r\n",
        "\r\n",
        "            # Generate compressed embeddings\r\n",
        "            compressed_embedding = embedding_compressor_model.predict_on_batch(embedding_batch)\r\n",
        "            compressed_embedding = np.reshape(compressed_embedding, (-1, 1, 1, condition_dim))\r\n",
        "            compressed_embedding = np.tile(compressed_embedding, (1, 4, 4, 1))\r\n",
        "\r\n",
        "            dis_loss_real = stage1_dis.train_on_batch([image_batch, compressed_embedding],\r\n",
        "                                                      np.reshape(real_labels, (batch_size, 1)))\r\n",
        "            dis_loss_fake = stage1_dis.train_on_batch([fake_images, compressed_embedding],\r\n",
        "                                                      np.reshape(fake_labels, (batch_size, 1)))\r\n",
        "            dis_loss_wrong = stage1_dis.train_on_batch([image_batch[:(batch_size - 1)], compressed_embedding[1:]],\r\n",
        "                                                       np.reshape(fake_labels[1:], (batch_size-1, 1)))\r\n",
        "\r\n",
        "            d_loss = 0.5 * np.add(dis_loss_real, 0.5 * np.add(dis_loss_wrong, dis_loss_fake))\r\n",
        "\r\n",
        "            print(\"d_loss_real:{}\".format(dis_loss_real))\r\n",
        "            print(\"d_loss_fake:{}\".format(dis_loss_fake))\r\n",
        "            print(\"d_loss_wrong:{}\".format(dis_loss_wrong))\r\n",
        "            print(\"d_loss:{}\".format(d_loss))\r\n",
        "\r\n",
        "            \"\"\"\r\n",
        "            Train the generator network \r\n",
        "            \"\"\"\r\n",
        "            g_loss = adversarial_model.train_on_batch([embedding_batch, z_noise, compressed_embedding],[K.ones((batch_size, 1)) * 0.9, K.ones((batch_size, 256)) * 0.9])\r\n",
        "            print(\"g_loss:{}\".format(g_loss))\r\n",
        "\r\n",
        "            dis_losses.append(d_loss)\r\n",
        "            gen_losses.append(g_loss)\r\n",
        "\r\n",
        "        \"\"\"\r\n",
        "        Save losses to Tensorboard after each epoch\r\n",
        "        \"\"\"\r\n",
        "        write_log(tensorboard, 'discriminator_loss', np.mean(dis_losses), epoch)\r\n",
        "        write_log(tensorboard, 'generator_loss', np.mean(gen_losses[0]), epoch)\r\n",
        "        \r\n",
        "        # Generate and save images after every 2nd epoch\r\n",
        "        if epoch % 2 == 0:\r\n",
        "            # z_noise2 = np.random.uniform(-1, 1, size=(batch_size, z_dim))\r\n",
        "            z_noise2 = np.random.normal(0, 1, size=(batch_size, z_dim))\r\n",
        "            embedding_batch = embeddings_test[0:batch_size]\r\n",
        "            fake_images, _ = stage1_gen.predict_on_batch([embedding_batch, z_noise2])\r\n",
        "\r\n",
        "            # Save images\r\n",
        "            for i, img in enumerate(fake_images[:10]):\r\n",
        "                save_rgb_img(img, \"results/gen_{}_{}.png\".format(epoch, i))\r\n",
        "\r\n",
        "    # Save models\r\n",
        "    stage1_gen.save_weights(\"stage1_gen.h5\")\r\n",
        "    stage1_dis.save_weights(\"stage1_dis.h5\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "embeddings:  (8855, 10, 1024)\n",
            "Embeddings shape: (8855, 10, 1024)\n",
            "embeddings:  (2933, 10, 1024)\n",
            "Embeddings shape: (2933, 10, 1024)\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/keras/callbacks/tensorboard_v1.py:200: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/keras/callbacks/tensorboard_v1.py:203: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "========================================\n",
            "Epoch is: 0\n",
            "Number of batches 138\n",
            "Batch:1\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.6/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n",
            "/tensorflow-1.15.2/python3.6/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "d_loss_real:0.942449688911438\n",
            "d_loss_fake:4.457418441772461\n",
            "d_loss_wrong:5.510509014129639\n",
            "d_loss:2.9632068276405334\n",
            "g_loss:[1.7547271, 1.7136953, 0.0205159]\n",
            "Batch:2\n",
            "d_loss_real:1.0045764446258545\n",
            "d_loss_fake:0.7832236886024475\n",
            "d_loss_wrong:0.9137067198753357\n",
            "d_loss:0.926520824432373\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.6/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "g_loss:[3.1910026, 3.148295, 0.02135387]\n",
            "Batch:3\n",
            "d_loss_real:3.087733745574951\n",
            "d_loss_fake:0.05736958980560303\n",
            "d_loss_wrong:1.5109689235687256\n",
            "d_loss:1.9359515011310577\n",
            "g_loss:[3.9219909, 3.8758295, 0.023080712]\n",
            "Batch:4\n",
            "d_loss_real:3.027909278869629\n",
            "d_loss_fake:0.2786144018173218\n",
            "d_loss_wrong:1.9721685647964478\n",
            "d_loss:2.076650381088257\n",
            "g_loss:[1.4460365, 1.4014146, 0.02231091]\n",
            "Batch:5\n",
            "d_loss_real:1.8777024745941162\n",
            "d_loss_fake:0.1662072241306305\n",
            "d_loss_wrong:2.448977470397949\n",
            "d_loss:1.5926474332809448\n",
            "g_loss:[2.7603796, 2.7246566, 0.017861534]\n",
            "Batch:6\n",
            "d_loss_real:2.1334455013275146\n",
            "d_loss_fake:0.012091031298041344\n",
            "d_loss_wrong:1.9189594984054565\n",
            "d_loss:1.5494853854179382\n",
            "g_loss:[0.9929192, 0.94798815, 0.02246552]\n",
            "Batch:7\n",
            "d_loss_real:2.544940233230591\n",
            "d_loss_fake:0.13081008195877075\n",
            "d_loss_wrong:0.9683182835578918\n",
            "d_loss:1.547252207994461\n",
            "g_loss:[1.9395545, 1.8980734, 0.020740494]\n",
            "Batch:8\n",
            "d_loss_real:2.6033740043640137\n",
            "d_loss_fake:0.12449747323989868\n",
            "d_loss_wrong:0.6636764407157898\n",
            "d_loss:1.498730480670929\n",
            "g_loss:[2.4691205, 2.399516, 0.034802157]\n",
            "Batch:9\n",
            "d_loss_real:1.8696982860565186\n",
            "d_loss_fake:0.3064785599708557\n",
            "d_loss_wrong:1.0200899839401245\n",
            "d_loss:1.2664912939071655\n",
            "g_loss:[2.4911516, 2.4043968, 0.043377396]\n",
            "Batch:10\n",
            "d_loss_real:1.5495805740356445\n",
            "d_loss_fake:0.01465021725744009\n",
            "d_loss_wrong:1.1457805633544922\n",
            "d_loss:1.0648979842662811\n",
            "g_loss:[3.1072152, 3.0541196, 0.026547743]\n",
            "Batch:11\n",
            "d_loss_real:1.5997647047042847\n",
            "d_loss_fake:0.04442872479557991\n",
            "d_loss_wrong:1.0159592628479004\n",
            "d_loss:1.0649793446063995\n",
            "g_loss:[1.651341, 1.5988394, 0.02625075]\n",
            "Batch:12\n",
            "d_loss_real:1.6131447553634644\n",
            "d_loss_fake:0.17139093577861786\n",
            "d_loss_wrong:0.8223638534545898\n",
            "d_loss:1.0550110787153244\n",
            "g_loss:[2.9212186, 2.8765004, 0.022359125]\n",
            "Batch:13\n",
            "d_loss_real:1.6621776819229126\n",
            "d_loss_fake:0.021871745586395264\n",
            "d_loss_wrong:0.9078290462493896\n",
            "d_loss:1.0635140389204025\n",
            "g_loss:[2.9255745, 2.879708, 0.022933252]\n",
            "Batch:14\n",
            "d_loss_real:1.4348398447036743\n",
            "d_loss_fake:0.10227914899587631\n",
            "d_loss_wrong:0.9562243819236755\n",
            "d_loss:0.9820457994937897\n",
            "g_loss:[2.740542, 2.7085924, 0.015974753]\n",
            "Batch:15\n",
            "d_loss_real:1.1234997510910034\n",
            "d_loss_fake:0.14263004064559937\n",
            "d_loss_wrong:1.3274630308151245\n",
            "d_loss:0.9292731285095215\n",
            "g_loss:[2.8810072, 2.832437, 0.024285018]\n",
            "Batch:16\n",
            "d_loss_real:1.3279719352722168\n",
            "d_loss_fake:0.057810597121715546\n",
            "d_loss_wrong:1.0220705270767212\n",
            "d_loss:0.9339562356472015\n",
            "g_loss:[2.4627764, 2.4137664, 0.024504986]\n",
            "Batch:17\n",
            "d_loss_real:1.5157735347747803\n",
            "d_loss_fake:0.020689155906438828\n",
            "d_loss_wrong:1.6256824731826782\n",
            "d_loss:1.1694796681404114\n",
            "g_loss:[2.345954, 2.3007145, 0.02261969]\n",
            "Batch:18\n",
            "d_loss_real:1.434272289276123\n",
            "d_loss_fake:0.12220297008752823\n",
            "d_loss_wrong:0.6243272423744202\n",
            "d_loss:0.9037687033414841\n",
            "g_loss:[2.8416266, 2.8023167, 0.019654933]\n",
            "Batch:19\n",
            "d_loss_real:1.5722908973693848\n",
            "d_loss_fake:0.015256144106388092\n",
            "d_loss_wrong:0.87288898229599\n",
            "d_loss:1.0081817358732224\n",
            "g_loss:[1.5395362, 1.4960003, 0.02176797]\n",
            "Batch:20\n",
            "d_loss_real:1.388679027557373\n",
            "d_loss_fake:0.07217103242874146\n",
            "d_loss_wrong:0.9612321853637695\n",
            "d_loss:0.9526903033256531\n",
            "g_loss:[1.603476, 1.5602264, 0.021624804]\n",
            "Batch:21\n",
            "d_loss_real:1.4173341989517212\n",
            "d_loss_fake:0.011906476691365242\n",
            "d_loss_wrong:0.7645538449287415\n",
            "d_loss:0.9027821868658066\n",
            "g_loss:[1.2502563, 1.2084527, 0.020901829]\n",
            "Batch:22\n",
            "d_loss_real:1.0923688411712646\n",
            "d_loss_fake:0.027886755764484406\n",
            "d_loss_wrong:0.978546142578125\n",
            "d_loss:0.7977926433086395\n",
            "g_loss:[1.5045472, 1.466593, 0.018977117]\n",
            "Batch:23\n",
            "d_loss_real:1.147839069366455\n",
            "d_loss_fake:0.007837500423192978\n",
            "d_loss_wrong:0.8343133926391602\n",
            "d_loss:0.7844572514295578\n",
            "g_loss:[1.7228907, 1.6809984, 0.020946162]\n",
            "Batch:24\n",
            "d_loss_real:1.056671142578125\n",
            "d_loss_fake:0.022636158391833305\n",
            "d_loss_wrong:0.8914365172386169\n",
            "d_loss:0.7568537443876266\n",
            "g_loss:[1.2797936, 1.2333695, 0.023212068]\n",
            "Batch:25\n",
            "d_loss_real:1.0989576578140259\n",
            "d_loss_fake:0.03157251328229904\n",
            "d_loss_wrong:0.9273405075073242\n",
            "d_loss:0.7892070859670639\n",
            "g_loss:[1.4592776, 1.4078608, 0.025708444]\n",
            "Batch:26\n",
            "d_loss_real:1.1252191066741943\n",
            "d_loss_fake:0.03419667109847069\n",
            "d_loss_wrong:0.9493137001991272\n",
            "d_loss:0.8084871470928192\n",
            "g_loss:[1.1633167, 1.117918, 0.022699341]\n",
            "Batch:27\n",
            "d_loss_real:1.284566879272461\n",
            "d_loss_fake:0.1253223717212677\n",
            "d_loss_wrong:0.9433289766311646\n",
            "d_loss:0.9094462692737579\n",
            "g_loss:[2.0739405, 2.0352087, 0.019365933]\n",
            "Batch:28\n",
            "d_loss_real:1.1817333698272705\n",
            "d_loss_fake:0.06794185936450958\n",
            "d_loss_wrong:0.8750227689743042\n",
            "d_loss:0.8266078382730484\n",
            "g_loss:[1.2882898, 1.1989684, 0.044660658]\n",
            "Batch:29\n",
            "d_loss_real:1.1460074186325073\n",
            "d_loss_fake:0.08095155656337738\n",
            "d_loss_wrong:0.6885144114494324\n",
            "d_loss:0.7653702050447464\n",
            "g_loss:[1.8569865, 1.7948954, 0.031045578]\n",
            "Batch:30\n",
            "d_loss_real:1.215562105178833\n",
            "d_loss_fake:0.02266748994588852\n",
            "d_loss_wrong:1.1473232507705688\n",
            "d_loss:0.9002787470817566\n",
            "g_loss:[1.6945906, 1.6432726, 0.02565899]\n",
            "Batch:31\n",
            "d_loss_real:0.9820485711097717\n",
            "d_loss_fake:0.027804231271147728\n",
            "d_loss_wrong:0.8128556609153748\n",
            "d_loss:0.7011892646551132\n",
            "g_loss:[2.0970476, 2.0465584, 0.025244612]\n",
            "Batch:32\n",
            "d_loss_real:1.237538456916809\n",
            "d_loss_fake:0.0580449253320694\n",
            "d_loss_wrong:0.6429105401039124\n",
            "d_loss:0.7940080910921097\n",
            "g_loss:[1.4274733, 1.3582029, 0.034635164]\n",
            "Batch:33\n",
            "d_loss_real:1.1393539905548096\n",
            "d_loss_fake:0.044069141149520874\n",
            "d_loss_wrong:0.7656785845756531\n",
            "d_loss:0.7721139192581177\n",
            "g_loss:[2.2372546, 2.176049, 0.030602818]\n",
            "Batch:34\n",
            "d_loss_real:1.1506679058074951\n",
            "d_loss_fake:0.06004669517278671\n",
            "d_loss_wrong:0.714389979839325\n",
            "d_loss:0.76894311606884\n",
            "g_loss:[1.4037621, 1.3526578, 0.025552168]\n",
            "Batch:35\n",
            "d_loss_real:1.0330290794372559\n",
            "d_loss_fake:0.08622676134109497\n",
            "d_loss_wrong:0.7890709042549133\n",
            "d_loss:0.73533895611763\n",
            "g_loss:[1.5242797, 1.4747305, 0.024774611]\n",
            "Batch:36\n",
            "d_loss_real:1.115049958229065\n",
            "d_loss_fake:0.22062474489212036\n",
            "d_loss_wrong:0.6805030703544617\n",
            "d_loss:0.782806932926178\n",
            "g_loss:[1.7147672, 1.6582922, 0.028237503]\n",
            "Batch:37\n",
            "d_loss_real:1.253113031387329\n",
            "d_loss_fake:0.21913722157478333\n",
            "d_loss_wrong:0.7919890284538269\n",
            "d_loss:0.8793380856513977\n",
            "g_loss:[2.1304877, 2.0710578, 0.029714901]\n",
            "Batch:38\n",
            "d_loss_real:1.2358894348144531\n",
            "d_loss_fake:0.10757960379123688\n",
            "d_loss_wrong:0.805903434753418\n",
            "d_loss:0.8463154733181\n",
            "g_loss:[1.9367136, 1.8879923, 0.024360662]\n",
            "Batch:39\n",
            "d_loss_real:1.317205548286438\n",
            "d_loss_fake:0.01489119790494442\n",
            "d_loss_wrong:0.7216311693191528\n",
            "d_loss:0.8427333682775497\n",
            "g_loss:[2.4599755, 2.4081588, 0.025908403]\n",
            "Batch:40\n",
            "d_loss_real:1.174231767654419\n",
            "d_loss_fake:0.05935664474964142\n",
            "d_loss_wrong:1.0099189281463623\n",
            "d_loss:0.8544347882270813\n",
            "g_loss:[2.0772028, 2.0316677, 0.022767575]\n",
            "Batch:41\n",
            "d_loss_real:1.014734148979187\n",
            "d_loss_fake:0.06455135345458984\n",
            "d_loss_wrong:0.6962257027626038\n",
            "d_loss:0.6975613385438919\n",
            "g_loss:[2.5726562, 2.513192, 0.029732076]\n",
            "Batch:42\n",
            "d_loss_real:1.2527498006820679\n",
            "d_loss_fake:0.15220165252685547\n",
            "d_loss_wrong:0.6318271160125732\n",
            "d_loss:0.8223820924758911\n",
            "g_loss:[2.3617325, 2.3079777, 0.026877355]\n",
            "Batch:43\n",
            "d_loss_real:1.1228420734405518\n",
            "d_loss_fake:0.042840857058763504\n",
            "d_loss_wrong:0.701956033706665\n",
            "d_loss:0.7476202547550201\n",
            "g_loss:[2.2137709, 2.1561034, 0.028833697]\n",
            "Batch:44\n",
            "d_loss_real:0.9821608662605286\n",
            "d_loss_fake:0.02673269808292389\n",
            "d_loss_wrong:0.788996160030365\n",
            "d_loss:0.6950126439332962\n",
            "g_loss:[1.8844506, 1.8265882, 0.02893122]\n",
            "Batch:45\n",
            "d_loss_real:1.1433298587799072\n",
            "d_loss_fake:0.06805209070444107\n",
            "d_loss_wrong:0.6500411033630371\n",
            "d_loss:0.7511882334947586\n",
            "g_loss:[1.930097, 1.864013, 0.033042032]\n",
            "Batch:46\n",
            "d_loss_real:0.9900245666503906\n",
            "d_loss_fake:0.10132334381341934\n",
            "d_loss_wrong:0.7454352378845215\n",
            "d_loss:0.706701934337616\n",
            "g_loss:[1.8772261, 1.8158357, 0.030695211]\n",
            "Batch:47\n",
            "d_loss_real:1.097440242767334\n",
            "d_loss_fake:0.08051919937133789\n",
            "d_loss_wrong:0.6998840570449829\n",
            "d_loss:0.7438209354877472\n",
            "g_loss:[1.4814934, 1.4121212, 0.03468609]\n",
            "Batch:48\n",
            "d_loss_real:1.13185453414917\n",
            "d_loss_fake:0.05020786076784134\n",
            "d_loss_wrong:0.6706363558769226\n",
            "d_loss:0.7461383193731308\n",
            "g_loss:[2.0730555, 2.0103736, 0.03134101]\n",
            "Batch:49\n",
            "d_loss_real:1.0935124158859253\n",
            "d_loss_fake:0.08499780297279358\n",
            "d_loss_wrong:0.6704609990119934\n",
            "d_loss:0.73562091588974\n",
            "g_loss:[1.7999954, 1.7275221, 0.03623663]\n",
            "Batch:50\n",
            "d_loss_real:1.0319628715515137\n",
            "d_loss_fake:0.03048846870660782\n",
            "d_loss_wrong:0.6895062327384949\n",
            "d_loss:0.695980116724968\n",
            "g_loss:[1.7084229, 1.6624255, 0.022998711]\n",
            "Batch:51\n",
            "d_loss_real:1.0027648210525513\n",
            "d_loss_fake:0.030741669237613678\n",
            "d_loss_wrong:0.7646942138671875\n",
            "d_loss:0.7002413868904114\n",
            "g_loss:[1.6886568, 1.64111, 0.023773426]\n",
            "Batch:52\n",
            "d_loss_real:0.9797048568725586\n",
            "d_loss_fake:0.040852490812540054\n",
            "d_loss_wrong:0.7724395990371704\n",
            "d_loss:0.6931754499673843\n",
            "g_loss:[1.1377369, 1.1028111, 0.01746292]\n",
            "Batch:53\n",
            "d_loss_real:1.1152663230895996\n",
            "d_loss_fake:0.04701901599764824\n",
            "d_loss_wrong:0.7174831628799438\n",
            "d_loss:0.7487587034702301\n",
            "g_loss:[1.1307801, 1.0856869, 0.022546604]\n",
            "Batch:54\n",
            "d_loss_real:0.9253923892974854\n",
            "d_loss_fake:0.042115043848752975\n",
            "d_loss_wrong:0.7732129693031311\n",
            "d_loss:0.666528195142746\n",
            "g_loss:[1.1072131, 1.0604106, 0.023401236]\n",
            "Batch:55\n",
            "d_loss_real:0.978442907333374\n",
            "d_loss_fake:0.07125182449817657\n",
            "d_loss_wrong:0.691063404083252\n",
            "d_loss:0.6798002570867538\n",
            "g_loss:[1.1471298, 1.1025386, 0.022295617]\n",
            "Batch:56\n",
            "d_loss_real:1.149307370185852\n",
            "d_loss_fake:0.02604290470480919\n",
            "d_loss_wrong:0.7076739072799683\n",
            "d_loss:0.7580828815698624\n",
            "g_loss:[1.0259109, 0.97176486, 0.027072977]\n",
            "Batch:57\n",
            "d_loss_real:1.0762615203857422\n",
            "d_loss_fake:0.025686785578727722\n",
            "d_loss_wrong:0.7517260909080505\n",
            "d_loss:0.732483983039856\n",
            "g_loss:[1.0259392, 0.97393656, 0.02600135]\n",
            "Batch:58\n",
            "d_loss_real:0.9173250198364258\n",
            "d_loss_fake:0.018487785011529922\n",
            "d_loss_wrong:0.7698801159858704\n",
            "d_loss:0.655754491686821\n",
            "g_loss:[1.0749248, 1.0229243, 0.026000282]\n",
            "Batch:59\n",
            "d_loss_real:0.9322215914726257\n",
            "d_loss_fake:0.012449528090655804\n",
            "d_loss_wrong:0.8164152503013611\n",
            "d_loss:0.6733269840478897\n",
            "g_loss:[1.1393327, 1.0983326, 0.02050002]\n",
            "Batch:60\n",
            "d_loss_real:0.9979000091552734\n",
            "d_loss_fake:0.009924357756972313\n",
            "d_loss_wrong:0.7350134253501892\n",
            "d_loss:0.6851844489574432\n",
            "g_loss:[0.81915694, 0.78098994, 0.019083487]\n",
            "Batch:61\n",
            "d_loss_real:1.0273020267486572\n",
            "d_loss_fake:0.013988522812724113\n",
            "d_loss_wrong:0.767869234085083\n",
            "d_loss:0.7091154456138611\n",
            "g_loss:[0.7091779, 0.67454994, 0.017313993]\n",
            "Batch:62\n",
            "d_loss_real:1.0187000036239624\n",
            "d_loss_fake:0.006603802088648081\n",
            "d_loss_wrong:0.7407370805740356\n",
            "d_loss:0.6961852163076401\n",
            "g_loss:[0.71321046, 0.67328715, 0.019961651]\n",
            "Batch:63\n",
            "d_loss_real:1.0760594606399536\n",
            "d_loss_fake:0.010718090459704399\n",
            "d_loss_wrong:0.7210071682929993\n",
            "d_loss:0.7209610491991043\n",
            "g_loss:[0.649882, 0.6091505, 0.020365758]\n",
            "Batch:64\n",
            "d_loss_real:0.9464476108551025\n",
            "d_loss_fake:0.02954115718603134\n",
            "d_loss_wrong:0.7498410940170288\n",
            "d_loss:0.6680693626403809\n",
            "g_loss:[0.6130348, 0.57391113, 0.01956182]\n",
            "Batch:65\n",
            "d_loss_real:0.9905858039855957\n",
            "d_loss_fake:0.004757434129714966\n",
            "d_loss_wrong:0.7496339082717896\n",
            "d_loss:0.6838907301425934\n",
            "g_loss:[0.5535255, 0.5130762, 0.02022465]\n",
            "Batch:66\n",
            "d_loss_real:0.8939775824546814\n",
            "d_loss_fake:0.010677248239517212\n",
            "d_loss_wrong:0.7553121447563171\n",
            "d_loss:0.6384861469268799\n",
            "g_loss:[0.68893677, 0.6574254, 0.01575568]\n",
            "Batch:67\n",
            "d_loss_real:1.0104894638061523\n",
            "d_loss_fake:0.004738898016512394\n",
            "d_loss_wrong:0.7101636528968811\n",
            "d_loss:0.6839703768491745\n",
            "g_loss:[0.6424186, 0.6124517, 0.014983476]\n",
            "Batch:68\n",
            "d_loss_real:0.8925950527191162\n",
            "d_loss_fake:0.0012323228875175118\n",
            "d_loss_wrong:0.8319023251533508\n",
            "d_loss:0.6545811891555786\n",
            "g_loss:[0.58620805, 0.55124843, 0.017479815]\n",
            "Batch:69\n",
            "d_loss_real:1.0558745861053467\n",
            "d_loss_fake:0.004156860522925854\n",
            "d_loss_wrong:1.0462077856063843\n",
            "d_loss:0.7905284464359283\n",
            "g_loss:[0.6927924, 0.6579431, 0.017424628]\n",
            "Batch:70\n",
            "d_loss_real:0.9094427824020386\n",
            "d_loss_fake:0.001939081703312695\n",
            "d_loss_wrong:0.7285957932472229\n",
            "d_loss:0.6373551040887833\n",
            "g_loss:[0.72129554, 0.679451, 0.02092227]\n",
            "Batch:71\n",
            "d_loss_real:1.0127711296081543\n",
            "d_loss_fake:0.0032327743247151375\n",
            "d_loss_wrong:0.6292545199394226\n",
            "d_loss:0.6645073890686035\n",
            "g_loss:[0.61718744, 0.5802045, 0.018491482]\n",
            "Batch:72\n",
            "d_loss_real:0.975581169128418\n",
            "d_loss_fake:0.003502745646983385\n",
            "d_loss_wrong:0.6822866797447205\n",
            "d_loss:0.6592379361391068\n",
            "g_loss:[0.4996032, 0.46803433, 0.015784448]\n",
            "Batch:73\n",
            "d_loss_real:0.9349187612533569\n",
            "d_loss_fake:0.00242377957329154\n",
            "d_loss_wrong:0.720665693283081\n",
            "d_loss:0.6482317447662354\n",
            "g_loss:[0.43085, 0.40165606, 0.014596972]\n",
            "Batch:74\n",
            "d_loss_real:0.9841176271438599\n",
            "d_loss_fake:0.003433368867263198\n",
            "d_loss_wrong:0.7205451130867004\n",
            "d_loss:0.673053428530693\n",
            "g_loss:[0.44848216, 0.41962355, 0.014429302]\n",
            "Batch:75\n",
            "d_loss_real:0.9216187000274658\n",
            "d_loss_fake:0.007750564254820347\n",
            "d_loss_wrong:0.7589508891105652\n",
            "d_loss:0.6524847149848938\n",
            "g_loss:[0.4568855, 0.42832917, 0.01427816]\n",
            "Batch:76\n",
            "d_loss_real:0.9504361152648926\n",
            "d_loss_fake:0.004038952756673098\n",
            "d_loss_wrong:0.699371337890625\n",
            "d_loss:0.65107062458992\n",
            "g_loss:[0.4167957, 0.38742948, 0.014683118]\n",
            "Batch:77\n",
            "d_loss_real:0.9114909768104553\n",
            "d_loss_fake:0.0030274672899395227\n",
            "d_loss_wrong:0.7500678300857544\n",
            "d_loss:0.6440193057060242\n",
            "g_loss:[0.45727438, 0.42900896, 0.014132714]\n",
            "Batch:78\n",
            "d_loss_real:0.9012621641159058\n",
            "d_loss_fake:0.002862438792362809\n",
            "d_loss_wrong:0.7239163517951965\n",
            "d_loss:0.6323257833719254\n",
            "g_loss:[0.47400218, 0.44533718, 0.014332502]\n",
            "Batch:79\n",
            "d_loss_real:0.926394522190094\n",
            "d_loss_fake:0.003428495256230235\n",
            "d_loss_wrong:0.6996219754219055\n",
            "d_loss:0.6389598846435547\n",
            "g_loss:[0.42198354, 0.38990885, 0.016037341]\n",
            "Batch:80\n",
            "d_loss_real:0.9362084865570068\n",
            "d_loss_fake:0.005534789524972439\n",
            "d_loss_wrong:0.6890568733215332\n",
            "d_loss:0.641752153635025\n",
            "g_loss:[0.47205916, 0.44582248, 0.01311834]\n",
            "Batch:81\n",
            "d_loss_real:0.9227108359336853\n",
            "d_loss_fake:0.0026666519697755575\n",
            "d_loss_wrong:0.6729980111122131\n",
            "d_loss:0.6302715837955475\n",
            "g_loss:[0.4110879, 0.37371233, 0.018687787]\n",
            "Batch:82\n",
            "d_loss_real:1.037564754486084\n",
            "d_loss_fake:0.005991251673549414\n",
            "d_loss_wrong:0.706349790096283\n",
            "d_loss:0.6968676447868347\n",
            "g_loss:[0.47096363, 0.44507527, 0.012944183]\n",
            "Batch:83\n",
            "d_loss_real:0.8352183103561401\n",
            "d_loss_fake:0.002130641136318445\n",
            "d_loss_wrong:0.7317829728126526\n",
            "d_loss:0.6010875552892685\n",
            "g_loss:[0.46646348, 0.4396194, 0.013422044]\n",
            "Batch:84\n",
            "d_loss_real:0.8700897097587585\n",
            "d_loss_fake:0.008847590535879135\n",
            "d_loss_wrong:0.7352374792098999\n",
            "d_loss:0.6210661232471466\n",
            "g_loss:[0.48184165, 0.4528206, 0.014510521]\n",
            "Batch:85\n",
            "d_loss_real:0.914565920829773\n",
            "d_loss_fake:0.0057878755033016205\n",
            "d_loss_wrong:0.6914916634559631\n",
            "d_loss:0.6316028386354446\n",
            "g_loss:[0.4647195, 0.43978548, 0.012467006]\n",
            "Batch:86\n",
            "d_loss_real:0.9186348915100098\n",
            "d_loss_fake:0.0013257355894893408\n",
            "d_loss_wrong:0.6772221326828003\n",
            "d_loss:0.6289544105529785\n",
            "g_loss:[0.47310328, 0.45179617, 0.010653557]\n",
            "Batch:87\n",
            "d_loss_real:0.8772211670875549\n",
            "d_loss_fake:0.0020337840542197227\n",
            "d_loss_wrong:0.7166672945022583\n",
            "d_loss:0.6182858496904373\n",
            "g_loss:[0.46700692, 0.4371926, 0.014907159]\n",
            "Batch:88\n",
            "d_loss_real:0.9314610362052917\n",
            "d_loss_fake:0.0036235766019672155\n",
            "d_loss_wrong:0.7052935361862183\n",
            "d_loss:0.6429598033428192\n",
            "g_loss:[0.4915088, 0.4568833, 0.01731275]\n",
            "Batch:89\n",
            "d_loss_real:0.940078616142273\n",
            "d_loss_fake:0.002531616482883692\n",
            "d_loss_wrong:0.8713365793228149\n",
            "d_loss:0.6885063499212265\n",
            "g_loss:[0.46957067, 0.4239059, 0.022832382]\n",
            "Batch:90\n",
            "d_loss_real:0.8842605948448181\n",
            "d_loss_fake:0.003116730833426118\n",
            "d_loss_wrong:0.7434720396995544\n",
            "d_loss:0.628777489066124\n",
            "g_loss:[0.39977404, 0.360528, 0.019623026]\n",
            "Batch:91\n",
            "d_loss_real:0.9007140398025513\n",
            "d_loss_fake:0.002165281679481268\n",
            "d_loss_wrong:0.7309066653251648\n",
            "d_loss:0.6336250007152557\n",
            "g_loss:[0.40726382, 0.3769507, 0.015156556]\n",
            "Batch:92\n",
            "d_loss_real:1.052802562713623\n",
            "d_loss_fake:0.006512988358736038\n",
            "d_loss_wrong:0.7744460701942444\n",
            "d_loss:0.7216410487890244\n",
            "g_loss:[0.41114503, 0.37608472, 0.017530154]\n",
            "Batch:93\n",
            "d_loss_real:0.9313265085220337\n",
            "d_loss_fake:0.004888912197202444\n",
            "d_loss_wrong:0.7194920182228088\n",
            "d_loss:0.6467584818601608\n",
            "g_loss:[0.40205657, 0.36995518, 0.016050689]\n",
            "Batch:94\n",
            "d_loss_real:0.8552695512771606\n",
            "d_loss_fake:0.005101284012198448\n",
            "d_loss_wrong:0.7940125465393066\n",
            "d_loss:0.6274132281541824\n",
            "g_loss:[0.4188884, 0.38101512, 0.018936628]\n",
            "Batch:95\n",
            "d_loss_real:0.9288637638092041\n",
            "d_loss_fake:0.0071162632666528225\n",
            "d_loss_wrong:0.6707420945167542\n",
            "d_loss:0.6338964700698853\n",
            "g_loss:[0.39021903, 0.3561735, 0.017022777]\n",
            "Batch:96\n",
            "d_loss_real:0.8381547927856445\n",
            "d_loss_fake:0.0035249004140496254\n",
            "d_loss_wrong:0.7209470272064209\n",
            "d_loss:0.6001953780651093\n",
            "g_loss:[0.45229083, 0.41507095, 0.018609943]\n",
            "Batch:97\n",
            "d_loss_real:0.8694307804107666\n",
            "d_loss_fake:0.0067578330636024475\n",
            "d_loss_wrong:0.7110690474510193\n",
            "d_loss:0.6141721159219742\n",
            "g_loss:[0.55728364, 0.5223299, 0.017476872]\n",
            "Batch:98\n",
            "d_loss_real:0.9154101610183716\n",
            "d_loss_fake:0.004982823505997658\n",
            "d_loss_wrong:0.702875554561615\n",
            "d_loss:0.6346696764230728\n",
            "g_loss:[0.45511174, 0.42153358, 0.016789077]\n",
            "Batch:99\n",
            "d_loss_real:0.9404424428939819\n",
            "d_loss_fake:0.004902448505163193\n",
            "d_loss_wrong:0.6740441918373108\n",
            "d_loss:0.6399578750133514\n",
            "g_loss:[0.4056845, 0.3749612, 0.0153616555]\n",
            "Batch:100\n",
            "d_loss_real:0.9041620492935181\n",
            "d_loss_fake:0.00341397849842906\n",
            "d_loss_wrong:0.6830787062644958\n",
            "d_loss:0.623704195022583\n",
            "g_loss:[0.3828907, 0.35801604, 0.012437327]\n",
            "Batch:101\n",
            "d_loss_real:0.9375954866409302\n",
            "d_loss_fake:0.002397531410679221\n",
            "d_loss_wrong:0.6957709193229675\n",
            "d_loss:0.6433398574590683\n",
            "g_loss:[0.36925063, 0.34315407, 0.013048276]\n",
            "Batch:102\n",
            "d_loss_real:0.9361835718154907\n",
            "d_loss_fake:0.006453022360801697\n",
            "d_loss_wrong:0.7562015056610107\n",
            "d_loss:0.6587554216384888\n",
            "g_loss:[0.36740938, 0.3366045, 0.015402436]\n",
            "Batch:103\n",
            "d_loss_real:0.9413686394691467\n",
            "d_loss_fake:0.003892266657203436\n",
            "d_loss_wrong:0.6821637749671936\n",
            "d_loss:0.6421983242034912\n",
            "g_loss:[0.50916404, 0.48014262, 0.014510692]\n",
            "Batch:104\n",
            "d_loss_real:0.9315508604049683\n",
            "d_loss_fake:0.004620438441634178\n",
            "d_loss_wrong:0.7844525575637817\n",
            "d_loss:0.6630436778068542\n",
            "g_loss:[0.3953186, 0.36778447, 0.013767058]\n",
            "Batch:105\n",
            "d_loss_real:0.9679510593414307\n",
            "d_loss_fake:0.008295399136841297\n",
            "d_loss_wrong:0.7219067811965942\n",
            "d_loss:0.6665260791778564\n",
            "g_loss:[0.36125493, 0.34004366, 0.010605626]\n",
            "Batch:106\n",
            "d_loss_real:0.8573521375656128\n",
            "d_loss_fake:0.0058423238806426525\n",
            "d_loss_wrong:0.6989081501960754\n",
            "d_loss:0.6048636883497238\n",
            "g_loss:[0.47686422, 0.45296723, 0.011948504]\n",
            "Batch:107\n",
            "d_loss_real:0.9515191912651062\n",
            "d_loss_fake:0.006002492271363735\n",
            "d_loss_wrong:0.6959954500198364\n",
            "d_loss:0.6512590795755386\n",
            "g_loss:[0.40624437, 0.38245326, 0.011895552]\n",
            "Batch:108\n",
            "d_loss_real:0.9009870886802673\n",
            "d_loss_fake:0.002730051288381219\n",
            "d_loss_wrong:0.7188364863395691\n",
            "d_loss:0.6308851838111877\n",
            "g_loss:[0.36176383, 0.341281, 0.0102414265]\n",
            "Batch:109\n",
            "d_loss_real:0.9298583269119263\n",
            "d_loss_fake:0.012029278092086315\n",
            "d_loss_wrong:0.6899188160896301\n",
            "d_loss:0.6404161900281906\n",
            "g_loss:[0.37226218, 0.34361368, 0.014324253]\n",
            "Batch:110\n",
            "d_loss_real:0.8852408528327942\n",
            "d_loss_fake:0.004136398434638977\n",
            "d_loss_wrong:0.6937048435211182\n",
            "d_loss:0.6170807331800461\n",
            "g_loss:[0.36725923, 0.33606857, 0.015595331]\n",
            "Batch:111\n",
            "d_loss_real:0.8901522159576416\n",
            "d_loss_fake:0.00850130058825016\n",
            "d_loss_wrong:0.704543948173523\n",
            "d_loss:0.6233374178409576\n",
            "g_loss:[0.3894177, 0.3604166, 0.014500558]\n",
            "Batch:112\n",
            "d_loss_real:0.9301073551177979\n",
            "d_loss_fake:0.005254523828625679\n",
            "d_loss_wrong:0.744590163230896\n",
            "d_loss:0.6525148451328278\n",
            "g_loss:[0.39554927, 0.36528787, 0.015130699]\n",
            "Batch:113\n",
            "d_loss_real:0.8723316192626953\n",
            "d_loss_fake:0.008927117101848125\n",
            "d_loss_wrong:0.7121966481208801\n",
            "d_loss:0.6164467483758926\n",
            "g_loss:[0.44028077, 0.403979, 0.018150881]\n",
            "Batch:114\n",
            "d_loss_real:0.8690106868743896\n",
            "d_loss_fake:0.00571238249540329\n",
            "d_loss_wrong:0.6810429096221924\n",
            "d_loss:0.6061941683292389\n",
            "g_loss:[0.3887421, 0.35946053, 0.014640773]\n",
            "Batch:115\n",
            "d_loss_real:0.9098907709121704\n",
            "d_loss_fake:0.004792437888681889\n",
            "d_loss_wrong:0.6882156133651733\n",
            "d_loss:0.6281974017620087\n",
            "g_loss:[0.38436204, 0.3564375, 0.013962273]\n",
            "Batch:116\n",
            "d_loss_real:0.9546940326690674\n",
            "d_loss_fake:0.017519284039735794\n",
            "d_loss_wrong:0.7020606398582458\n",
            "d_loss:0.6572420001029968\n",
            "g_loss:[0.35504127, 0.33043507, 0.0123031065]\n",
            "Batch:117\n",
            "d_loss_real:0.8992360830307007\n",
            "d_loss_fake:0.0062738158740103245\n",
            "d_loss_wrong:0.7171705365180969\n",
            "d_loss:0.6304791271686554\n",
            "g_loss:[0.36224172, 0.34211642, 0.010062647]\n",
            "Batch:118\n",
            "d_loss_real:0.9043722748756409\n",
            "d_loss_fake:0.009846086613833904\n",
            "d_loss_wrong:0.6780635118484497\n",
            "d_loss:0.6241635382175446\n",
            "g_loss:[0.39427018, 0.3711053, 0.011582427]\n",
            "Batch:119\n",
            "d_loss_real:0.889173686504364\n",
            "d_loss_fake:0.002392279217019677\n",
            "d_loss_wrong:0.7016159296035767\n",
            "d_loss:0.6205888986587524\n",
            "g_loss:[0.38174468, 0.3646596, 0.008542535]\n",
            "Batch:120\n",
            "d_loss_real:0.9014667272567749\n",
            "d_loss_fake:0.0038595860823988914\n",
            "d_loss_wrong:0.6742315292358398\n",
            "d_loss:0.6202561408281326\n",
            "g_loss:[0.37448308, 0.35241306, 0.011035008]\n",
            "Batch:121\n",
            "d_loss_real:0.9094220995903015\n",
            "d_loss_fake:0.008425083942711353\n",
            "d_loss_wrong:0.7379904985427856\n",
            "d_loss:0.6413149386644363\n",
            "g_loss:[0.407802, 0.38479418, 0.011503911]\n",
            "Batch:122\n",
            "d_loss_real:0.8616127967834473\n",
            "d_loss_fake:0.001994866179302335\n",
            "d_loss_wrong:0.7050540447235107\n",
            "d_loss:0.607568621635437\n",
            "g_loss:[0.35544938, 0.33076882, 0.012340272]\n",
            "Batch:123\n",
            "d_loss_real:1.0073883533477783\n",
            "d_loss_fake:0.006939758080989122\n",
            "d_loss_wrong:0.7633453011512756\n",
            "d_loss:0.6962654441595078\n",
            "g_loss:[0.37465376, 0.35838693, 0.008133409]\n",
            "Batch:124\n",
            "d_loss_real:0.9367155432701111\n",
            "d_loss_fake:0.010152289643883705\n",
            "d_loss_wrong:0.6565230488777161\n",
            "d_loss:0.635026603937149\n",
            "g_loss:[0.34616485, 0.33049983, 0.007832518]\n",
            "Batch:125\n",
            "d_loss_real:0.8363232612609863\n",
            "d_loss_fake:0.0058448598720133305\n",
            "d_loss_wrong:0.7228177785873413\n",
            "d_loss:0.6003272831439972\n",
            "g_loss:[0.3709505, 0.35039124, 0.010279632]\n",
            "Batch:126\n",
            "d_loss_real:0.8667711019515991\n",
            "d_loss_fake:0.0032630334608256817\n",
            "d_loss_wrong:0.6951916813850403\n",
            "d_loss:0.6079992353916168\n",
            "g_loss:[0.35242668, 0.33255985, 0.009933408]\n",
            "Batch:127\n",
            "d_loss_real:0.9313860535621643\n",
            "d_loss_fake:0.0032393764704465866\n",
            "d_loss_wrong:0.6831697821617126\n",
            "d_loss:0.6372953206300735\n",
            "g_loss:[0.36170426, 0.3439839, 0.008860182]\n",
            "Batch:128\n",
            "d_loss_real:0.8772199749946594\n",
            "d_loss_fake:0.006718493066728115\n",
            "d_loss_wrong:0.7847365736961365\n",
            "d_loss:0.636473760008812\n",
            "g_loss:[0.39880818, 0.37390137, 0.012453408]\n",
            "Batch:129\n",
            "d_loss_real:0.8980389833450317\n",
            "d_loss_fake:0.0023230784572660923\n",
            "d_loss_wrong:0.6991472244262695\n",
            "d_loss:0.6243870705366135\n",
            "g_loss:[0.36373958, 0.34119487, 0.011272361]\n",
            "Batch:130\n",
            "d_loss_real:0.8956054449081421\n",
            "d_loss_fake:0.004101133905351162\n",
            "d_loss_wrong:0.6944320797920227\n",
            "d_loss:0.6224360316991806\n",
            "g_loss:[0.34882858, 0.32904392, 0.009892333]\n",
            "Batch:131\n",
            "d_loss_real:0.9334851503372192\n",
            "d_loss_fake:0.0036669408436864614\n",
            "d_loss_wrong:0.6878279447555542\n",
            "d_loss:0.6396162956953049\n",
            "g_loss:[0.3495295, 0.32910156, 0.010213966]\n",
            "Batch:132\n",
            "d_loss_real:0.8737660646438599\n",
            "d_loss_fake:0.002686740830540657\n",
            "d_loss_wrong:0.6958669424057007\n",
            "d_loss:0.611521452665329\n",
            "g_loss:[0.36663276, 0.3453058, 0.010663484]\n",
            "Batch:133\n",
            "d_loss_real:0.8813402652740479\n",
            "d_loss_fake:0.0029413909651339054\n",
            "d_loss_wrong:0.6875047087669373\n",
            "d_loss:0.6132816523313522\n",
            "g_loss:[0.34534252, 0.3314688, 0.0069368575]\n",
            "Batch:134\n",
            "d_loss_real:0.8758737444877625\n",
            "d_loss_fake:0.004733467474579811\n",
            "d_loss_wrong:0.6785469055175781\n",
            "d_loss:0.608756959438324\n",
            "g_loss:[0.34756267, 0.33146375, 0.00804946]\n",
            "Batch:135\n",
            "d_loss_real:0.8840193748474121\n",
            "d_loss_fake:0.0026839899364858866\n",
            "d_loss_wrong:0.6960178017616272\n",
            "d_loss:0.6166851371526718\n",
            "g_loss:[0.34261996, 0.32884842, 0.0068857735]\n",
            "Batch:136\n",
            "d_loss_real:0.8806380033493042\n",
            "d_loss_fake:0.0018443051958456635\n",
            "d_loss_wrong:0.6863247156143188\n",
            "d_loss:0.6123612523078918\n",
            "g_loss:[0.3451245, 0.33054772, 0.0072884033]\n",
            "Batch:137\n",
            "d_loss_real:0.9129292964935303\n",
            "d_loss_fake:0.002578552346676588\n",
            "d_loss_wrong:0.6755006313323975\n",
            "d_loss:0.6259844452142715\n",
            "g_loss:[0.36379823, 0.35040322, 0.0066975127]\n",
            "Batch:138\n",
            "d_loss_real:0.862372636795044\n",
            "d_loss_fake:0.002380292396992445\n",
            "d_loss_wrong:0.7019102573394775\n",
            "d_loss:0.6072589606046677\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "g_loss:[0.35005772, 0.3344525, 0.0078026126]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "========================================\n",
            "Epoch is: 1\n",
            "Number of batches 138\n",
            "Batch:1\n",
            "d_loss_real:0.8713287115097046\n",
            "d_loss_fake:0.0014270374085754156\n",
            "d_loss_wrong:0.7256526350975037\n",
            "d_loss:0.6174342781305313\n",
            "g_loss:[0.35832104, 0.3408267, 0.00874718]\n",
            "Batch:2\n",
            "d_loss_real:0.8558797836303711\n",
            "d_loss_fake:0.0024644325021654367\n",
            "d_loss_wrong:0.6966694593429565\n",
            "d_loss:0.6027233600616455\n",
            "g_loss:[0.36689213, 0.34455302, 0.011169556]\n",
            "Batch:3\n",
            "d_loss_real:0.9031451940536499\n",
            "d_loss_fake:0.0019404597114771605\n",
            "d_loss_wrong:0.6876111626625061\n",
            "d_loss:0.6239605098962784\n",
            "g_loss:[0.35930398, 0.33824724, 0.010528369]\n",
            "Batch:4\n",
            "d_loss_real:0.9534056186676025\n",
            "d_loss_fake:0.0014098354149609804\n",
            "d_loss_wrong:0.8105895519256592\n",
            "d_loss:0.6797026544809341\n",
            "g_loss:[0.35636505, 0.33691537, 0.009724846]\n",
            "Batch:5\n",
            "d_loss_real:0.8535199761390686\n",
            "d_loss_fake:0.0011333134025335312\n",
            "d_loss_wrong:0.9061132669448853\n",
            "d_loss:0.6535716354846954\n",
            "g_loss:[0.35045534, 0.33371603, 0.008369649]\n",
            "Batch:6\n",
            "d_loss_real:0.9595019817352295\n",
            "d_loss_fake:0.001608245074748993\n",
            "d_loss_wrong:0.8936590552330017\n",
            "d_loss:0.7035678178071976\n",
            "g_loss:[0.3637318, 0.3464403, 0.008645753]\n",
            "Batch:7\n",
            "d_loss_real:0.9603755474090576\n",
            "d_loss_fake:0.002380418125540018\n",
            "d_loss_wrong:0.6726730465888977\n",
            "d_loss:0.6489511430263519\n",
            "g_loss:[0.36122772, 0.34565333, 0.007787197]\n",
            "Batch:8\n",
            "d_loss_real:0.9378242492675781\n",
            "d_loss_fake:0.001686125760897994\n",
            "d_loss_wrong:0.6201903223991394\n",
            "d_loss:0.6243812292814255\n",
            "g_loss:[0.35464412, 0.33011568, 0.012264214]\n",
            "Batch:9\n",
            "d_loss_real:0.8883990049362183\n",
            "d_loss_fake:0.004115196876227856\n",
            "d_loss_wrong:0.6787117719650269\n",
            "d_loss:0.6149062514305115\n",
            "g_loss:[0.36599463, 0.33601594, 0.01498935]\n",
            "Batch:10\n",
            "d_loss_real:0.8560031056404114\n",
            "d_loss_fake:0.001268751104362309\n",
            "d_loss_wrong:0.6811914443969727\n",
            "d_loss:0.5986166000366211\n",
            "g_loss:[0.34847867, 0.3292743, 0.0096021835]\n",
            "Batch:11\n",
            "d_loss_real:0.9007522463798523\n",
            "d_loss_fake:0.0028995489701628685\n",
            "d_loss_wrong:0.6886922717094421\n",
            "d_loss:0.6232740730047226\n",
            "g_loss:[0.3477178, 0.33096087, 0.0083784545]\n",
            "Batch:12\n",
            "d_loss_real:0.9266899824142456\n",
            "d_loss_fake:0.0019714413210749626\n",
            "d_loss_wrong:0.6605234742164612\n",
            "d_loss:0.6289687156677246\n",
            "g_loss:[0.34255445, 0.32945597, 0.006549232]\n",
            "Batch:13\n",
            "d_loss_real:0.918553352355957\n",
            "d_loss_fake:0.0024805907160043716\n",
            "d_loss_wrong:0.6700413823127747\n",
            "d_loss:0.6274071633815765\n",
            "g_loss:[0.35311532, 0.34057117, 0.006272083]\n",
            "Batch:14\n",
            "d_loss_real:0.9560913443565369\n",
            "d_loss_fake:0.0022216313518583775\n",
            "d_loss_wrong:0.662344217300415\n",
            "d_loss:0.6441871374845505\n",
            "g_loss:[0.3480956, 0.33694482, 0.005575385]\n",
            "Batch:15\n",
            "d_loss_real:0.893933117389679\n",
            "d_loss_fake:0.0016651544719934464\n",
            "d_loss_wrong:0.7916129231452942\n",
            "d_loss:0.6452860832214355\n",
            "g_loss:[0.34801483, 0.32966897, 0.009172939]\n",
            "Batch:16\n",
            "d_loss_real:0.8636611700057983\n",
            "d_loss_fake:0.0015157063025981188\n",
            "d_loss_wrong:0.7741774916648865\n",
            "d_loss:0.6257538795471191\n",
            "g_loss:[0.35006863, 0.33134025, 0.009364184]\n",
            "Batch:17\n",
            "d_loss_real:0.959444522857666\n",
            "d_loss_fake:0.0007869002292864025\n",
            "d_loss_wrong:0.9495269656181335\n",
            "d_loss:0.7173007279634476\n",
            "g_loss:[0.35518804, 0.33771655, 0.008735749]\n",
            "Batch:18\n",
            "d_loss_real:0.8959742784500122\n",
            "d_loss_fake:0.0021457443945109844\n",
            "d_loss_wrong:0.6665267944335938\n",
            "d_loss:0.6151552796363831\n",
            "g_loss:[0.3746333, 0.3618688, 0.0063822507]\n",
            "Batch:19\n",
            "d_loss_real:0.9819252490997314\n",
            "d_loss_fake:0.0013817416038364172\n",
            "d_loss_wrong:0.6858174800872803\n",
            "d_loss:0.6627624332904816\n",
            "g_loss:[0.34714374, 0.33389652, 0.0066236123]\n",
            "Batch:20\n",
            "d_loss_real:1.0024151802062988\n",
            "d_loss_fake:0.0026105912402272224\n",
            "d_loss_wrong:0.732209324836731\n",
            "d_loss:0.6849125623703003\n",
            "g_loss:[0.3417407, 0.3286429, 0.0065489006]\n",
            "Batch:21\n",
            "d_loss_real:0.8910402655601501\n",
            "d_loss_fake:0.0015522027388215065\n",
            "d_loss_wrong:0.6579762101173401\n",
            "d_loss:0.6104022413492203\n",
            "g_loss:[0.34369385, 0.33287078, 0.005411541]\n",
            "Batch:22\n",
            "d_loss_real:0.871108889579773\n",
            "d_loss_fake:0.0015518390573561192\n",
            "d_loss_wrong:0.7019414901733398\n",
            "d_loss:0.6114277839660645\n",
            "g_loss:[0.36615002, 0.3564976, 0.0048262253]\n",
            "Batch:23\n",
            "d_loss_real:0.8663658499717712\n",
            "d_loss_fake:0.001370331970974803\n",
            "d_loss_wrong:0.692771315574646\n",
            "d_loss:0.6067183315753937\n",
            "g_loss:[0.34935588, 0.33829373, 0.005531074]\n",
            "Batch:24\n",
            "d_loss_real:0.8302638530731201\n",
            "d_loss_fake:0.0021143981721252203\n",
            "d_loss_wrong:0.7059396505355835\n",
            "d_loss:0.5921454429626465\n",
            "g_loss:[0.3818297, 0.37061238, 0.0056086592]\n",
            "Batch:25\n",
            "d_loss_real:0.911765992641449\n",
            "d_loss_fake:0.0017827458214014769\n",
            "d_loss_wrong:0.72835773229599\n",
            "d_loss:0.63841812312603\n",
            "g_loss:[0.35577726, 0.34136945, 0.0072038993]\n",
            "Batch:26\n",
            "d_loss_real:0.8722942471504211\n",
            "d_loss_fake:0.0016316246474161744\n",
            "d_loss_wrong:0.7148810625076294\n",
            "d_loss:0.6152752935886383\n",
            "g_loss:[0.34320107, 0.33100992, 0.0060955673]\n",
            "Batch:27\n",
            "d_loss_real:0.9385467767715454\n",
            "d_loss_fake:0.0023482649121433496\n",
            "d_loss_wrong:0.7104445099830627\n",
            "d_loss:0.6474715769290924\n",
            "g_loss:[0.3426155, 0.33146942, 0.005573038]\n",
            "Batch:28\n",
            "d_loss_real:0.8362886905670166\n",
            "d_loss_fake:0.0017318017780780792\n",
            "d_loss_wrong:0.704531192779541\n",
            "d_loss:0.5947100967168808\n",
            "g_loss:[0.3474728, 0.3301168, 0.008677985]\n",
            "Batch:29\n",
            "d_loss_real:0.8742125034332275\n",
            "d_loss_fake:0.003059930633753538\n",
            "d_loss_wrong:0.6669240593910217\n",
            "d_loss:0.6046022474765778\n",
            "g_loss:[0.3454377, 0.3326223, 0.00640771]\n",
            "Batch:30\n",
            "d_loss_real:0.9225848317146301\n",
            "d_loss_fake:0.0013197578955441713\n",
            "d_loss_wrong:0.7798906564712524\n",
            "d_loss:0.6565950214862823\n",
            "g_loss:[0.35960433, 0.34580034, 0.0069019943]\n",
            "Batch:31\n",
            "d_loss_real:0.8401731848716736\n",
            "d_loss_fake:0.0007010877598077059\n",
            "d_loss_wrong:0.7021611928939819\n",
            "d_loss:0.5958021581172943\n",
            "g_loss:[0.3426725, 0.3293054, 0.0066835443]\n",
            "Batch:32\n",
            "d_loss_real:0.894871711730957\n",
            "d_loss_fake:0.00036020250990986824\n",
            "d_loss_wrong:0.643438458442688\n",
            "d_loss:0.6083855181932449\n",
            "g_loss:[0.36174732, 0.34643716, 0.0076550776]\n",
            "Batch:33\n",
            "d_loss_real:0.8899530172348022\n",
            "d_loss_fake:0.0009845971362665296\n",
            "d_loss_wrong:0.6735920906066895\n",
            "d_loss:0.6136206835508347\n",
            "g_loss:[0.34713182, 0.33441302, 0.006359395]\n",
            "Batch:34\n",
            "d_loss_real:0.8908514380455017\n",
            "d_loss_fake:0.001011393149383366\n",
            "d_loss_wrong:0.6701437830924988\n",
            "d_loss:0.6132145076990128\n",
            "g_loss:[0.34275866, 0.33129936, 0.0057296464]\n",
            "Batch:35\n",
            "d_loss_real:0.896501898765564\n",
            "d_loss_fake:0.0018182191997766495\n",
            "d_loss_wrong:0.7026047706604004\n",
            "d_loss:0.6243567019701004\n",
            "g_loss:[0.34200174, 0.33023936, 0.005881187]\n",
            "Batch:36\n",
            "d_loss_real:0.851553201675415\n",
            "d_loss_fake:0.0006065083434805274\n",
            "d_loss_wrong:0.6904417872428894\n",
            "d_loss:0.5985386818647385\n",
            "g_loss:[0.34335384, 0.3282392, 0.0075573158]\n",
            "Batch:37\n",
            "d_loss_real:0.874555230140686\n",
            "d_loss_fake:0.0012362158158794045\n",
            "d_loss_wrong:0.7304974794387817\n",
            "d_loss:0.6202110350131989\n",
            "g_loss:[0.35211188, 0.33669412, 0.007708881]\n",
            "Batch:38\n",
            "d_loss_real:0.911067008972168\n",
            "d_loss_fake:0.0014501516707241535\n",
            "d_loss_wrong:0.7102248668670654\n",
            "d_loss:0.6334522664546967\n",
            "g_loss:[0.37808233, 0.36528626, 0.0063980343]\n",
            "Batch:39\n",
            "d_loss_real:0.8921529650688171\n",
            "d_loss_fake:0.0013483554357662797\n",
            "d_loss_wrong:0.6918519735336304\n",
            "d_loss:0.6193765699863434\n",
            "g_loss:[0.34357378, 0.32994264, 0.0068155723]\n",
            "Batch:40\n",
            "d_loss_real:0.8980922698974609\n",
            "d_loss_fake:0.0017705966020002961\n",
            "d_loss_wrong:0.789496898651123\n",
            "d_loss:0.6468630135059357\n",
            "g_loss:[0.37463257, 0.36255163, 0.0060404744]\n",
            "Batch:41\n",
            "d_loss_real:0.866734504699707\n",
            "d_loss_fake:0.0013534682802855968\n",
            "d_loss_wrong:0.6705019474029541\n",
            "d_loss:0.6013310998678207\n",
            "g_loss:[0.3915604, 0.37721983, 0.0071702935]\n",
            "Batch:42\n",
            "d_loss_real:0.9281595945358276\n",
            "d_loss_fake:0.0021657594479620457\n",
            "d_loss_wrong:0.6580054759979248\n",
            "d_loss:0.6291225999593735\n",
            "g_loss:[0.34296235, 0.32965583, 0.006653268]\n",
            "Batch:43\n",
            "d_loss_real:0.8298523426055908\n",
            "d_loss_fake:0.0018389644101262093\n",
            "d_loss_wrong:0.6859586238861084\n",
            "d_loss:0.5868755728006363\n",
            "g_loss:[0.34006497, 0.3285141, 0.005775431]\n",
            "Batch:44\n",
            "d_loss_real:0.8561385869979858\n",
            "d_loss_fake:0.0015693079913035035\n",
            "d_loss_wrong:0.6957792043685913\n",
            "d_loss:0.6024064272642136\n",
            "g_loss:[0.36181378, 0.34925842, 0.006277674]\n",
            "Batch:45\n",
            "d_loss_real:0.8517658710479736\n",
            "d_loss_fake:0.0012955593410879374\n",
            "d_loss_wrong:0.6714596152305603\n",
            "d_loss:0.5940717309713364\n",
            "g_loss:[0.3446324, 0.33005476, 0.0072888113]\n",
            "Batch:46\n",
            "d_loss_real:0.8554260730743408\n",
            "d_loss_fake:0.0008609007927589118\n",
            "d_loss_wrong:0.6772803664207458\n",
            "d_loss:0.5972483605146408\n",
            "g_loss:[0.36294195, 0.3495109, 0.006715518]\n",
            "Batch:47\n",
            "d_loss_real:0.8899751305580139\n",
            "d_loss_fake:0.0007001673220656812\n",
            "d_loss_wrong:0.670555591583252\n",
            "d_loss:0.6128015071153641\n",
            "g_loss:[0.3454171, 0.32965186, 0.007882625]\n",
            "Batch:48\n",
            "d_loss_real:0.8930644989013672\n",
            "d_loss_fake:0.0021331030875444412\n",
            "d_loss_wrong:0.6530236005783081\n",
            "d_loss:0.610321432352066\n",
            "g_loss:[0.34538263, 0.3317389, 0.0068218634]\n",
            "Batch:49\n",
            "d_loss_real:0.8540927171707153\n",
            "d_loss_fake:0.00144746876321733\n",
            "d_loss_wrong:0.6739452481269836\n",
            "d_loss:0.595894530415535\n",
            "g_loss:[0.35227397, 0.3395819, 0.006346034]\n",
            "Batch:50\n",
            "d_loss_real:0.8629502058029175\n",
            "d_loss_fake:0.0009128922829404473\n",
            "d_loss_wrong:0.6671012043952942\n",
            "d_loss:0.5984786301851273\n",
            "g_loss:[0.34566855, 0.33675086, 0.0044588493]\n",
            "Batch:51\n",
            "d_loss_real:0.8590114116668701\n",
            "d_loss_fake:0.0014312623534351587\n",
            "d_loss_wrong:0.6763287782669067\n",
            "d_loss:0.5989457219839096\n",
            "g_loss:[0.33941877, 0.3307406, 0.0043390887]\n",
            "Batch:52\n",
            "d_loss_real:0.865559458732605\n",
            "d_loss_fake:0.0010967821581289172\n",
            "d_loss_wrong:0.6932032108306885\n",
            "d_loss:0.6063547283411026\n",
            "g_loss:[0.3378815, 0.33125007, 0.0033157137]\n",
            "Batch:53\n",
            "d_loss_real:0.8736943602561951\n",
            "d_loss_fake:0.0004152414621785283\n",
            "d_loss_wrong:0.6769697070121765\n",
            "d_loss:0.6061934232711792\n",
            "g_loss:[0.36611333, 0.3567481, 0.0046826117]\n",
            "Batch:54\n",
            "d_loss_real:0.8403987288475037\n",
            "d_loss_fake:0.0029105027206242085\n",
            "d_loss_wrong:0.6880241632461548\n",
            "d_loss:0.5929330289363861\n",
            "g_loss:[0.37116042, 0.36135855, 0.0049009384]\n",
            "Batch:55\n",
            "d_loss_real:0.8580062985420227\n",
            "d_loss_fake:0.0018199844053015113\n",
            "d_loss_wrong:0.6676365733146667\n",
            "d_loss:0.596367284655571\n",
            "g_loss:[0.3469679, 0.33731192, 0.004827985]\n",
            "Batch:56\n",
            "d_loss_real:0.8993446230888367\n",
            "d_loss_fake:0.002448128070682287\n",
            "d_loss_wrong:0.6824607253074646\n",
            "d_loss:0.6208995282649994\n",
            "g_loss:[0.34745646, 0.3368942, 0.0052811243]\n",
            "Batch:57\n",
            "d_loss_real:0.8710851669311523\n",
            "d_loss_fake:0.0005218862206675112\n",
            "d_loss_wrong:0.6786354780197144\n",
            "d_loss:0.6053319275379181\n",
            "g_loss:[0.3679846, 0.35691023, 0.00553718]\n",
            "Batch:58\n",
            "d_loss_real:0.835796058177948\n",
            "d_loss_fake:0.0005352373700588942\n",
            "d_loss_wrong:0.698894202709198\n",
            "d_loss:0.5927553921937943\n",
            "g_loss:[0.3449054, 0.33475557, 0.0050749145]\n",
            "Batch:59\n",
            "d_loss_real:0.8651243448257446\n",
            "d_loss_fake:0.0008932771161198616\n",
            "d_loss_wrong:0.6889089941978455\n",
            "d_loss:0.6050127446651459\n",
            "g_loss:[0.34199968, 0.3325712, 0.0047142426]\n",
            "Batch:60\n",
            "d_loss_real:0.888475775718689\n",
            "d_loss_fake:0.0018485188484191895\n",
            "d_loss_wrong:0.6840993762016296\n",
            "d_loss:0.6157248616218567\n",
            "g_loss:[0.34307054, 0.3338415, 0.0046145134]\n",
            "Batch:61\n",
            "d_loss_real:0.8863933086395264\n",
            "d_loss_fake:0.0013397068250924349\n",
            "d_loss_wrong:0.6979697942733765\n",
            "d_loss:0.6180240362882614\n",
            "g_loss:[0.33902562, 0.33119118, 0.00391722]\n",
            "Batch:62\n",
            "d_loss_real:0.8870496153831482\n",
            "d_loss_fake:0.0014797772746533155\n",
            "d_loss_wrong:0.6798860430717468\n",
            "d_loss:0.6138662695884705\n",
            "g_loss:[0.33617944, 0.32819214, 0.0039936528]\n",
            "Batch:63\n",
            "d_loss_real:0.8804413080215454\n",
            "d_loss_fake:0.0010971345473080873\n",
            "d_loss_wrong:0.6832908391952515\n",
            "d_loss:0.6113176494836807\n",
            "g_loss:[0.33951953, 0.3315794, 0.00397007]\n",
            "Batch:64\n",
            "d_loss_real:0.8510816693305969\n",
            "d_loss_fake:0.003468405222520232\n",
            "d_loss_wrong:0.6787936687469482\n",
            "d_loss:0.5961063504219055\n",
            "g_loss:[0.34702602, 0.33915794, 0.003934041]\n",
            "Batch:65\n",
            "d_loss_real:0.9042827486991882\n",
            "d_loss_fake:0.001854108413681388\n",
            "d_loss_wrong:0.6978421211242676\n",
            "d_loss:0.627065435051918\n",
            "g_loss:[0.3568467, 0.34753755, 0.0046545677]\n",
            "Batch:66\n",
            "d_loss_real:0.8394560813903809\n",
            "d_loss_fake:0.0011221005115658045\n",
            "d_loss_wrong:0.6959019303321838\n",
            "d_loss:0.5939840525388718\n",
            "g_loss:[0.34322226, 0.33666083, 0.0032807093]\n",
            "Batch:67\n",
            "d_loss_real:0.8917983174324036\n",
            "d_loss_fake:0.0038891807198524475\n",
            "d_loss_wrong:0.6647042036056519\n",
            "d_loss:0.6130475103855133\n",
            "g_loss:[0.3508419, 0.3435495, 0.003646207]\n",
            "Batch:68\n",
            "d_loss_real:0.858433187007904\n",
            "d_loss_fake:0.0030934298411011696\n",
            "d_loss_wrong:0.719317615032196\n",
            "d_loss:0.6098193526268005\n",
            "g_loss:[0.3726927, 0.36429277, 0.004199963]\n",
            "Batch:69\n",
            "d_loss_real:0.9263449907302856\n",
            "d_loss_fake:0.0013507838593795896\n",
            "d_loss_wrong:0.8459034562110901\n",
            "d_loss:0.6749860495328903\n",
            "g_loss:[0.4422723, 0.4333649, 0.0044537066]\n",
            "Batch:70\n",
            "d_loss_real:0.8343168497085571\n",
            "d_loss_fake:0.008661855943500996\n",
            "d_loss_wrong:0.7010840773582458\n",
            "d_loss:0.5945949107408524\n",
            "g_loss:[0.44862726, 0.4388274, 0.0048999344]\n",
            "Batch:71\n",
            "d_loss_real:0.8864036202430725\n",
            "d_loss_fake:0.0036450638435781\n",
            "d_loss_wrong:0.6329417824745178\n",
            "d_loss:0.6023485213518143\n",
            "g_loss:[0.49839553, 0.49057043, 0.0039125476]\n",
            "Batch:72\n",
            "d_loss_real:0.9021264910697937\n",
            "d_loss_fake:0.002702507423236966\n",
            "d_loss_wrong:0.6505549550056458\n",
            "d_loss:0.6143776178359985\n",
            "g_loss:[0.45408368, 0.44746307, 0.003310307]\n",
            "Batch:73\n",
            "d_loss_real:0.8780739903450012\n",
            "d_loss_fake:0.0034212765749543905\n",
            "d_loss_wrong:0.6585240364074707\n",
            "d_loss:0.604523316025734\n",
            "g_loss:[0.39931738, 0.39330012, 0.0030086306]\n",
            "Batch:74\n",
            "d_loss_real:0.9019096493721008\n",
            "d_loss_fake:0.0024507674388587475\n",
            "d_loss_wrong:0.6852601170539856\n",
            "d_loss:0.6228825449943542\n",
            "g_loss:[0.37413076, 0.36761174, 0.0032595163]\n",
            "Batch:75\n",
            "d_loss_real:0.8826881647109985\n",
            "d_loss_fake:0.004258249886333942\n",
            "d_loss_wrong:0.6876434683799744\n",
            "d_loss:0.6143195182085037\n",
            "g_loss:[0.437346, 0.4305915, 0.0033772574]\n",
            "Batch:76\n",
            "d_loss_real:0.8833826184272766\n",
            "d_loss_fake:0.0030058659613132477\n",
            "d_loss_wrong:0.6679080128669739\n",
            "d_loss:0.6094197779893875\n",
            "g_loss:[0.38161924, 0.3747298, 0.0034447191]\n",
            "Batch:77\n",
            "d_loss_real:0.8657582998275757\n",
            "d_loss_fake:0.004999361466616392\n",
            "d_loss_wrong:0.6881042718887329\n",
            "d_loss:0.606155052781105\n",
            "g_loss:[0.42696822, 0.42072982, 0.0031192019]\n",
            "Batch:78\n",
            "d_loss_real:0.8722670078277588\n",
            "d_loss_fake:0.0057756779715418816\n",
            "d_loss_wrong:0.6662867665290833\n",
            "d_loss:0.604149118065834\n",
            "g_loss:[0.50323415, 0.4966417, 0.003296239]\n",
            "Batch:79\n",
            "d_loss_real:0.8701345920562744\n",
            "d_loss_fake:0.001571904867887497\n",
            "d_loss_wrong:0.6656570434570312\n",
            "d_loss:0.6018745303153992\n",
            "g_loss:[0.5108167, 0.5032255, 0.0037955926]\n",
            "Batch:80\n",
            "d_loss_real:0.8534352779388428\n",
            "d_loss_fake:0.0014830122236162424\n",
            "d_loss_wrong:0.6736591458320618\n",
            "d_loss:0.595503181219101\n",
            "g_loss:[0.4327232, 0.4269355, 0.0028938511]\n",
            "Batch:81\n",
            "d_loss_real:0.863616943359375\n",
            "d_loss_fake:0.001857328461483121\n",
            "d_loss_wrong:0.6426558494567871\n",
            "d_loss:0.5929367691278458\n",
            "g_loss:[0.36392137, 0.355622, 0.0041496893]\n",
            "Batch:82\n",
            "d_loss_real:0.9401761293411255\n",
            "d_loss_fake:0.0016794269904494286\n",
            "d_loss_wrong:0.6674796938896179\n",
            "d_loss:0.6373778432607651\n",
            "g_loss:[0.43867454, 0.43293232, 0.0028711157]\n",
            "Batch:83\n",
            "d_loss_real:0.8048056364059448\n",
            "d_loss_fake:0.005810312461107969\n",
            "d_loss_wrong:0.6864972710609436\n",
            "d_loss:0.5754797160625458\n",
            "g_loss:[0.44312206, 0.43729556, 0.0029132478]\n",
            "Batch:84\n",
            "d_loss_real:0.8539865016937256\n",
            "d_loss_fake:0.0009361310512758791\n",
            "d_loss_wrong:0.6905649304389954\n",
            "d_loss:0.5998685210943222\n",
            "g_loss:[0.5926948, 0.5860691, 0.003312862]\n",
            "Batch:85\n",
            "d_loss_real:0.863221287727356\n",
            "d_loss_fake:0.00744167435914278\n",
            "d_loss_wrong:0.6622728705406189\n",
            "d_loss:0.5990392863750458\n",
            "g_loss:[0.74948585, 0.74347377, 0.0030060392]\n",
            "Batch:86\n",
            "d_loss_real:0.8588806390762329\n",
            "d_loss_fake:0.0013348149368539453\n",
            "d_loss_wrong:0.6599498987197876\n",
            "d_loss:0.5947614908218384\n",
            "g_loss:[0.48862156, 0.48341876, 0.0026013996]\n",
            "Batch:87\n",
            "d_loss_real:0.8615782856941223\n",
            "d_loss_fake:0.0011215938720852137\n",
            "d_loss_wrong:0.6595908999443054\n",
            "d_loss:0.5959672629833221\n",
            "g_loss:[0.5349093, 0.5270616, 0.003923854]\n",
            "Batch:88\n",
            "d_loss_real:0.8904374837875366\n",
            "d_loss_fake:0.009392119944095612\n",
            "d_loss_wrong:0.6643696427345276\n",
            "d_loss:0.6136591881513596\n",
            "g_loss:[0.77230775, 0.763916, 0.0041958643]\n",
            "Batch:89\n",
            "d_loss_real:0.8949536085128784\n",
            "d_loss_fake:0.002591026248410344\n",
            "d_loss_wrong:0.7421761155128479\n",
            "d_loss:0.6336685866117477\n",
            "g_loss:[1.0450025, 1.034675, 0.005163717]\n",
            "Batch:90\n",
            "d_loss_real:0.857978343963623\n",
            "d_loss_fake:0.015033531934022903\n",
            "d_loss_wrong:0.6910301446914673\n",
            "d_loss:0.6055050939321518\n",
            "g_loss:[1.433188, 1.4239838, 0.0046021007]\n",
            "Batch:91\n",
            "d_loss_real:0.8624781966209412\n",
            "d_loss_fake:0.01618005707859993\n",
            "d_loss_wrong:0.6803681254386902\n",
            "d_loss:0.6053761392831802\n",
            "g_loss:[1.961406, 1.9539745, 0.0037157238]\n",
            "Batch:92\n",
            "d_loss_real:0.9439007639884949\n",
            "d_loss_fake:0.08748830854892731\n",
            "d_loss_wrong:0.6620387434959412\n",
            "d_loss:0.6593321412801743\n",
            "g_loss:[4.4764247, 4.4675856, 0.004419541]\n",
            "Batch:93\n",
            "d_loss_real:1.0612964630126953\n",
            "d_loss_fake:0.026651471853256226\n",
            "d_loss_wrong:0.7042704820632935\n",
            "d_loss:0.7133787274360657\n",
            "g_loss:[2.9513566, 2.9414337, 0.0049615065]\n",
            "Batch:94\n",
            "d_loss_real:0.8743050694465637\n",
            "d_loss_fake:0.07393791526556015\n",
            "d_loss_wrong:0.6558936238288879\n",
            "d_loss:0.6196104139089584\n",
            "g_loss:[4.8902607, 4.8807106, 0.0047751637]\n",
            "Batch:95\n",
            "d_loss_real:0.9384217858314514\n",
            "d_loss_fake:0.009103575721383095\n",
            "d_loss_wrong:0.6320258378982544\n",
            "d_loss:0.6294932514429092\n",
            "g_loss:[3.3552277, 3.3466787, 0.0042744433]\n",
            "Batch:96\n",
            "d_loss_real:0.8554301261901855\n",
            "d_loss_fake:0.032327763736248016\n",
            "d_loss_wrong:0.6577906608581543\n",
            "d_loss:0.6002446711063385\n",
            "g_loss:[3.473187, 3.4630482, 0.005069417]\n",
            "Batch:97\n",
            "d_loss_real:0.8997468948364258\n",
            "d_loss_fake:0.00543899554759264\n",
            "d_loss_wrong:0.6716031432151794\n",
            "d_loss:0.6191339790821075\n",
            "g_loss:[2.6168492, 2.607574, 0.0046375873]\n",
            "Batch:98\n",
            "d_loss_real:0.9135411381721497\n",
            "d_loss_fake:0.03640582412481308\n",
            "d_loss_wrong:0.6680931448936462\n",
            "d_loss:0.6328953057527542\n",
            "g_loss:[3.1127768, 3.1031284, 0.0048241895]\n",
            "Batch:99\n",
            "d_loss_real:0.8981382846832275\n",
            "d_loss_fake:0.02382798120379448\n",
            "d_loss_wrong:0.6669563055038452\n",
            "d_loss:0.621765211224556\n",
            "g_loss:[2.845742, 2.8370714, 0.0043353336]\n",
            "Batch:100\n",
            "d_loss_real:0.9375622272491455\n",
            "d_loss_fake:0.05182841792702675\n",
            "d_loss_wrong:0.6323792934417725\n",
            "d_loss:0.6398330479860306\n",
            "g_loss:[2.713136, 2.706153, 0.0034915414]\n",
            "Batch:101\n",
            "d_loss_real:0.9267767071723938\n",
            "d_loss_fake:0.012937743216753006\n",
            "d_loss_wrong:0.6562842726707458\n",
            "d_loss:0.6306938529014587\n",
            "g_loss:[2.566095, 2.5590427, 0.0035261926]\n",
            "Batch:102\n",
            "d_loss_real:0.927074670791626\n",
            "d_loss_fake:0.018207885324954987\n",
            "d_loss_wrong:0.7089517116546631\n",
            "d_loss:0.645327240228653\n",
            "g_loss:[2.1118205, 2.1049676, 0.0034263972]\n",
            "Batch:103\n",
            "d_loss_real:0.9909116625785828\n",
            "d_loss_fake:0.05463869497179985\n",
            "d_loss_wrong:0.6014989614486694\n",
            "d_loss:0.659490242600441\n",
            "g_loss:[2.6590798, 2.652947, 0.0030664455]\n",
            "Batch:104\n",
            "d_loss_real:0.9755381345748901\n",
            "d_loss_fake:0.031907618045806885\n",
            "d_loss_wrong:0.6939541697502136\n",
            "d_loss:0.6692345142364502\n",
            "g_loss:[2.1242092, 2.1183448, 0.0029322435]\n",
            "Batch:105\n",
            "d_loss_real:0.9455625414848328\n",
            "d_loss_fake:0.16080111265182495\n",
            "d_loss_wrong:0.6580564379692078\n",
            "d_loss:0.6774956583976746\n",
            "g_loss:[4.2525396, 4.247816, 0.00236182]\n",
            "Batch:106\n",
            "d_loss_real:0.9379487037658691\n",
            "d_loss_fake:0.02129746973514557\n",
            "d_loss_wrong:0.6003824472427368\n",
            "d_loss:0.6243943274021149\n",
            "g_loss:[3.7887673, 3.783277, 0.002745193]\n",
            "Batch:107\n",
            "d_loss_real:1.1216108798980713\n",
            "d_loss_fake:0.10419090837240219\n",
            "d_loss_wrong:0.6246812343597412\n",
            "d_loss:0.743023470044136\n",
            "g_loss:[3.5689125, 3.5636096, 0.0026514705]\n",
            "Batch:108\n",
            "d_loss_real:0.9991158843040466\n",
            "d_loss_fake:0.05517156422138214\n",
            "d_loss_wrong:0.6312224268913269\n",
            "d_loss:0.6711564362049103\n",
            "g_loss:[3.922819, 3.9176364, 0.0025912013]\n",
            "Batch:109\n",
            "d_loss_real:0.9429892897605896\n",
            "d_loss_fake:0.020844124257564545\n",
            "d_loss_wrong:0.683213472366333\n",
            "d_loss:0.6475090384483337\n",
            "g_loss:[3.3760142, 3.3692908, 0.0033616596]\n",
            "Batch:110\n",
            "d_loss_real:0.9199040532112122\n",
            "d_loss_fake:0.13488760590553284\n",
            "d_loss_wrong:0.6270868182182312\n",
            "d_loss:0.6504456400871277\n",
            "g_loss:[2.3235252, 2.316298, 0.0036136368]\n",
            "Batch:111\n",
            "d_loss_real:1.1065044403076172\n",
            "d_loss_fake:0.23825794458389282\n",
            "d_loss_wrong:0.6218428611755371\n",
            "d_loss:0.7682774215936661\n",
            "g_loss:[1.7940166, 1.7871807, 0.0034179837]\n",
            "Batch:112\n",
            "d_loss_real:0.9404231309890747\n",
            "d_loss_fake:0.0028509609401226044\n",
            "d_loss_wrong:0.7204226851463318\n",
            "d_loss:0.6510299742221832\n",
            "g_loss:[1.6131654, 1.6057782, 0.0036935867]\n",
            "Batch:113\n",
            "d_loss_real:0.9569125175476074\n",
            "d_loss_fake:0.004510232247412205\n",
            "d_loss_wrong:0.6532126665115356\n",
            "d_loss:0.6428869813680649\n",
            "g_loss:[1.6531578, 1.6442859, 0.0044359593]\n",
            "Batch:114\n",
            "d_loss_real:0.9036123752593994\n",
            "d_loss_fake:0.003589087864384055\n",
            "d_loss_wrong:0.6446250081062317\n",
            "d_loss:0.6138597130775452\n",
            "g_loss:[1.4485611, 1.4411364, 0.0037123705]\n",
            "Batch:115\n",
            "d_loss_real:0.914316713809967\n",
            "d_loss_fake:0.05016211420297623\n",
            "d_loss_wrong:0.6506631970405579\n",
            "d_loss:0.6323646903038025\n",
            "g_loss:[1.431106, 1.423216, 0.0039449753]\n",
            "Batch:116\n",
            "d_loss_real:0.9648231267929077\n",
            "d_loss_fake:0.010157419368624687\n",
            "d_loss_wrong:0.6776524186134338\n",
            "d_loss:0.6543640196323395\n",
            "g_loss:[1.4200411, 1.4125954, 0.0037228635]\n",
            "Batch:117\n",
            "d_loss_real:0.9539152383804321\n",
            "d_loss_fake:0.009575625881552696\n",
            "d_loss_wrong:0.6486266851425171\n",
            "d_loss:0.6415081918239594\n",
            "g_loss:[1.3863903, 1.3794847, 0.0034528081]\n",
            "Batch:118\n",
            "d_loss_real:0.8658620119094849\n",
            "d_loss_fake:0.0414862260222435\n",
            "d_loss_wrong:0.6668902039527893\n",
            "d_loss:0.6100251078605652\n",
            "g_loss:[1.1777612, 1.1694978, 0.0041316645]\n",
            "Batch:119\n",
            "d_loss_real:0.9364295601844788\n",
            "d_loss_fake:0.009470917284488678\n",
            "d_loss_wrong:0.6564704775810242\n",
            "d_loss:0.634700134396553\n",
            "g_loss:[1.5836706, 1.577813, 0.0029287897]\n",
            "Batch:120\n",
            "d_loss_real:0.9140179753303528\n",
            "d_loss_fake:0.015447968617081642\n",
            "d_loss_wrong:0.6462028622627258\n",
            "d_loss:0.6224216967821121\n",
            "g_loss:[1.396736, 1.3885893, 0.004073404]\n",
            "Batch:121\n",
            "d_loss_real:0.9439980983734131\n",
            "d_loss_fake:0.03110041841864586\n",
            "d_loss_wrong:0.7104170322418213\n",
            "d_loss:0.6573784053325653\n",
            "g_loss:[1.1230031, 1.1137137, 0.0046446896]\n",
            "Batch:122\n",
            "d_loss_real:0.8688274621963501\n",
            "d_loss_fake:0.034599363803863525\n",
            "d_loss_wrong:0.674845278263092\n",
            "d_loss:0.6117748916149139\n",
            "g_loss:[1.3118229, 1.3004678, 0.005677494]\n",
            "Batch:123\n",
            "d_loss_real:1.0426716804504395\n",
            "d_loss_fake:0.08936533331871033\n",
            "d_loss_wrong:0.7951184511184692\n",
            "d_loss:0.7424567937850952\n",
            "g_loss:[1.0698165, 1.0623636, 0.0037264084]\n",
            "Batch:124\n",
            "d_loss_real:1.007007360458374\n",
            "d_loss_fake:0.10932644456624985\n",
            "d_loss_wrong:0.5571518540382385\n",
            "d_loss:0.6701232492923737\n",
            "g_loss:[1.9155363, 1.9079323, 0.0038020094]\n",
            "Batch:125\n",
            "d_loss_real:0.925724983215332\n",
            "d_loss_fake:0.03505820035934448\n",
            "d_loss_wrong:0.6382417678833008\n",
            "d_loss:0.6311874836683273\n",
            "g_loss:[1.6275302, 1.6160293, 0.0057504745]\n",
            "Batch:126\n",
            "d_loss_real:0.9349916577339172\n",
            "d_loss_fake:0.1295938938856125\n",
            "d_loss_wrong:0.6476961374282837\n",
            "d_loss:0.661818340420723\n",
            "g_loss:[2.914159, 2.9008284, 0.0066653867]\n",
            "Batch:127\n",
            "d_loss_real:1.2307140827178955\n",
            "d_loss_fake:0.13558343052864075\n",
            "d_loss_wrong:0.6491479873657227\n",
            "d_loss:0.811539888381958\n",
            "g_loss:[2.4274995, 2.4177027, 0.004898371]\n",
            "Batch:128\n",
            "d_loss_real:1.1612119674682617\n",
            "d_loss_fake:0.0650898888707161\n",
            "d_loss_wrong:0.5828676223754883\n",
            "d_loss:0.7425953596830368\n",
            "g_loss:[2.1982892, 2.1888428, 0.004723207]\n",
            "Batch:129\n",
            "d_loss_real:0.9956498146057129\n",
            "d_loss_fake:0.1281883418560028\n",
            "d_loss_wrong:0.661912202835083\n",
            "d_loss:0.6953500509262085\n",
            "g_loss:[2.7643092, 2.7557094, 0.004299908]\n",
            "Batch:130\n",
            "d_loss_real:1.0498905181884766\n",
            "d_loss_fake:0.19303929805755615\n",
            "d_loss_wrong:0.5655206441879272\n",
            "d_loss:0.7145852446556091\n",
            "g_loss:[2.799002, 2.7912302, 0.0038858526]\n",
            "Batch:131\n",
            "d_loss_real:1.2179316282272339\n",
            "d_loss_fake:0.15514276921749115\n",
            "d_loss_wrong:0.6844020485877991\n",
            "d_loss:0.8188520222902298\n",
            "g_loss:[2.37914, 2.3711426, 0.0039986167]\n",
            "Batch:132\n",
            "d_loss_real:1.026338815689087\n",
            "d_loss_fake:0.16050520539283752\n",
            "d_loss_wrong:0.580800473690033\n",
            "d_loss:0.6984958350658417\n",
            "g_loss:[2.7498875, 2.7413158, 0.004285798]\n",
            "Batch:133\n",
            "d_loss_real:1.0081164836883545\n",
            "d_loss_fake:0.2969561517238617\n",
            "d_loss_wrong:0.5612781643867493\n",
            "d_loss:0.7186168134212494\n",
            "g_loss:[2.6919734, 2.6857758, 0.0030988543]\n",
            "Batch:134\n",
            "d_loss_real:1.078946828842163\n",
            "d_loss_fake:0.10147208720445633\n",
            "d_loss_wrong:0.5793441534042358\n",
            "d_loss:0.7096774727106094\n",
            "g_loss:[2.9783928, 2.9715445, 0.0034241658]\n",
            "Batch:135\n",
            "d_loss_real:1.1429102420806885\n",
            "d_loss_fake:0.15859921276569366\n",
            "d_loss_wrong:0.6081365942955017\n",
            "d_loss:0.7631390690803528\n",
            "g_loss:[2.5167193, 2.510925, 0.0028971813]\n",
            "Batch:136\n",
            "d_loss_real:1.0387052297592163\n",
            "d_loss_fake:0.17747828364372253\n",
            "d_loss_wrong:0.5814558267593384\n",
            "d_loss:0.709086149930954\n",
            "g_loss:[2.8522265, 2.846607, 0.0028098207]\n",
            "Batch:137\n",
            "d_loss_real:1.1292004585266113\n",
            "d_loss_fake:0.1852300465106964\n",
            "d_loss_wrong:0.5408138036727905\n",
            "d_loss:0.7461111843585968\n",
            "g_loss:[2.4546328, 2.4495232, 0.0025547151]\n",
            "Batch:138\n",
            "d_loss_real:1.1611555814743042\n",
            "d_loss_fake:0.13027723133563995\n",
            "d_loss_wrong:0.6085084080696106\n",
            "d_loss:0.7652741968631744\n",
            "g_loss:[2.7275548, 2.7202606, 0.003647071]\n",
            "========================================\n",
            "Epoch is: 2\n",
            "Number of batches 138\n",
            "Batch:1\n",
            "d_loss_real:1.0832173824310303\n",
            "d_loss_fake:0.22203750908374786\n",
            "d_loss_wrong:0.5668540596961975\n",
            "d_loss:0.7388315796852112\n",
            "g_loss:[2.3075492, 2.301191, 0.0031790726]\n",
            "Batch:2\n",
            "d_loss_real:1.141898512840271\n",
            "d_loss_fake:0.2359711229801178\n",
            "d_loss_wrong:0.519357442855835\n",
            "d_loss:0.7597813904285431\n",
            "g_loss:[2.9832792, 2.9753723, 0.003953401]\n",
            "Batch:3\n",
            "d_loss_real:1.1337001323699951\n",
            "d_loss_fake:0.13499346375465393\n",
            "d_loss_wrong:0.5727668404579163\n",
            "d_loss:0.7437901496887207\n",
            "g_loss:[2.6232984, 2.6155763, 0.0038610601]\n",
            "Batch:4\n",
            "d_loss_real:1.1612839698791504\n",
            "d_loss_fake:0.10970117896795273\n",
            "d_loss_wrong:0.7974514365196228\n",
            "d_loss:0.8074301332235336\n",
            "g_loss:[2.3589554, 2.3517737, 0.0035908215]\n",
            "Batch:5\n",
            "d_loss_real:1.0057634115219116\n",
            "d_loss_fake:0.16936632990837097\n",
            "d_loss_wrong:0.8175173997879028\n",
            "d_loss:0.7496026456356049\n",
            "g_loss:[2.4867966, 2.4805393, 0.0031286173]\n",
            "Batch:6\n",
            "d_loss_real:1.0633289813995361\n",
            "d_loss_fake:0.11309891194105148\n",
            "d_loss_wrong:0.8067435622215271\n",
            "d_loss:0.7616251111030579\n",
            "g_loss:[2.5290425, 2.52221, 0.0034163203]\n",
            "Batch:7\n",
            "d_loss_real:1.0458475351333618\n",
            "d_loss_fake:0.1258372962474823\n",
            "d_loss_wrong:0.5963989496231079\n",
            "d_loss:0.7034828364849091\n",
            "g_loss:[2.2822332, 2.2764165, 0.002908397]\n",
            "Batch:8\n",
            "d_loss_real:1.1603004932403564\n",
            "d_loss_fake:0.11707186698913574\n",
            "d_loss_wrong:0.5026344060897827\n",
            "d_loss:0.7350768148899078\n",
            "g_loss:[2.3808615, 2.3722916, 0.004285026]\n",
            "Batch:9\n",
            "d_loss_real:1.0994232892990112\n",
            "d_loss_fake:0.11729203909635544\n",
            "d_loss_wrong:0.6167917251586914\n",
            "d_loss:0.7332325875759125\n",
            "g_loss:[2.01589, 2.003859, 0.006015433]\n",
            "Batch:10\n",
            "d_loss_real:1.0388352870941162\n",
            "d_loss_fake:0.1044543981552124\n",
            "d_loss_wrong:0.601671040058136\n",
            "d_loss:0.6959490031003952\n",
            "g_loss:[2.1862128, 2.1763477, 0.0049324865]\n",
            "Batch:11\n",
            "d_loss_real:1.096196174621582\n",
            "d_loss_fake:0.12796665728092194\n",
            "d_loss_wrong:0.5835169553756714\n",
            "d_loss:0.725968986749649\n",
            "g_loss:[2.4594753, 2.4532816, 0.003096782]\n",
            "Batch:12\n",
            "d_loss_real:1.200721263885498\n",
            "d_loss_fake:0.10045383870601654\n",
            "d_loss_wrong:0.5482758283615112\n",
            "d_loss:0.7625430524349213\n",
            "g_loss:[1.942384, 1.9369655, 0.002709289]\n",
            "Batch:13\n",
            "d_loss_real:1.102617859840393\n",
            "d_loss_fake:0.22826239466667175\n",
            "d_loss_wrong:0.5588712096214294\n",
            "d_loss:0.7480923235416412\n",
            "g_loss:[2.2565682, 2.2512784, 0.0026448513]\n",
            "Batch:14\n",
            "d_loss_real:1.2491683959960938\n",
            "d_loss_fake:0.11039181053638458\n",
            "d_loss_wrong:0.554606020450592\n",
            "d_loss:0.7908336520195007\n",
            "g_loss:[2.0626712, 2.0577967, 0.0024372004]\n",
            "Batch:15\n",
            "d_loss_real:1.0236756801605225\n",
            "d_loss_fake:0.2779867947101593\n",
            "d_loss_wrong:0.698185384273529\n",
            "d_loss:0.7558808922767639\n",
            "g_loss:[1.5403485, 1.5328118, 0.003768413]\n",
            "Batch:16\n",
            "d_loss_real:1.0721328258514404\n",
            "d_loss_fake:0.1747509241104126\n",
            "d_loss_wrong:0.6753572821617126\n",
            "d_loss:0.7485934644937515\n",
            "g_loss:[1.785875, 1.778448, 0.0037134876]\n",
            "Batch:17\n",
            "d_loss_real:1.0924293994903564\n",
            "d_loss_fake:0.06806299090385437\n",
            "d_loss_wrong:0.7880139946937561\n",
            "d_loss:0.7602339386940002\n",
            "g_loss:[1.9630765, 1.9543941, 0.00434117]\n",
            "Batch:18\n",
            "d_loss_real:1.0420246124267578\n",
            "d_loss_fake:0.03186887875199318\n",
            "d_loss_wrong:0.6265714168548584\n",
            "d_loss:0.6856223791837692\n",
            "g_loss:[1.7125736, 1.7066587, 0.0029574486]\n",
            "Batch:19\n",
            "d_loss_real:1.0067695379257202\n",
            "d_loss_fake:0.05218715965747833\n",
            "d_loss_wrong:0.645327091217041\n",
            "d_loss:0.6777633279561996\n",
            "g_loss:[1.8560052, 1.8500947, 0.002955248]\n",
            "Batch:20\n",
            "d_loss_real:1.1497093439102173\n",
            "d_loss_fake:0.0619477741420269\n",
            "d_loss_wrong:0.6262474656105042\n",
            "d_loss:0.7469034790992737\n",
            "g_loss:[1.967401, 1.9605936, 0.0034036958]\n",
            "Batch:21\n",
            "d_loss_real:1.0920395851135254\n",
            "d_loss_fake:0.024662215262651443\n",
            "d_loss_wrong:0.5803787112236023\n",
            "d_loss:0.6972800195217133\n",
            "g_loss:[1.8777714, 1.8724117, 0.002679796]\n",
            "Batch:22\n",
            "d_loss_real:1.0076160430908203\n",
            "d_loss_fake:0.030100777745246887\n",
            "d_loss_wrong:0.685462236404419\n",
            "d_loss:0.6826987713575363\n",
            "g_loss:[2.2285082, 2.224321, 0.002093682]\n",
            "Batch:23\n",
            "d_loss_real:0.9783304929733276\n",
            "d_loss_fake:0.05100052058696747\n",
            "d_loss_wrong:0.6751431822776794\n",
            "d_loss:0.6707011759281158\n",
            "g_loss:[2.0650034, 2.0601075, 0.0024479576]\n",
            "Batch:24\n",
            "d_loss_real:0.873997688293457\n",
            "d_loss_fake:0.09253474324941635\n",
            "d_loss_wrong:0.6617392897605896\n",
            "d_loss:0.6255673468112946\n",
            "g_loss:[2.0269632, 2.0196624, 0.0036504809]\n",
            "Batch:25\n",
            "d_loss_real:1.0764683485031128\n",
            "d_loss_fake:0.03493286669254303\n",
            "d_loss_wrong:0.6404803991317749\n",
            "d_loss:0.7070874869823456\n",
            "g_loss:[1.6947092, 1.6870122, 0.003848505]\n",
            "Batch:26\n",
            "d_loss_real:1.026084065437317\n",
            "d_loss_fake:0.09520436078310013\n",
            "d_loss_wrong:0.689434826374054\n",
            "d_loss:0.7092018276453018\n",
            "g_loss:[1.7797987, 1.7743181, 0.0027403298]\n",
            "Batch:27\n",
            "d_loss_real:1.1207128763198853\n",
            "d_loss_fake:0.08157677948474884\n",
            "d_loss_wrong:0.661457359790802\n",
            "d_loss:0.74611496925354\n",
            "g_loss:[2.636423, 2.6305323, 0.0029454662]\n",
            "Batch:28\n",
            "d_loss_real:0.9560943245887756\n",
            "d_loss_fake:0.11169786006212234\n",
            "d_loss_wrong:0.6911149024963379\n",
            "d_loss:0.6787503510713577\n",
            "g_loss:[2.2151935, 2.2067769, 0.0042082816]\n",
            "Batch:29\n",
            "d_loss_real:0.9353941679000854\n",
            "d_loss_fake:0.32123398780822754\n",
            "d_loss_wrong:0.5673062801361084\n",
            "d_loss:0.6898321509361267\n",
            "g_loss:[2.395801, 2.387755, 0.0040230327]\n",
            "Batch:30\n",
            "d_loss_real:1.221971869468689\n",
            "d_loss_fake:0.11814143508672714\n",
            "d_loss_wrong:0.6763676404953003\n",
            "d_loss:0.8096131980419159\n",
            "g_loss:[2.2254486, 2.215577, 0.004935865]\n",
            "Batch:31\n",
            "d_loss_real:1.0172929763793945\n",
            "d_loss_fake:0.09871871769428253\n",
            "d_loss_wrong:0.625569760799408\n",
            "d_loss:0.6897186040878296\n",
            "g_loss:[1.6617917, 1.6530612, 0.0043652738]\n",
            "Batch:32\n",
            "d_loss_real:1.1900792121887207\n",
            "d_loss_fake:0.18343579769134521\n",
            "d_loss_wrong:0.6007713675498962\n",
            "d_loss:0.7910913974046707\n",
            "g_loss:[1.7411132, 1.732732, 0.004190564]\n",
            "Batch:33\n",
            "d_loss_real:0.9441672563552856\n",
            "d_loss_fake:0.16029071807861328\n",
            "d_loss_wrong:0.6051645278930664\n",
            "d_loss:0.6634474396705627\n",
            "g_loss:[2.072892, 2.0653124, 0.003789783]\n",
            "Batch:34\n",
            "d_loss_real:1.0353758335113525\n",
            "d_loss_fake:0.07817814499139786\n",
            "d_loss_wrong:0.5449738502502441\n",
            "d_loss:0.6734759211540222\n",
            "g_loss:[2.0115302, 2.0042791, 0.003625473]\n",
            "Batch:35\n",
            "d_loss_real:1.0586570501327515\n",
            "d_loss_fake:0.059842608869075775\n",
            "d_loss_wrong:0.6236361265182495\n",
            "d_loss:0.7001982033252716\n",
            "g_loss:[2.1055362, 2.098495, 0.0035205572]\n",
            "Batch:36\n",
            "d_loss_real:1.0106287002563477\n",
            "d_loss_fake:0.12683619558811188\n",
            "d_loss_wrong:0.6240617036819458\n",
            "d_loss:0.693038821220398\n",
            "g_loss:[2.0534253, 2.0459363, 0.003744435]\n",
            "Batch:37\n",
            "d_loss_real:0.9460346698760986\n",
            "d_loss_fake:0.033733829855918884\n",
            "d_loss_wrong:0.6647708415985107\n",
            "d_loss:0.647643506526947\n",
            "g_loss:[2.0855112, 2.0783567, 0.0035772596]\n",
            "Batch:38\n",
            "d_loss_real:1.0658338069915771\n",
            "d_loss_fake:0.10834753513336182\n",
            "d_loss_wrong:0.6476660966873169\n",
            "d_loss:0.7219203114509583\n",
            "g_loss:[1.9341452, 1.9277978, 0.0031736805]\n",
            "Batch:39\n",
            "d_loss_real:1.0258820056915283\n",
            "d_loss_fake:0.09697186946868896\n",
            "d_loss_wrong:0.5965415239334106\n",
            "d_loss:0.6863193511962891\n",
            "g_loss:[1.7431792, 1.7361239, 0.0035276604]\n",
            "Batch:40\n",
            "d_loss_real:1.0098035335540771\n",
            "d_loss_fake:0.08623485267162323\n",
            "d_loss_wrong:0.6971745491027832\n",
            "d_loss:0.7007541209459305\n",
            "g_loss:[2.3717308, 2.3653758, 0.003177531]\n",
            "Batch:41\n",
            "d_loss_real:1.0356481075286865\n",
            "d_loss_fake:0.08824896812438965\n",
            "d_loss_wrong:0.589020848274231\n",
            "d_loss:0.6871415078639984\n",
            "g_loss:[1.944806, 1.9373654, 0.003720263]\n",
            "Batch:42\n",
            "d_loss_real:1.0851027965545654\n",
            "d_loss_fake:0.10411003232002258\n",
            "d_loss_wrong:0.5824987292289734\n",
            "d_loss:0.7142035961151123\n",
            "g_loss:[2.528037, 2.5210452, 0.0034959659]\n",
            "Batch:43\n",
            "d_loss_real:0.973995566368103\n",
            "d_loss_fake:0.1556432992219925\n",
            "d_loss_wrong:0.5940505862236023\n",
            "d_loss:0.6744212508201599\n",
            "g_loss:[2.7180624, 2.7122374, 0.0029124767]\n",
            "Batch:44\n",
            "d_loss_real:0.9142478704452515\n",
            "d_loss_fake:0.06512598693370819\n",
            "d_loss_wrong:0.6270172595977783\n",
            "d_loss:0.6301597505807877\n",
            "g_loss:[2.7145367, 2.708383, 0.0030767887]\n",
            "Batch:45\n",
            "d_loss_real:0.9527861475944519\n",
            "d_loss_fake:0.05247309058904648\n",
            "d_loss_wrong:0.6226311326026917\n",
            "d_loss:0.645169124007225\n",
            "g_loss:[2.5261614, 2.5190773, 0.0035420395]\n",
            "Batch:46\n",
            "d_loss_real:0.9752840995788574\n",
            "d_loss_fake:0.03767292946577072\n",
            "d_loss_wrong:0.6269206404685974\n",
            "d_loss:0.6537904441356659\n",
            "g_loss:[2.6182616, 2.6118417, 0.0032099506]\n",
            "Batch:47\n",
            "d_loss_real:0.9477853775024414\n",
            "d_loss_fake:0.05815083160996437\n",
            "d_loss_wrong:0.6369431614875793\n",
            "d_loss:0.6476661860942841\n",
            "g_loss:[2.7481854, 2.7408037, 0.0036908297]\n",
            "Batch:48\n",
            "d_loss_real:1.0068154335021973\n",
            "d_loss_fake:0.0306985042989254\n",
            "d_loss_wrong:0.6518869996070862\n",
            "d_loss:0.6740540862083435\n",
            "g_loss:[2.4903853, 2.484219, 0.0030830815]\n",
            "Batch:49\n",
            "d_loss_real:0.9333444833755493\n",
            "d_loss_fake:0.02999202162027359\n",
            "d_loss_wrong:0.6359115839004517\n",
            "d_loss:0.6331481486558914\n",
            "g_loss:[2.2998571, 2.2934082, 0.0032244902]\n",
            "Batch:50\n",
            "d_loss_real:1.0144109725952148\n",
            "d_loss_fake:0.04206119105219841\n",
            "d_loss_wrong:0.6671536564826965\n",
            "d_loss:0.684509202837944\n",
            "g_loss:[2.5122159, 2.507465, 0.002375463]\n",
            "Batch:51\n",
            "d_loss_real:1.004064679145813\n",
            "d_loss_fake:0.042260635644197464\n",
            "d_loss_wrong:0.6838617324829102\n",
            "d_loss:0.6835629343986511\n",
            "g_loss:[2.8749464, 2.8703382, 0.0023040685]\n",
            "Batch:52\n",
            "d_loss_real:0.9818494319915771\n",
            "d_loss_fake:0.04018738493323326\n",
            "d_loss_wrong:0.7339258193969727\n",
            "d_loss:0.684453010559082\n",
            "g_loss:[3.2727897, 3.2694638, 0.0016630001]\n",
            "Batch:53\n",
            "d_loss_real:0.8242607116699219\n",
            "d_loss_fake:0.017218079417943954\n",
            "d_loss_wrong:0.717880368232727\n",
            "d_loss:0.5959049612283707\n",
            "g_loss:[2.9993002, 2.9939046, 0.0026978073]\n",
            "Batch:54\n",
            "d_loss_real:0.896521806716919\n",
            "d_loss_fake:0.04723336547613144\n",
            "d_loss_wrong:0.744054913520813\n",
            "d_loss:0.6460829675197601\n",
            "g_loss:[3.2552943, 3.250252, 0.0025211535]\n",
            "Batch:55\n",
            "d_loss_real:0.9006286859512329\n",
            "d_loss_fake:0.06805222481489182\n",
            "d_loss_wrong:0.6424610614776611\n",
            "d_loss:0.6279426664113998\n",
            "g_loss:[2.9676335, 2.962029, 0.002802217]\n",
            "Batch:56\n",
            "d_loss_real:1.186711072921753\n",
            "d_loss_fake:0.20921742916107178\n",
            "d_loss_wrong:0.6834558248519897\n",
            "d_loss:0.8165238499641418\n",
            "g_loss:[1.938714, 1.9328983, 0.002907888]\n",
            "Batch:57\n",
            "d_loss_real:0.9357624053955078\n",
            "d_loss_fake:0.1620280146598816\n",
            "d_loss_wrong:0.6035547256469727\n",
            "d_loss:0.6592768877744675\n",
            "g_loss:[1.9604048, 1.9541914, 0.0031066497]\n",
            "Batch:58\n",
            "d_loss_real:1.0865222215652466\n",
            "d_loss_fake:0.13160917162895203\n",
            "d_loss_wrong:0.5529173612594604\n",
            "d_loss:0.714392751455307\n",
            "g_loss:[1.8046232, 1.7991145, 0.0027543711]\n",
            "Batch:59\n",
            "d_loss_real:1.065704107284546\n",
            "d_loss_fake:0.16660553216934204\n",
            "d_loss_wrong:0.5948205590248108\n",
            "d_loss:0.7232085764408112\n",
            "g_loss:[1.9415165, 1.9359226, 0.0027969603]\n",
            "Batch:60\n",
            "d_loss_real:1.0144059658050537\n",
            "d_loss_fake:0.22561387717723846\n",
            "d_loss_wrong:0.5352880358695984\n",
            "d_loss:0.6974284648895264\n",
            "g_loss:[1.8376514, 1.8320858, 0.0027827728]\n",
            "Batch:61\n",
            "d_loss_real:1.165194034576416\n",
            "d_loss_fake:0.15016557276248932\n",
            "d_loss_wrong:0.5822535753250122\n",
            "d_loss:0.7657018005847931\n",
            "g_loss:[1.694607, 1.6901379, 0.0022345567]\n",
            "Batch:62\n",
            "d_loss_real:0.9961493015289307\n",
            "d_loss_fake:0.13197645545005798\n",
            "d_loss_wrong:0.6246023774147034\n",
            "d_loss:0.6872193515300751\n",
            "g_loss:[1.8137193, 1.8091717, 0.0022737947]\n",
            "Batch:63\n",
            "d_loss_real:1.194148063659668\n",
            "d_loss_fake:0.15199381113052368\n",
            "d_loss_wrong:0.511650562286377\n",
            "d_loss:0.7629851251840591\n",
            "g_loss:[2.3415182, 2.3362129, 0.0026526242]\n",
            "Batch:64\n",
            "d_loss_real:0.9899902939796448\n",
            "d_loss_fake:0.06112419441342354\n",
            "d_loss_wrong:0.6019366979598999\n",
            "d_loss:0.660760372877121\n",
            "g_loss:[2.3886354, 2.3835983, 0.0025185393]\n",
            "Batch:65\n",
            "d_loss_real:1.140183448791504\n",
            "d_loss_fake:0.06516845524311066\n",
            "d_loss_wrong:0.5837274789810181\n",
            "d_loss:0.7323157042264938\n",
            "g_loss:[1.8459251, 1.8402622, 0.0028314865]\n",
            "Batch:66\n",
            "d_loss_real:1.0435584783554077\n",
            "d_loss_fake:0.06926809251308441\n",
            "d_loss_wrong:0.650603711605072\n",
            "d_loss:0.7017471939325333\n",
            "g_loss:[1.9456533, 1.9412891, 0.002182146]\n",
            "Batch:67\n",
            "d_loss_real:1.0313458442687988\n",
            "d_loss_fake:0.10119473934173584\n",
            "d_loss_wrong:0.6228801012039185\n",
            "d_loss:0.696691632270813\n",
            "g_loss:[1.6833029, 1.6785197, 0.0023915498]\n",
            "Batch:68\n",
            "d_loss_real:1.003197193145752\n",
            "d_loss_fake:0.07742303609848022\n",
            "d_loss_wrong:0.6671837568283081\n",
            "d_loss:0.6877502948045731\n",
            "g_loss:[2.2882516, 2.2831323, 0.0025596893]\n",
            "Batch:69\n",
            "d_loss_real:1.151443600654602\n",
            "d_loss_fake:0.044940248131752014\n",
            "d_loss_wrong:0.8713456392288208\n",
            "d_loss:0.8047932684421539\n",
            "g_loss:[1.510437, 1.5052054, 0.0026158]\n",
            "Batch:70\n",
            "d_loss_real:0.928156852722168\n",
            "d_loss_fake:0.15385735034942627\n",
            "d_loss_wrong:0.6129341721534729\n",
            "d_loss:0.6557763069868088\n",
            "g_loss:[1.447767, 1.4417866, 0.0029901837]\n",
            "Batch:71\n",
            "d_loss_real:1.1235575675964355\n",
            "d_loss_fake:0.07283405214548111\n",
            "d_loss_wrong:0.5563269853591919\n",
            "d_loss:0.7190690487623215\n",
            "g_loss:[1.2750758, 1.2700967, 0.002489577]\n",
            "Batch:72\n",
            "d_loss_real:1.2084802389144897\n",
            "d_loss_fake:0.15758559107780457\n",
            "d_loss_wrong:0.5930464267730713\n",
            "d_loss:0.7918981313705444\n",
            "g_loss:[1.4613059, 1.4571904, 0.0020577547]\n",
            "Batch:73\n",
            "d_loss_real:0.9967098236083984\n",
            "d_loss_fake:0.20673343539237976\n",
            "d_loss_wrong:0.5648418664932251\n",
            "d_loss:0.691248744726181\n",
            "g_loss:[2.0227747, 2.0187418, 0.0020163748]\n",
            "Batch:74\n",
            "d_loss_real:0.9931668639183044\n",
            "d_loss_fake:0.09947458654642105\n",
            "d_loss_wrong:0.540779709815979\n",
            "d_loss:0.6566470116376877\n",
            "g_loss:[2.1189396, 2.1144881, 0.0022257732]\n",
            "Batch:75\n",
            "d_loss_real:1.062853455543518\n",
            "d_loss_fake:0.06691732257604599\n",
            "d_loss_wrong:0.627756655216217\n",
            "d_loss:0.7050952166318893\n",
            "g_loss:[2.140993, 2.1362453, 0.002373983]\n",
            "Batch:76\n",
            "d_loss_real:1.0757075548171997\n",
            "d_loss_fake:0.11986050009727478\n",
            "d_loss_wrong:0.5936578512191772\n",
            "d_loss:0.7162333726882935\n",
            "g_loss:[1.8479874, 1.843134, 0.0024266911]\n",
            "Batch:77\n",
            "d_loss_real:0.9840894937515259\n",
            "d_loss_fake:0.08708968758583069\n",
            "d_loss_wrong:0.6783849000930786\n",
            "d_loss:0.6834133863449097\n",
            "g_loss:[2.03753, 2.0330248, 0.0022526127]\n",
            "Batch:78\n",
            "d_loss_real:0.9641991853713989\n",
            "d_loss_fake:0.09296846389770508\n",
            "d_loss_wrong:0.6648787260055542\n",
            "d_loss:0.6715613901615143\n",
            "g_loss:[2.3672888, 2.362392, 0.0024484666]\n",
            "Batch:79\n",
            "d_loss_real:0.9972603917121887\n",
            "d_loss_fake:0.029616905376315117\n",
            "d_loss_wrong:0.5924769043922424\n",
            "d_loss:0.6541536450386047\n",
            "g_loss:[2.0251899, 2.0197325, 0.0027287444]\n",
            "Batch:80\n",
            "d_loss_real:1.115411639213562\n",
            "d_loss_fake:0.05625368654727936\n",
            "d_loss_wrong:0.7119236588478088\n",
            "d_loss:0.7497501522302628\n",
            "g_loss:[1.5929294, 1.5883725, 0.0022784444]\n",
            "Batch:81\n",
            "d_loss_real:0.9079970717430115\n",
            "d_loss_fake:0.03581633418798447\n",
            "d_loss_wrong:0.5984082818031311\n",
            "d_loss:0.6125546842813492\n",
            "g_loss:[1.8401765, 1.8340802, 0.0030480928]\n",
            "Batch:82\n",
            "d_loss_real:1.0781339406967163\n",
            "d_loss_fake:0.19610145688056946\n",
            "d_loss_wrong:0.5891280770301819\n",
            "d_loss:0.7353743612766266\n",
            "g_loss:[1.6881245, 1.6831295, 0.0024974756]\n",
            "Batch:83\n",
            "d_loss_real:0.9224274158477783\n",
            "d_loss_fake:0.16229236125946045\n",
            "d_loss_wrong:0.5652058720588684\n",
            "d_loss:0.6430882662534714\n",
            "g_loss:[1.7072725, 1.7026622, 0.0023051477]\n",
            "Batch:84\n",
            "d_loss_real:1.1098244190216064\n",
            "d_loss_fake:0.18266350030899048\n",
            "d_loss_wrong:0.5461355447769165\n",
            "d_loss:0.73711197078228\n",
            "g_loss:[1.7538925, 1.748657, 0.0026177734]\n",
            "Batch:85\n",
            "d_loss_real:1.0168046951293945\n",
            "d_loss_fake:0.25201722979545593\n",
            "d_loss_wrong:0.5565345287322998\n",
            "d_loss:0.7105402946472168\n",
            "g_loss:[2.3502893, 2.3456283, 0.0023306003]\n",
            "Batch:86\n",
            "d_loss_real:0.9760771989822388\n",
            "d_loss_fake:0.10513843595981598\n",
            "d_loss_wrong:0.5890851616859436\n",
            "d_loss:0.661594495177269\n",
            "g_loss:[2.7751682, 2.7708077, 0.0021801684]\n",
            "Batch:87\n",
            "d_loss_real:0.9991910457611084\n",
            "d_loss_fake:0.06691481173038483\n",
            "d_loss_wrong:0.5634981393814087\n",
            "d_loss:0.6571987569332123\n",
            "g_loss:[2.6497142, 2.6440697, 0.0028222543]\n",
            "Batch:88\n",
            "d_loss_real:1.2884492874145508\n",
            "d_loss_fake:0.15593329071998596\n",
            "d_loss_wrong:0.64390629529953\n",
            "d_loss:0.844184547662735\n",
            "g_loss:[2.4431267, 2.4365997, 0.003263513]\n",
            "Batch:89\n",
            "d_loss_real:1.0311410427093506\n",
            "d_loss_fake:0.10297699272632599\n",
            "d_loss_wrong:0.8251643180847168\n",
            "d_loss:0.7476058453321457\n",
            "g_loss:[2.600838, 2.5941324, 0.0033528036]\n",
            "Batch:90\n",
            "d_loss_real:0.94240403175354\n",
            "d_loss_fake:0.15160039067268372\n",
            "d_loss_wrong:0.5801247358322144\n",
            "d_loss:0.6541332900524139\n",
            "g_loss:[2.8064399, 2.8004503, 0.0029947595]\n",
            "Batch:92\n",
            "d_loss_real:1.1699419021606445\n",
            "d_loss_fake:0.12390188127756119\n",
            "d_loss_wrong:0.6759774684906006\n",
            "d_loss:0.7849407941102982\n",
            "g_loss:[3.3076534, 3.2996402, 0.0040066466]\n",
            "Batch:93\n",
            "d_loss_real:1.0037271976470947\n",
            "d_loss_fake:0.11948107182979584\n",
            "d_loss_wrong:0.5983737707138062\n",
            "d_loss:0.6813273131847382\n",
            "g_loss:[2.0144491, 2.0066438, 0.0039027312]\n",
            "Batch:94\n",
            "d_loss_real:1.1002788543701172\n",
            "d_loss_fake:0.1817018985748291\n",
            "d_loss_wrong:0.5506148338317871\n",
            "d_loss:0.7332186102867126\n",
            "g_loss:[2.0624413, 2.056354, 0.0030436013]\n",
            "Batch:95\n",
            "d_loss_real:1.02162766456604\n",
            "d_loss_fake:0.15319548547267914\n",
            "d_loss_wrong:0.59634929895401\n",
            "d_loss:0.6982000321149826\n",
            "g_loss:[2.3007402, 2.2948375, 0.0029513272]\n",
            "Batch:96\n",
            "d_loss_real:0.9904975295066833\n",
            "d_loss_fake:0.21122369170188904\n",
            "d_loss_wrong:0.5444340705871582\n",
            "d_loss:0.6841632127761841\n",
            "g_loss:[1.9544729, 1.9469483, 0.0037622824]\n",
            "Batch:97\n",
            "d_loss_real:1.101335048675537\n",
            "d_loss_fake:0.15472467243671417\n",
            "d_loss_wrong:0.5521792769432068\n",
            "d_loss:0.7273935079574585\n",
            "g_loss:[2.663088, 2.655042, 0.004023102]\n",
            "Batch:98\n",
            "d_loss_real:1.1062545776367188\n",
            "d_loss_fake:0.13759653270244598\n",
            "d_loss_wrong:0.5570803284645081\n",
            "d_loss:0.7267965078353882\n",
            "g_loss:[1.8347682, 1.824725, 0.005021559]\n",
            "Batch:99\n",
            "d_loss_real:1.0939743518829346\n",
            "d_loss_fake:0.09496374428272247\n",
            "d_loss_wrong:0.5130701661109924\n",
            "d_loss:0.6989956498146057\n",
            "g_loss:[2.059147, 2.050196, 0.004475417]\n",
            "Batch:100\n",
            "d_loss_real:1.0691839456558228\n",
            "d_loss_fake:0.04052620008587837\n",
            "d_loss_wrong:0.5658852458000183\n",
            "d_loss:0.6861948370933533\n",
            "g_loss:[1.590322, 1.5845754, 0.002873276]\n",
            "Batch:101\n",
            "d_loss_real:1.0062487125396729\n",
            "d_loss_fake:0.04569374397397041\n",
            "d_loss_wrong:0.6333505511283875\n",
            "d_loss:0.6728854328393936\n",
            "g_loss:[1.616603, 1.611253, 0.0026750104]\n",
            "Batch:102\n",
            "d_loss_real:0.9381505846977234\n",
            "d_loss_fake:0.1740792840719223\n",
            "d_loss_wrong:0.5990952849388123\n",
            "d_loss:0.6623689383268356\n",
            "g_loss:[1.4001156, 1.3937266, 0.0031944865]\n",
            "Batch:103\n",
            "d_loss_real:1.0652436017990112\n",
            "d_loss_fake:0.1907360553741455\n",
            "d_loss_wrong:0.5174903273582458\n",
            "d_loss:0.7096783965826035\n",
            "g_loss:[2.0828412, 2.076198, 0.00332149]\n",
            "Batch:104\n",
            "d_loss_real:1.2008204460144043\n",
            "d_loss_fake:0.08532775938510895\n",
            "d_loss_wrong:0.554755687713623\n",
            "d_loss:0.7604310810565948\n",
            "g_loss:[2.108095, 2.1017885, 0.0031532492]\n",
            "Batch:105\n",
            "d_loss_real:1.1154870986938477\n",
            "d_loss_fake:0.04418957233428955\n",
            "d_loss_wrong:0.607271134853363\n",
            "d_loss:0.720608726143837\n",
            "g_loss:[1.8611536, 1.8559635, 0.0025950682]\n",
            "Batch:106\n",
            "d_loss_real:0.9514822363853455\n",
            "d_loss_fake:0.123356893658638\n",
            "d_loss_wrong:0.6086430549621582\n",
            "d_loss:0.6587411016225815\n",
            "g_loss:[2.1945097, 2.1889, 0.0028048502]\n",
            "Batch:107\n",
            "d_loss_real:1.050818920135498\n",
            "d_loss_fake:0.02516961842775345\n",
            "d_loss_wrong:0.6169799566268921\n",
            "d_loss:0.6859468519687653\n",
            "g_loss:[1.7773287, 1.7718353, 0.002746724]\n",
            "Batch:108\n",
            "d_loss_real:0.9618103504180908\n",
            "d_loss_fake:0.05230719968676567\n",
            "d_loss_wrong:0.6850962042808533\n",
            "d_loss:0.6652560234069824\n",
            "g_loss:[2.0637076, 2.0584178, 0.0026449382]\n",
            "Batch:109\n",
            "d_loss_real:1.0153683423995972\n",
            "d_loss_fake:0.0728972926735878\n",
            "d_loss_wrong:0.71354079246521\n",
            "d_loss:0.7042936980724335\n",
            "g_loss:[1.6079782, 1.600794, 0.003592163]\n",
            "Batch:110\n",
            "d_loss_real:0.9612703323364258\n",
            "d_loss_fake:0.0689922422170639\n",
            "d_loss_wrong:0.6208977699279785\n",
            "d_loss:0.6531076729297638\n",
            "g_loss:[2.278704, 2.27143, 0.003636965]\n",
            "Batch:111\n",
            "d_loss_real:1.0143108367919922\n",
            "d_loss_fake:0.10686591267585754\n",
            "d_loss_wrong:0.6017886400222778\n",
            "d_loss:0.6843190491199493\n",
            "g_loss:[2.981849, 2.9748793, 0.0034848899]\n",
            "Batch:112\n",
            "d_loss_real:1.2888768911361694\n",
            "d_loss_fake:0.045804720371961594\n",
            "d_loss_wrong:1.0643707513809204\n",
            "d_loss:0.9219823181629181\n",
            "g_loss:[1.8311054, 1.8235888, 0.0037582363]\n",
            "Batch:113\n",
            "d_loss_real:0.909163236618042\n",
            "d_loss_fake:0.016428112983703613\n",
            "d_loss_wrong:0.6032599210739136\n",
            "d_loss:0.6095036268234253\n",
            "g_loss:[1.75116, 1.7425904, 0.0042847972]\n",
            "Batch:114\n",
            "d_loss_real:1.0056524276733398\n",
            "d_loss_fake:0.03722644969820976\n",
            "d_loss_wrong:0.5968837141990662\n",
            "d_loss:0.6613537520170212\n",
            "g_loss:[1.7812989, 1.7742667, 0.0035160668]\n",
            "Batch:115\n",
            "d_loss_real:0.9576715230941772\n",
            "d_loss_fake:0.09547686576843262\n",
            "d_loss_wrong:0.5947648286819458\n",
            "d_loss:0.6513961851596832\n",
            "g_loss:[2.698895, 2.6906173, 0.004138798]\n",
            "Batch:116\n",
            "d_loss_real:1.5315824747085571\n",
            "d_loss_fake:0.08679090440273285\n",
            "d_loss_wrong:0.7799186110496521\n",
            "d_loss:0.9824686199426651\n",
            "g_loss:[2.3008256, 2.2937872, 0.0035191388]\n",
            "Batch:117\n",
            "d_loss_real:0.8217819929122925\n",
            "d_loss_fake:0.1576334536075592\n",
            "d_loss_wrong:0.6447436809539795\n",
            "d_loss:0.6114852726459503\n",
            "g_loss:[2.9656918, 2.959476, 0.00310795]\n",
            "Batch:118\n",
            "d_loss_real:0.9651506543159485\n",
            "d_loss_fake:0.10087265074253082\n",
            "d_loss_wrong:0.6002205014228821\n",
            "d_loss:0.6578486114740372\n",
            "g_loss:[2.741236, 2.7345333, 0.003351278]\n",
            "Batch:119\n",
            "d_loss_real:0.9806294441223145\n",
            "d_loss_fake:0.1353590488433838\n",
            "d_loss_wrong:0.5745855569839478\n",
            "d_loss:0.6678008735179901\n",
            "g_loss:[2.5204973, 2.5158758, 0.0023107077]\n",
            "Batch:120\n",
            "d_loss_real:0.9823254942893982\n",
            "d_loss_fake:0.06467638909816742\n",
            "d_loss_wrong:0.5870201587677002\n",
            "d_loss:0.6540868878364563\n",
            "g_loss:[1.9948535, 1.9889808, 0.0029363753]\n",
            "Batch:121\n",
            "d_loss_real:0.9913001656532288\n",
            "d_loss_fake:0.09569457173347473\n",
            "d_loss_wrong:0.6238661408424377\n",
            "d_loss:0.6755402684211731\n",
            "g_loss:[2.3551357, 2.3489604, 0.0030876903]\n",
            "Batch:122\n",
            "d_loss_real:1.018330693244934\n",
            "d_loss_fake:0.02409541793167591\n",
            "d_loss_wrong:0.6173959374427795\n",
            "d_loss:0.6695381850004196\n",
            "g_loss:[2.0776572, 2.0704937, 0.0035817144]\n",
            "Batch:123\n",
            "d_loss_real:1.1800130605697632\n",
            "d_loss_fake:0.04078473895788193\n",
            "d_loss_wrong:0.7232468724250793\n",
            "d_loss:0.7810144275426865\n",
            "g_loss:[1.7168297, 1.7115192, 0.0026552111]\n",
            "Batch:124\n",
            "d_loss_real:0.9556792974472046\n",
            "d_loss_fake:0.03031061589717865\n",
            "d_loss_wrong:0.6039761304855347\n",
            "d_loss:0.6364113390445709\n",
            "g_loss:[1.7560679, 1.7512485, 0.002409725]\n",
            "Batch:125\n",
            "d_loss_real:0.9021129608154297\n",
            "d_loss_fake:0.03227058798074722\n",
            "d_loss_wrong:0.6450707316398621\n",
            "d_loss:0.6203918159008026\n",
            "g_loss:[1.6553164, 1.6485424, 0.003386952]\n",
            "Batch:126\n",
            "d_loss_real:0.8780791759490967\n",
            "d_loss_fake:0.02809114381670952\n",
            "d_loss_wrong:0.6890350580215454\n",
            "d_loss:0.6183211356401443\n",
            "g_loss:[1.6033697, 1.5960371, 0.0036662947]\n",
            "Batch:127\n",
            "d_loss_real:0.8757423758506775\n",
            "d_loss_fake:0.03511643782258034\n",
            "d_loss_wrong:0.6586435437202454\n",
            "d_loss:0.6113111823797226\n",
            "g_loss:[1.4205812, 1.4149908, 0.0027952155]\n",
            "Batch:128\n",
            "d_loss_real:0.9302449226379395\n",
            "d_loss_fake:0.06858185678720474\n",
            "d_loss_wrong:0.6986293196678162\n",
            "d_loss:0.6569252610206604\n",
            "g_loss:[1.6394378, 1.6300805, 0.0046786466]\n",
            "Batch:129\n",
            "d_loss_real:0.9248212575912476\n",
            "d_loss_fake:0.02436792105436325\n",
            "d_loss_wrong:0.6139601469039917\n",
            "d_loss:0.6219926476478577\n",
            "g_loss:[1.5017539, 1.4930266, 0.0043636593]\n",
            "Batch:130\n",
            "d_loss_real:1.0542479753494263\n",
            "d_loss_fake:0.06178244575858116\n",
            "d_loss_wrong:0.6906960010528564\n",
            "d_loss:0.7152435928583145\n",
            "g_loss:[1.4281621, 1.4227684, 0.0026968427]\n",
            "Batch:131\n",
            "d_loss_real:0.858947217464447\n",
            "d_loss_fake:0.07437591999769211\n",
            "d_loss_wrong:0.6726127862930298\n",
            "d_loss:0.6162207871675491\n",
            "g_loss:[1.3302603, 1.3230885, 0.003585889]\n",
            "Batch:132\n",
            "d_loss_real:0.9405831694602966\n",
            "d_loss_fake:0.04823135957121849\n",
            "d_loss_wrong:0.6515899896621704\n",
            "d_loss:0.6452469229698181\n",
            "g_loss:[1.3223758, 1.3165071, 0.0029343122]\n",
            "Batch:133\n",
            "d_loss_real:0.9625039100646973\n",
            "d_loss_fake:0.025288917124271393\n",
            "d_loss_wrong:0.6283397078514099\n",
            "d_loss:0.6446591168642044\n",
            "g_loss:[1.3212475, 1.3170469, 0.002100317]\n",
            "Batch:134\n",
            "d_loss_real:0.970505952835083\n",
            "d_loss_fake:0.03351886570453644\n",
            "d_loss_wrong:0.6588103175163269\n",
            "d_loss:0.658335268497467\n",
            "g_loss:[1.3590267, 1.3543448, 0.0023409182]\n",
            "Batch:135\n",
            "d_loss_real:0.9549996852874756\n",
            "d_loss_fake:0.021264920011162758\n",
            "d_loss_wrong:0.6742860078811646\n",
            "d_loss:0.6513875722885132\n",
            "g_loss:[1.4279435, 1.4233778, 0.0022828388]\n",
            "Batch:136\n",
            "d_loss_real:0.8795531392097473\n",
            "d_loss_fake:0.04083387553691864\n",
            "d_loss_wrong:0.6535388827323914\n",
            "d_loss:0.6133697628974915\n",
            "g_loss:[1.089484, 1.0851746, 0.0021547088]\n",
            "Batch:137\n",
            "d_loss_real:0.9868996143341064\n",
            "d_loss_fake:0.048094235360622406\n",
            "d_loss_wrong:0.6413230299949646\n",
            "d_loss:0.6658041179180145\n",
            "g_loss:[1.055112, 1.0510644, 0.0020238273]\n",
            "Batch:138\n",
            "d_loss_real:0.8184927105903625\n",
            "d_loss_fake:0.006175751332193613\n",
            "d_loss_wrong:0.686913251876831\n",
            "d_loss:0.582518607378006\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "g_loss:[1.042722, 1.0378087, 0.0024566385]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "========================================\n",
            "Epoch is: 3\n",
            "Number of batches 138\n",
            "Batch:1\n",
            "d_loss_real:0.970874011516571\n",
            "d_loss_fake:0.011996046639978886\n",
            "d_loss_wrong:0.6847807765007019\n",
            "d_loss:0.6596312075853348\n",
            "g_loss:[1.071834, 1.066367, 0.0027334471]\n",
            "Batch:2\n",
            "d_loss_real:0.9175928235054016\n",
            "d_loss_fake:0.007031439803540707\n",
            "d_loss_wrong:0.6795256733894348\n",
            "d_loss:0.6304356902837753\n",
            "g_loss:[0.93874466, 0.9324414, 0.0031516273]\n",
            "Batch:3\n",
            "d_loss_real:0.8765872120857239\n",
            "d_loss_fake:0.014993611723184586\n",
            "d_loss_wrong:0.6884638667106628\n",
            "d_loss:0.6141579747200012\n",
            "g_loss:[0.98291737, 0.9757516, 0.0035829]\n",
            "Batch:4\n",
            "d_loss_real:0.9403363466262817\n",
            "d_loss_fake:0.012924612499773502\n",
            "d_loss_wrong:0.7153588533401489\n",
            "d_loss:0.6522390395402908\n",
            "g_loss:[0.9520584, 0.94667906, 0.0026896726]\n",
            "Batch:5\n",
            "d_loss_real:0.8449126482009888\n",
            "d_loss_fake:0.005843612365424633\n",
            "d_loss_wrong:0.7398915886878967\n",
            "d_loss:0.6088901311159134\n",
            "g_loss:[1.051988, 1.047625, 0.0021815402]\n",
            "Batch:6\n",
            "d_loss_real:0.8648130893707275\n",
            "d_loss_fake:0.06021581217646599\n",
            "d_loss_wrong:0.8054941296577454\n",
            "d_loss:0.6488340348005295\n",
            "g_loss:[1.0074085, 1.002422, 0.0024932737]\n",
            "Batch:7\n",
            "d_loss_real:0.8263223767280579\n",
            "d_loss_fake:0.01132369227707386\n",
            "d_loss_wrong:0.6929294466972351\n",
            "d_loss:0.5892244726419449\n",
            "g_loss:[1.0412365, 1.0368913, 0.0021726103]\n",
            "Batch:8\n",
            "d_loss_real:0.9764575362205505\n",
            "d_loss_fake:0.06413264572620392\n",
            "d_loss_wrong:0.5703603625297546\n",
            "d_loss:0.6468520164489746\n",
            "g_loss:[1.0856721, 1.0782094, 0.0037313704]\n",
            "Batch:9\n",
            "d_loss_real:1.0772788524627686\n",
            "d_loss_fake:0.022507302463054657\n",
            "d_loss_wrong:0.6539134383201599\n",
            "d_loss:0.7077446132898331\n",
            "g_loss:[1.0393472, 1.0281283, 0.005609436]\n",
            "Batch:10\n",
            "d_loss_real:0.8661133050918579\n",
            "d_loss_fake:0.1019449308514595\n",
            "d_loss_wrong:0.6447762250900269\n",
            "d_loss:0.6197369396686554\n",
            "g_loss:[1.1197133, 1.1106614, 0.004525965]\n",
            "Batch:11\n",
            "d_loss_real:1.0356169939041138\n",
            "d_loss_fake:0.047354936599731445\n",
            "d_loss_wrong:0.6460675597190857\n",
            "d_loss:0.6911641210317612\n",
            "g_loss:[1.2000258, 1.1942146, 0.002905599]\n",
            "Batch:12\n",
            "d_loss_real:0.9471538066864014\n",
            "d_loss_fake:0.0447683110833168\n",
            "d_loss_wrong:0.6090948581695557\n",
            "d_loss:0.6370427012443542\n",
            "g_loss:[1.2005283, 1.1957381, 0.0023951186]\n",
            "Batch:13\n",
            "d_loss_real:0.925923764705658\n",
            "d_loss_fake:0.04576301574707031\n",
            "d_loss_wrong:0.6254173517227173\n",
            "d_loss:0.6307569742202759\n",
            "g_loss:[1.2859981, 1.2817192, 0.0021394645]\n",
            "Batch:14\n",
            "d_loss_real:1.0473597049713135\n",
            "d_loss_fake:0.06953388452529907\n",
            "d_loss_wrong:0.5685334801673889\n",
            "d_loss:0.6831966936588287\n",
            "g_loss:[1.1539944, 1.1502235, 0.0018854503]\n",
            "Batch:15\n",
            "d_loss_real:0.9455496668815613\n",
            "d_loss_fake:0.01938745751976967\n",
            "d_loss_wrong:0.7352869510650635\n",
            "d_loss:0.661443442106247\n",
            "g_loss:[1.234582, 1.2290478, 0.0027670967]\n",
            "Batch:16\n",
            "d_loss_real:0.8885990381240845\n",
            "d_loss_fake:0.11115026473999023\n",
            "d_loss_wrong:0.695698082447052\n",
            "d_loss:0.6460116058588028\n",
            "g_loss:[1.3684546, 1.3629618, 0.0027463986]\n",
            "Batch:17\n",
            "d_loss_real:1.0358936786651611\n",
            "d_loss_fake:0.031585149466991425\n",
            "d_loss_wrong:0.7873746752738953\n",
            "d_loss:0.7226867973804474\n",
            "g_loss:[1.1748458, 1.1693558, 0.0027450123]\n",
            "Batch:18\n",
            "d_loss_real:0.9452602863311768\n",
            "d_loss_fake:0.12753178179264069\n",
            "d_loss_wrong:0.6000142097473145\n",
            "d_loss:0.6545166373252869\n",
            "g_loss:[1.3212869, 1.3168795, 0.0022037071]\n",
            "Batch:19\n",
            "d_loss_real:1.0251301527023315\n",
            "d_loss_fake:0.15650959312915802\n",
            "d_loss_wrong:0.5821213126182556\n",
            "d_loss:0.6972227990627289\n",
            "g_loss:[1.2419374, 1.2374659, 0.002235783]\n",
            "Batch:20\n",
            "d_loss_real:1.2464191913604736\n",
            "d_loss_fake:0.11708012968301773\n",
            "d_loss_wrong:0.601452112197876\n",
            "d_loss:0.8028426617383957\n",
            "g_loss:[1.1507858, 1.1459348, 0.0024255041]\n",
            "Batch:21\n",
            "d_loss_real:0.9575202465057373\n",
            "d_loss_fake:0.03827029466629028\n",
            "d_loss_wrong:0.5940301418304443\n",
            "d_loss:0.6368352323770523\n",
            "g_loss:[1.0172616, 1.0128832, 0.0021892018]\n",
            "Batch:22\n",
            "d_loss_real:0.972793459892273\n",
            "d_loss_fake:0.02279415726661682\n",
            "d_loss_wrong:0.7518907785415649\n",
            "d_loss:0.6800679564476013\n",
            "g_loss:[1.0420257, 1.0383493, 0.001838228]\n",
            "Batch:23\n",
            "d_loss_real:0.9729307293891907\n",
            "d_loss_fake:0.07707873731851578\n",
            "d_loss_wrong:0.6545353531837463\n",
            "d_loss:0.6693688929080963\n",
            "g_loss:[1.1385013, 1.1335764, 0.002462426]\n",
            "Batch:24\n",
            "d_loss_real:0.8922362327575684\n",
            "d_loss_fake:0.004928195849061012\n",
            "d_loss_wrong:0.6921001076698303\n",
            "d_loss:0.6203751862049103\n",
            "g_loss:[1.0654029, 1.0589072, 0.0032478839]\n",
            "Batch:25\n",
            "d_loss_real:0.967783510684967\n",
            "d_loss_fake:0.14808881282806396\n",
            "d_loss_wrong:0.6797204613685608\n",
            "d_loss:0.6908440738916397\n",
            "g_loss:[1.2066652, 1.200583, 0.0030410716]\n",
            "Batch:26\n",
            "d_loss_real:1.0538657903671265\n",
            "d_loss_fake:0.0569416806101799\n",
            "d_loss_wrong:0.7032416462898254\n",
            "d_loss:0.7169787287712097\n",
            "g_loss:[1.0455133, 1.0408618, 0.002325695]\n",
            "Batch:27\n",
            "d_loss_real:0.9213511943817139\n",
            "d_loss_fake:0.2713559865951538\n",
            "d_loss_wrong:0.7237257361412048\n",
            "d_loss:0.7094460278749466\n",
            "g_loss:[1.295849, 1.2918228, 0.0020131068]\n",
            "Batch:28\n",
            "d_loss_real:0.989680290222168\n",
            "d_loss_fake:0.15314602851867676\n",
            "d_loss_wrong:0.5706135630607605\n",
            "d_loss:0.6757800430059433\n",
            "g_loss:[1.4143534, 1.4066541, 0.0038496056]\n",
            "Batch:29\n",
            "d_loss_real:1.0696332454681396\n",
            "d_loss_fake:0.09777706116437912\n",
            "d_loss_wrong:0.5663480162620544\n",
            "d_loss:0.7008478939533234\n",
            "g_loss:[1.2982363, 1.2933626, 0.0024368113]\n",
            "Batch:30\n",
            "d_loss_real:1.0827839374542236\n",
            "d_loss_fake:0.05840165913105011\n",
            "d_loss_wrong:0.7154676914215088\n",
            "d_loss:0.7348593026399612\n",
            "g_loss:[1.3506076, 1.345909, 0.0023493273]\n",
            "Batch:31\n",
            "d_loss_real:1.0097802877426147\n",
            "d_loss_fake:0.28923729062080383\n",
            "d_loss_wrong:0.6224937438964844\n",
            "d_loss:0.7328228950500488\n",
            "g_loss:[1.7864975, 1.7816732, 0.0024121618]\n",
            "Batch:32\n",
            "d_loss_real:1.3557190895080566\n",
            "d_loss_fake:0.238133043050766\n",
            "d_loss_wrong:0.5441068410873413\n",
            "d_loss:0.8734195232391357\n",
            "g_loss:[1.4358033, 1.4303935, 0.0027049207]\n",
            "Batch:33\n",
            "d_loss_real:1.0026094913482666\n",
            "d_loss_fake:0.24170830845832825\n",
            "d_loss_wrong:0.5592402815818787\n",
            "d_loss:0.7015419006347656\n",
            "g_loss:[1.550041, 1.5449871, 0.0025269329]\n",
            "Batch:34\n",
            "d_loss_real:1.0642342567443848\n",
            "d_loss_fake:0.2538982033729553\n",
            "d_loss_wrong:0.504514753818512\n",
            "d_loss:0.7217203676700592\n",
            "g_loss:[1.6281735, 1.6230552, 0.0025591282]\n",
            "Batch:35\n",
            "d_loss_real:1.0639196634292603\n",
            "d_loss_fake:0.2145882397890091\n",
            "d_loss_wrong:0.5330772399902344\n",
            "d_loss:0.7188761979341507\n",
            "g_loss:[1.5137173, 1.5088223, 0.002447459]\n",
            "Batch:36\n",
            "d_loss_real:1.0744438171386719\n",
            "d_loss_fake:0.21085083484649658\n",
            "d_loss_wrong:0.5224750638008118\n",
            "d_loss:0.720553383231163\n",
            "g_loss:[1.5100738, 1.5041888, 0.0029425002]\n",
            "Batch:37\n",
            "d_loss_real:1.0995796918869019\n",
            "d_loss_fake:0.1745516061782837\n",
            "d_loss_wrong:0.5356420278549194\n",
            "d_loss:0.7273382544517517\n",
            "g_loss:[1.5156292, 1.5097376, 0.0029457663]\n",
            "Batch:38\n",
            "d_loss_real:1.0227727890014648\n",
            "d_loss_fake:0.1784585863351822\n",
            "d_loss_wrong:0.5813818573951721\n",
            "d_loss:0.7013465017080307\n",
            "g_loss:[1.3357397, 1.3301907, 0.002774563]\n",
            "Batch:39\n",
            "d_loss_real:1.0845165252685547\n",
            "d_loss_fake:0.06800608336925507\n",
            "d_loss_wrong:0.5709109902381897\n",
            "d_loss:0.7019875347614288\n",
            "g_loss:[1.1785653, 1.1729735, 0.0027958953]\n",
            "Batch:40\n",
            "d_loss_real:1.1328635215759277\n",
            "d_loss_fake:0.17566993832588196\n",
            "d_loss_wrong:0.5782753825187683\n",
            "d_loss:0.754918098449707\n",
            "g_loss:[1.2413826, 1.2361225, 0.0026300414]\n",
            "Batch:41\n",
            "d_loss_real:1.0093741416931152\n",
            "d_loss_fake:0.15508240461349487\n",
            "d_loss_wrong:0.5792233347892761\n",
            "d_loss:0.6882635056972504\n",
            "g_loss:[1.0973779, 1.091474, 0.0029519193]\n",
            "Batch:42\n",
            "d_loss_real:0.9801161289215088\n",
            "d_loss_fake:0.17090877890586853\n",
            "d_loss_wrong:0.6105467677116394\n",
            "d_loss:0.6854219436645508\n",
            "g_loss:[1.5844011, 1.5789931, 0.0027040406]\n",
            "Batch:43\n",
            "d_loss_real:1.2323445081710815\n",
            "d_loss_fake:0.1453283727169037\n",
            "d_loss_wrong:0.5585648417472839\n",
            "d_loss:0.7921455502510071\n",
            "g_loss:[1.2522479, 1.2473532, 0.0024473935]\n",
            "Batch:44\n",
            "d_loss_real:1.011647343635559\n",
            "d_loss_fake:0.13214325904846191\n",
            "d_loss_wrong:0.5784547328948975\n",
            "d_loss:0.6834731698036194\n",
            "g_loss:[1.3097463, 1.3041351, 0.002805572]\n",
            "Batch:45\n",
            "d_loss_real:1.2334147691726685\n",
            "d_loss_fake:0.08292803168296814\n",
            "d_loss_wrong:0.5125134587287903\n",
            "d_loss:0.7655677497386932\n",
            "g_loss:[1.0218571, 1.0157709, 0.0030431114]\n",
            "Batch:46\n",
            "d_loss_real:0.9093874096870422\n",
            "d_loss_fake:0.1646205335855484\n",
            "d_loss_wrong:0.6228304505348206\n",
            "d_loss:0.6515564471483231\n",
            "g_loss:[1.1553177, 1.1501975, 0.0025600642]\n",
            "Batch:47\n",
            "d_loss_real:0.9389774203300476\n",
            "d_loss_fake:0.05994501709938049\n",
            "d_loss_wrong:0.6297723650932312\n",
            "d_loss:0.6419180631637573\n",
            "g_loss:[0.9881255, 0.9817806, 0.0031724707]\n",
            "Batch:48\n",
            "d_loss_real:0.9738414883613586\n",
            "d_loss_fake:0.019820943474769592\n",
            "d_loss_wrong:0.6994645595550537\n",
            "d_loss:0.6667421162128448\n",
            "g_loss:[0.9374235, 0.9316589, 0.0028823083]\n",
            "Batch:49\n",
            "d_loss_real:1.0198694467544556\n",
            "d_loss_fake:0.060097794979810715\n",
            "d_loss_wrong:0.5872267484664917\n",
            "d_loss:0.6717658638954163\n",
            "g_loss:[0.794847, 0.78868115, 0.0030829418]\n",
            "Batch:50\n",
            "d_loss_real:0.9890718460083008\n",
            "d_loss_fake:0.05134795978665352\n",
            "d_loss_wrong:0.6904779076576233\n",
            "d_loss:0.6799923926591873\n",
            "g_loss:[0.8653005, 0.861452, 0.0019242592]\n",
            "Batch:51\n",
            "d_loss_real:0.8746450543403625\n",
            "d_loss_fake:0.08211728930473328\n",
            "d_loss_wrong:0.6411188244819641\n",
            "d_loss:0.618131548166275\n",
            "g_loss:[1.0913422, 1.0871797, 0.0020812927]\n",
            "Batch:52\n",
            "d_loss_real:0.9192905426025391\n",
            "d_loss_fake:0.0012690582079812884\n",
            "d_loss_wrong:0.6906716823577881\n",
            "d_loss:0.6326304525136948\n",
            "g_loss:[0.99231046, 0.9893482, 0.0014811421]\n",
            "Batch:53\n",
            "d_loss_real:0.9698233604431152\n",
            "d_loss_fake:0.01282314583659172\n",
            "d_loss_wrong:0.6150919795036316\n",
            "d_loss:0.6418904662132263\n",
            "g_loss:[0.780109, 0.7758454, 0.0021317797]\n",
            "Batch:54\n",
            "d_loss_real:0.779297947883606\n",
            "d_loss_fake:0.0020548186730593443\n",
            "d_loss_wrong:0.7556187510490417\n",
            "d_loss:0.5790673643350601\n",
            "g_loss:[0.8445085, 0.8405489, 0.0019798423]\n",
            "Batch:55\n",
            "d_loss_real:0.8755344152450562\n",
            "d_loss_fake:0.0009680214570835233\n",
            "d_loss_wrong:0.6372247934341431\n",
            "d_loss:0.5973154157400131\n",
            "g_loss:[0.73732567, 0.73315936, 0.002083154]\n",
            "Batch:56\n",
            "d_loss_real:0.8926925659179688\n",
            "d_loss_fake:0.0019939036574214697\n",
            "d_loss_wrong:0.7036816477775574\n",
            "d_loss:0.6227651685476303\n",
            "g_loss:[0.7301268, 0.72557527, 0.0022757747]\n",
            "Batch:57\n",
            "d_loss_real:0.8390437364578247\n",
            "d_loss_fake:0.0019220716785639524\n",
            "d_loss_wrong:0.6882471442222595\n",
            "d_loss:0.5920641720294952\n",
            "g_loss:[0.5657643, 0.5607693, 0.0024975026]\n",
            "Batch:58\n",
            "d_loss_real:0.8266357183456421\n",
            "d_loss_fake:0.007009338121861219\n",
            "d_loss_wrong:0.6635876297950745\n",
            "d_loss:0.5809670984745026\n",
            "g_loss:[0.73648036, 0.73199373, 0.0022432979]\n",
            "Batch:59\n",
            "d_loss_real:0.9301538467407227\n",
            "d_loss_fake:0.01595390774309635\n",
            "d_loss_wrong:0.6973473429679871\n",
            "d_loss:0.6434022337198257\n",
            "g_loss:[0.60735023, 0.60337055, 0.0019898536]\n",
            "Batch:60\n",
            "d_loss_real:0.8897610902786255\n",
            "d_loss_fake:0.008475227281451225\n",
            "d_loss_wrong:0.6721029281616211\n",
            "d_loss:0.6150250881910324\n",
            "g_loss:[0.72107637, 0.7171421, 0.0019671454]\n",
            "Batch:61\n",
            "d_loss_real:0.8998115658760071\n",
            "d_loss_fake:0.0028371296357363462\n",
            "d_loss_wrong:0.6288615465164185\n",
            "d_loss:0.6078304499387741\n",
            "g_loss:[0.5833357, 0.57984626, 0.0017447048]\n",
            "Batch:62\n",
            "d_loss_real:0.9382771253585815\n",
            "d_loss_fake:0.005661633796989918\n",
            "d_loss_wrong:0.617424488067627\n",
            "d_loss:0.6249100863933563\n",
            "g_loss:[0.63183916, 0.6278426, 0.0019982879]\n",
            "Batch:63\n",
            "d_loss_real:0.8924519419670105\n",
            "d_loss_fake:0.022176098078489304\n",
            "d_loss_wrong:0.6364077925682068\n",
            "d_loss:0.6108719408512115\n",
            "g_loss:[0.5311023, 0.5269802, 0.0020610392]\n",
            "Batch:64\n",
            "d_loss_real:0.9198895692825317\n",
            "d_loss_fake:0.008626474998891354\n",
            "d_loss_wrong:0.5832000970840454\n",
            "d_loss:0.6079014241695404\n",
            "g_loss:[0.57400095, 0.56989336, 0.0020537968]\n",
            "Batch:65\n",
            "d_loss_real:0.9155153036117554\n",
            "d_loss_fake:0.009605785831809044\n",
            "d_loss_wrong:0.7061132788658142\n",
            "d_loss:0.6366874128580093\n",
            "g_loss:[0.62467057, 0.6203182, 0.0021762021]\n",
            "Batch:66\n",
            "d_loss_real:0.8254780173301697\n",
            "d_loss_fake:0.002378846053034067\n",
            "d_loss_wrong:0.6666070818901062\n",
            "d_loss:0.5799854844808578\n",
            "g_loss:[0.54551363, 0.5420939, 0.0017098853]\n",
            "Batch:67\n",
            "d_loss_real:0.9828481674194336\n",
            "d_loss_fake:0.016787081956863403\n",
            "d_loss_wrong:0.5969854593276978\n",
            "d_loss:0.6448672115802765\n",
            "g_loss:[0.5428722, 0.5395968, 0.0016376888]\n",
            "Batch:68\n",
            "d_loss_real:0.8396677374839783\n",
            "d_loss_fake:0.008273428305983543\n",
            "d_loss_wrong:0.6872381567955017\n",
            "d_loss:0.5937117636203766\n",
            "g_loss:[0.47905663, 0.47479713, 0.0021297534]\n",
            "Batch:69\n",
            "d_loss_real:0.8607154488563538\n",
            "d_loss_fake:0.024643920361995697\n",
            "d_loss_wrong:0.7709380984306335\n",
            "d_loss:0.6292532235383987\n",
            "g_loss:[0.57586634, 0.5719312, 0.0019675836]\n",
            "Batch:70\n",
            "d_loss_real:0.8237619400024414\n",
            "d_loss_fake:0.004709447268396616\n",
            "d_loss_wrong:0.6522276997566223\n",
            "d_loss:0.5761152505874634\n",
            "g_loss:[0.5469435, 0.54266083, 0.0021413164]\n",
            "Batch:71\n",
            "d_loss_real:0.9137662649154663\n",
            "d_loss_fake:0.00431849155575037\n",
            "d_loss_wrong:0.620464563369751\n",
            "d_loss:0.6130788922309875\n",
            "g_loss:[0.5168312, 0.5133162, 0.0017575128]\n",
            "Batch:72\n",
            "d_loss_real:0.869943380355835\n",
            "d_loss_fake:0.0029383613727986813\n",
            "d_loss_wrong:0.6655269265174866\n",
            "d_loss:0.6020880192518234\n",
            "g_loss:[0.42164406, 0.41820768, 0.0017181911]\n",
            "Batch:73\n",
            "d_loss_real:0.8220875263214111\n",
            "d_loss_fake:0.011975191533565521\n",
            "d_loss_wrong:0.6562190055847168\n",
            "d_loss:0.5780923068523407\n",
            "g_loss:[0.44666648, 0.44340837, 0.0016290529]\n",
            "Batch:74\n",
            "d_loss_real:0.9421244859695435\n",
            "d_loss_fake:0.005198318045586348\n",
            "d_loss_wrong:0.6007694602012634\n",
            "d_loss:0.6225541830062866\n",
            "g_loss:[0.42724922, 0.42397472, 0.0016372564]\n",
            "Batch:75\n",
            "d_loss_real:0.8887926936149597\n",
            "d_loss_fake:0.007805066183209419\n",
            "d_loss_wrong:0.6226726174354553\n",
            "d_loss:0.6020157635211945\n",
            "g_loss:[0.41400725, 0.41064823, 0.0016795094]\n",
            "Batch:76\n",
            "d_loss_real:0.9873931407928467\n",
            "d_loss_fake:0.011244449764490128\n",
            "d_loss_wrong:0.6401315927505493\n",
            "d_loss:0.6565405875444412\n",
            "g_loss:[0.38354605, 0.38015473, 0.00169566]\n",
            "Batch:77\n",
            "d_loss_real:0.8124287128448486\n",
            "d_loss_fake:0.004138685297220945\n",
            "d_loss_wrong:0.6825546026229858\n",
            "d_loss:0.5778876841068268\n",
            "g_loss:[0.4429244, 0.43973964, 0.0015923772]\n",
            "Batch:78\n",
            "d_loss_real:0.9062291383743286\n",
            "d_loss_fake:0.0069960299879312515\n",
            "d_loss_wrong:0.6675165891647339\n",
            "d_loss:0.6217427253723145\n",
            "g_loss:[0.51508194, 0.5116946, 0.0016936535]\n",
            "Batch:79\n",
            "d_loss_real:0.8312697410583496\n",
            "d_loss_fake:0.008558793924748898\n",
            "d_loss_wrong:0.6515085697174072\n",
            "d_loss:0.5806517153978348\n",
            "g_loss:[0.44070336, 0.43690345, 0.0018999568]\n",
            "Batch:80\n",
            "d_loss_real:0.8788543939590454\n",
            "d_loss_fake:0.004311864264309406\n",
            "d_loss_wrong:0.7067669034004211\n",
            "d_loss:0.6171968877315521\n",
            "g_loss:[0.37626028, 0.37329453, 0.0014828709]\n",
            "Batch:81\n",
            "d_loss_real:0.8501652479171753\n",
            "d_loss_fake:0.0039124153554439545\n",
            "d_loss_wrong:0.6118113398551941\n",
            "d_loss:0.5790135562419891\n",
            "g_loss:[0.4373494, 0.43333519, 0.002007109]\n",
            "Batch:82\n",
            "d_loss_real:0.9729537963867188\n",
            "d_loss_fake:0.0015550797106698155\n",
            "d_loss_wrong:0.5834236741065979\n",
            "d_loss:0.6327215880155563\n",
            "g_loss:[0.38813275, 0.38502485, 0.0015539542]\n",
            "Batch:83\n",
            "d_loss_real:0.7958230376243591\n",
            "d_loss_fake:0.0024146607611328363\n",
            "d_loss_wrong:0.6591798067092896\n",
            "d_loss:0.5633101314306259\n",
            "g_loss:[0.4007979, 0.39771283, 0.0015425452]\n",
            "Batch:84\n",
            "d_loss_real:0.7894240617752075\n",
            "d_loss_fake:0.0011698559392243624\n",
            "d_loss_wrong:0.6768307089805603\n",
            "d_loss:0.5642121732234955\n",
            "g_loss:[0.3752102, 0.371742, 0.0017340928]\n",
            "Batch:85\n",
            "d_loss_real:0.8106883764266968\n",
            "d_loss_fake:0.00118288304656744\n",
            "d_loss_wrong:0.6794220805168152\n",
            "d_loss:0.5754954218864441\n",
            "g_loss:[0.33837926, 0.3352512, 0.0015640275]\n",
            "Batch:86\n",
            "d_loss_real:0.811974048614502\n",
            "d_loss_fake:0.0065888529643416405\n",
            "d_loss_wrong:0.6742318272590637\n",
            "d_loss:0.5761922001838684\n",
            "g_loss:[0.3704746, 0.36759576, 0.0014394226]\n",
            "Batch:87\n",
            "d_loss_real:0.8293986320495605\n",
            "d_loss_fake:0.0011935237562283874\n",
            "d_loss_wrong:0.6389355659484863\n",
            "d_loss:0.5747315883636475\n",
            "g_loss:[0.3499123, 0.34597486, 0.0019687165]\n",
            "Batch:88\n",
            "d_loss_real:0.9420422315597534\n",
            "d_loss_fake:0.0050947582349181175\n",
            "d_loss_wrong:0.6827025413513184\n",
            "d_loss:0.6429704427719116\n",
            "g_loss:[0.35367513, 0.34944668, 0.0021142159]\n",
            "Batch:89\n",
            "d_loss_real:0.8713605403900146\n",
            "d_loss_fake:0.005115496926009655\n",
            "d_loss_wrong:0.7314565777778625\n",
            "d_loss:0.6198232918977737\n",
            "g_loss:[0.3873385, 0.38223812, 0.0025501885]\n",
            "Batch:90\n",
            "d_loss_real:0.7931080460548401\n",
            "d_loss_fake:0.01309206709265709\n",
            "d_loss_wrong:0.6653265357017517\n",
            "d_loss:0.5661586672067642\n",
            "g_loss:[0.35947663, 0.35493875, 0.0022689395]\n",
            "Batch:91\n",
            "d_loss_real:0.8272894620895386\n",
            "d_loss_fake:0.0008306666277348995\n",
            "d_loss_wrong:0.7241122126579285\n",
            "d_loss:0.5948804467916489\n",
            "g_loss:[0.4136988, 0.40993455, 0.0018821184]\n",
            "Batch:92\n",
            "d_loss_real:0.9034163951873779\n",
            "d_loss_fake:0.018151171505451202\n",
            "d_loss_wrong:0.636526346206665\n",
            "d_loss:0.6153775751590729\n",
            "g_loss:[0.49010944, 0.4845689, 0.0027702786]\n",
            "Batch:93\n",
            "d_loss_real:0.8742188215255737\n",
            "d_loss_fake:0.0024514663964509964\n",
            "d_loss_wrong:0.6219125390052795\n",
            "d_loss:0.5932004153728485\n",
            "g_loss:[0.7655632, 0.759388, 0.0030875665]\n",
            "Batch:94\n",
            "d_loss_real:0.8415809273719788\n",
            "d_loss_fake:0.0015365666477009654\n",
            "d_loss_wrong:0.6786201000213623\n",
            "d_loss:0.5908296257257462\n",
            "g_loss:[0.58688396, 0.58060014, 0.003141903]\n",
            "Batch:95\n",
            "d_loss_real:0.8259791135787964\n",
            "d_loss_fake:0.002577579114586115\n",
            "d_loss_wrong:0.6997290849685669\n",
            "d_loss:0.5885662287473679\n",
            "g_loss:[0.57151574, 0.56656253, 0.002476608]\n",
            "Batch:96\n",
            "d_loss_real:0.7998616695404053\n",
            "d_loss_fake:0.0016639443347230554\n",
            "d_loss_wrong:0.6865869164466858\n",
            "d_loss:0.5719935446977615\n",
            "g_loss:[0.5564242, 0.55011487, 0.003154661]\n",
            "Batch:97\n",
            "d_loss_real:0.8342282772064209\n",
            "d_loss_fake:0.0005958317196927965\n",
            "d_loss_wrong:0.6640409827232361\n",
            "d_loss:0.5832733362913132\n",
            "g_loss:[0.39649767, 0.390505, 0.0029963348]\n",
            "Batch:98\n",
            "d_loss_real:0.8391140699386597\n",
            "d_loss_fake:0.0025123381055891514\n",
            "d_loss_wrong:0.6740759015083313\n",
            "d_loss:0.5887040942907333\n",
            "g_loss:[0.475681, 0.46988118, 0.0028999145]\n",
            "Batch:99\n",
            "d_loss_real:0.8499071598052979\n",
            "d_loss_fake:0.0011310770642012358\n",
            "d_loss_wrong:0.6127628087997437\n",
            "d_loss:0.5784270465373993\n",
            "g_loss:[0.47861388, 0.47392324, 0.002345322]\n",
            "Batch:100\n",
            "d_loss_real:0.9073755741119385\n",
            "d_loss_fake:0.012403196655213833\n",
            "d_loss_wrong:0.5716913342475891\n",
            "d_loss:0.5997114181518555\n",
            "g_loss:[0.4043652, 0.40103617, 0.001664521]\n",
            "Batch:101\n",
            "d_loss_real:0.8887616395950317\n",
            "d_loss_fake:0.001758265309035778\n",
            "d_loss_wrong:0.6500717401504517\n",
            "d_loss:0.6073383241891861\n",
            "g_loss:[0.45974427, 0.45623964, 0.0017523172]\n",
            "Batch:102\n",
            "d_loss_real:0.8366349339485168\n",
            "d_loss_fake:0.0019418392330408096\n",
            "d_loss_wrong:0.6292946338653564\n",
            "d_loss:0.5761265903711319\n",
            "g_loss:[0.392577, 0.3886239, 0.001976554]\n",
            "Batch:103\n",
            "d_loss_real:0.8992394208908081\n",
            "d_loss_fake:0.0014111410127952695\n",
            "d_loss_wrong:0.6288819313049316\n",
            "d_loss:0.6071929782629013\n",
            "g_loss:[0.34579507, 0.3417753, 0.0020098882]\n",
            "Batch:104\n",
            "d_loss_real:0.9231926202774048\n",
            "d_loss_fake:0.009274747222661972\n",
            "d_loss_wrong:0.6110848188400269\n",
            "d_loss:0.6166861951351166\n",
            "g_loss:[0.37354568, 0.36967617, 0.0019347483]\n",
            "Batch:105\n",
            "d_loss_real:0.8664034008979797\n",
            "d_loss_fake:0.03181285411119461\n",
            "d_loss_wrong:0.6272003054618835\n",
            "d_loss:0.5979549884796143\n",
            "g_loss:[0.48231822, 0.47915956, 0.0015793345]\n",
            "Batch:106\n",
            "d_loss_real:0.8323935270309448\n",
            "d_loss_fake:0.013736352324485779\n",
            "d_loss_wrong:0.66781085729599\n",
            "d_loss:0.5865835696458817\n",
            "g_loss:[0.6256992, 0.6222161, 0.0017415498]\n",
            "Batch:107\n",
            "d_loss_real:0.8897395133972168\n",
            "d_loss_fake:0.012739731930196285\n",
            "d_loss_wrong:0.6208247542381287\n",
            "d_loss:0.60326087474823\n",
            "g_loss:[0.55239636, 0.54889554, 0.001750404]\n",
            "Batch:108\n",
            "d_loss_real:0.9003965854644775\n",
            "d_loss_fake:0.008522617630660534\n",
            "d_loss_wrong:0.6135720610618591\n",
            "d_loss:0.605721965432167\n",
            "g_loss:[0.4833082, 0.4803004, 0.0015038988]\n",
            "Batch:109\n",
            "d_loss_real:0.8923594951629639\n",
            "d_loss_fake:0.04577581584453583\n",
            "d_loss_wrong:0.622566282749176\n",
            "d_loss:0.6132652759552002\n",
            "g_loss:[0.84109896, 0.83744764, 0.0018256519]\n",
            "Batch:110\n",
            "d_loss_real:0.8910362720489502\n",
            "d_loss_fake:0.07061535120010376\n",
            "d_loss_wrong:0.6030377745628357\n",
            "d_loss:0.61393141746521\n",
            "g_loss:[0.9417314, 0.9371016, 0.0023149024]\n",
            "Batch:111\n",
            "d_loss_real:1.040293574333191\n",
            "d_loss_fake:0.007576602045446634\n",
            "d_loss_wrong:0.6007064580917358\n",
            "d_loss:0.6722175478935242\n",
            "g_loss:[1.0716425, 1.0671163, 0.0022631113]\n",
            "Batch:112\n",
            "d_loss_real:1.065059781074524\n",
            "d_loss_fake:0.04266269505023956\n",
            "d_loss_wrong:0.7762449979782104\n",
            "d_loss:0.7372568100690842\n",
            "g_loss:[1.4603755, 1.4555409, 0.0024173204]\n",
            "Batch:113\n",
            "d_loss_real:0.8327309489250183\n",
            "d_loss_fake:0.007886817678809166\n",
            "d_loss_wrong:0.6282800436019897\n",
            "d_loss:0.5754071921110153\n",
            "g_loss:[1.162693, 1.1572382, 0.0027274182]\n",
            "Batch:114\n",
            "d_loss_real:0.8780001401901245\n",
            "d_loss_fake:0.08867929130792618\n",
            "d_loss_wrong:0.583916187286377\n",
            "d_loss:0.6071489453315735\n",
            "g_loss:[1.4012579, 1.3966837, 0.0022870647]\n",
            "Batch:115\n",
            "d_loss_real:0.9073834419250488\n",
            "d_loss_fake:0.1430395245552063\n",
            "d_loss_wrong:0.5746579170227051\n",
            "d_loss:0.6331160813570023\n",
            "g_loss:[2.001724, 1.9973121, 0.0022059088]\n",
            "Batch:116\n",
            "d_loss_real:1.2096534967422485\n",
            "d_loss_fake:0.24448050558567047\n",
            "d_loss_wrong:0.6710863709449768\n",
            "d_loss:0.8337184637784958\n",
            "g_loss:[1.5634174, 1.5589595, 0.0022289758]\n",
            "Batch:117\n",
            "d_loss_real:0.8756990432739258\n",
            "d_loss_fake:0.24760952591896057\n",
            "d_loss_wrong:0.5855150818824768\n",
            "d_loss:0.6461306810379028\n",
            "g_loss:[1.5482922, 1.5450268, 0.0016326981]\n",
            "Batch:118\n",
            "d_loss_real:1.0543723106384277\n",
            "d_loss_fake:0.2018837034702301\n",
            "d_loss_wrong:0.5407594442367554\n",
            "d_loss:0.7128469347953796\n",
            "g_loss:[1.4543666, 1.4502205, 0.0020730258]\n",
            "Batch:119\n",
            "d_loss_real:1.0033912658691406\n",
            "d_loss_fake:0.2527599334716797\n",
            "d_loss_wrong:0.5192943215370178\n",
            "d_loss:0.6947091966867447\n",
            "g_loss:[1.6655432, 1.6623496, 0.0015967902]\n",
            "Batch:120\n",
            "d_loss_real:1.0045299530029297\n",
            "d_loss_fake:0.27734214067459106\n",
            "d_loss_wrong:0.5172291994094849\n",
            "d_loss:0.7009078115224838\n",
            "g_loss:[1.5254517, 1.5217377, 0.0018569556]\n",
            "Batch:121\n",
            "d_loss_real:1.0785855054855347\n",
            "d_loss_fake:0.212022602558136\n",
            "d_loss_wrong:0.48638206720352173\n",
            "d_loss:0.7138939201831818\n",
            "g_loss:[1.4140074, 1.4099058, 0.0020507898]\n",
            "Batch:122\n",
            "d_loss_real:1.1321078538894653\n",
            "d_loss_fake:0.22780056297779083\n",
            "d_loss_wrong:0.4820881187915802\n",
            "d_loss:0.7435261011123657\n",
            "g_loss:[1.7016534, 1.6971452, 0.0022540428]\n",
            "Batch:123\n",
            "d_loss_real:1.3154876232147217\n",
            "d_loss_fake:0.2332107424736023\n",
            "d_loss_wrong:0.48619234561920166\n",
            "d_loss:0.8375945836305618\n",
            "g_loss:[1.6488068, 1.6454847, 0.001661092]\n",
            "Batch:124\n",
            "d_loss_real:1.1334943771362305\n",
            "d_loss_fake:0.23577257990837097\n",
            "d_loss_wrong:0.42897528409957886\n",
            "d_loss:0.7329341471195221\n",
            "g_loss:[1.7117037, 1.7086632, 0.0015202097]\n",
            "Batch:125\n",
            "d_loss_real:1.0219976902008057\n",
            "d_loss_fake:0.19711804389953613\n",
            "d_loss_wrong:0.4980863034725189\n",
            "d_loss:0.6847999393939972\n",
            "g_loss:[1.5382662, 1.5342329, 0.0020166417]\n",
            "Batch:126\n",
            "d_loss_real:1.0268313884735107\n",
            "d_loss_fake:0.240849107503891\n",
            "d_loss_wrong:0.48691773414611816\n",
            "d_loss:0.6953574120998383\n",
            "g_loss:[1.5952897, 1.5908518, 0.002218951]\n",
            "Batch:127\n",
            "d_loss_real:1.1665709018707275\n",
            "d_loss_fake:0.1941085159778595\n",
            "d_loss_wrong:0.44542840123176575\n",
            "d_loss:0.7431696802377701\n",
            "g_loss:[1.419767, 1.4163249, 0.001721065]\n",
            "Batch:128\n",
            "d_loss_real:1.124845266342163\n",
            "d_loss_fake:0.20464222133159637\n",
            "d_loss_wrong:0.45501649379730225\n",
            "d_loss:0.7273373156785965\n",
            "g_loss:[1.2433066, 1.2389922, 0.0021572225]\n",
            "Batch:129\n",
            "d_loss_real:1.1393827199935913\n",
            "d_loss_fake:0.14697322249412537\n",
            "d_loss_wrong:0.45100873708724976\n",
            "d_loss:0.7191868424415588\n",
            "g_loss:[1.5729139, 1.5685502, 0.002181821]\n",
            "Batch:130\n",
            "d_loss_real:1.1332613229751587\n",
            "d_loss_fake:0.25418564677238464\n",
            "d_loss_wrong:0.502766489982605\n",
            "d_loss:0.7558687031269073\n",
            "g_loss:[1.3777522, 1.3743402, 0.0017060126]\n",
            "Batch:131\n",
            "d_loss_real:1.1996992826461792\n",
            "d_loss_fake:0.16577868163585663\n",
            "d_loss_wrong:0.49548834562301636\n",
            "d_loss:0.7651664018630981\n",
            "g_loss:[1.3947804, 1.3906765, 0.0020519353]\n",
            "Batch:132\n",
            "d_loss_real:1.0000693798065186\n",
            "d_loss_fake:0.16355150938034058\n",
            "d_loss_wrong:0.5333133339881897\n",
            "d_loss:0.6742509007453918\n",
            "g_loss:[1.5933366, 1.589577, 0.0018798352]\n",
            "Batch:133\n",
            "d_loss_real:1.0904386043548584\n",
            "d_loss_fake:0.127741277217865\n",
            "d_loss_wrong:0.518048107624054\n",
            "d_loss:0.7066666483879089\n",
            "g_loss:[1.6169256, 1.6141196, 0.0014029846]\n",
            "Batch:134\n",
            "d_loss_real:1.0866891145706177\n",
            "d_loss_fake:0.1779715120792389\n",
            "d_loss_wrong:0.563517153263092\n",
            "d_loss:0.7287167310714722\n",
            "g_loss:[1.6000338, 1.5967274, 0.0016532049]\n",
            "Batch:135\n",
            "d_loss_real:1.1495871543884277\n",
            "d_loss_fake:0.17327097058296204\n",
            "d_loss_wrong:0.6459793448448181\n",
            "d_loss:0.7796061635017395\n",
            "g_loss:[1.533644, 1.5305154, 0.0015642467]\n",
            "Batch:136\n",
            "d_loss_real:0.9866974949836731\n",
            "d_loss_fake:0.24859781563282013\n",
            "d_loss_wrong:0.5287264585494995\n",
            "d_loss:0.6876798123121262\n",
            "g_loss:[1.4337807, 1.4306875, 0.001546551]\n",
            "Batch:137\n",
            "d_loss_real:1.0737934112548828\n",
            "d_loss_fake:0.15379425883293152\n",
            "d_loss_wrong:0.5308244228363037\n",
            "d_loss:0.7080513834953308\n",
            "g_loss:[1.4952532, 1.4922817, 0.0014857558]\n",
            "Batch:138\n",
            "d_loss_real:1.0619111061096191\n",
            "d_loss_fake:0.1489214301109314\n",
            "d_loss_wrong:0.6037107110023499\n",
            "d_loss:0.7191135883331299\n",
            "g_loss:[1.4666378, 1.4628589, 0.0018894401]\n",
            "========================================\n",
            "Epoch is: 4\n",
            "Number of batches 138\n",
            "Batch:1\n",
            "d_loss_real:1.335849404335022\n",
            "d_loss_fake:0.2133583277463913\n",
            "d_loss_wrong:0.5601289868354797\n",
            "d_loss:0.861296534538269\n",
            "g_loss:[1.4298521, 1.425862, 0.0019950655]\n",
            "Batch:2\n",
            "d_loss_real:1.1168837547302246\n",
            "d_loss_fake:0.22938401997089386\n",
            "d_loss_wrong:0.5426299571990967\n",
            "d_loss:0.7514453679323196\n",
            "g_loss:[1.4186488, 1.414186, 0.002231413]\n",
            "Batch:3\n",
            "d_loss_real:1.0569713115692139\n",
            "d_loss_fake:0.11907100677490234\n",
            "d_loss_wrong:0.6494168043136597\n",
            "d_loss:0.7206076085567474\n",
            "g_loss:[1.2527975, 1.2481356, 0.002330962]\n",
            "Batch:4\n",
            "d_loss_real:1.0303542613983154\n",
            "d_loss_fake:0.10701622813940048\n",
            "d_loss_wrong:0.7311917543411255\n",
            "d_loss:0.7247291207313538\n",
            "g_loss:[1.3693856, 1.3658237, 0.0017809271]\n",
            "Batch:5\n",
            "d_loss_real:1.1121950149536133\n",
            "d_loss_fake:0.16526596248149872\n",
            "d_loss_wrong:0.6351827383041382\n",
            "d_loss:0.7562096863985062\n",
            "g_loss:[1.1326551, 1.1294504, 0.0016023753]\n",
            "Batch:6\n",
            "d_loss_real:1.0328856706619263\n",
            "d_loss_fake:0.13978202641010284\n",
            "d_loss_wrong:0.633600115776062\n",
            "d_loss:0.709788367152214\n",
            "g_loss:[1.0497291, 1.0463337, 0.0016976998]\n",
            "Batch:7\n",
            "d_loss_real:0.9278513193130493\n",
            "d_loss_fake:0.09261821955442429\n",
            "d_loss_wrong:0.6289969086647034\n",
            "d_loss:0.6443294435739517\n",
            "g_loss:[1.189554, 1.1863331, 0.0016104854]\n",
            "Batch:8\n",
            "d_loss_real:1.2110912799835205\n",
            "d_loss_fake:0.09789741784334183\n",
            "d_loss_wrong:0.5078974366188049\n",
            "d_loss:0.7569943517446518\n",
            "g_loss:[1.0875624, 1.0818148, 0.002873859]\n",
            "Batch:9\n",
            "d_loss_real:1.3728623390197754\n",
            "d_loss_fake:0.16633491218090057\n",
            "d_loss_wrong:0.7142338752746582\n",
            "d_loss:0.9065733700990677\n",
            "g_loss:[1.0515081, 1.0436102, 0.0039489157]\n",
            "Batch:10\n",
            "d_loss_real:1.0153234004974365\n",
            "d_loss_fake:0.18975701928138733\n",
            "d_loss_wrong:0.630843997001648\n",
            "d_loss:0.7128119468688965\n",
            "g_loss:[1.1714059, 1.1652961, 0.0030549227]\n",
            "Batch:11\n",
            "d_loss_real:1.2867071628570557\n",
            "d_loss_fake:0.11550572514533997\n",
            "d_loss_wrong:0.6440340280532837\n",
            "d_loss:0.8332385122776031\n",
            "g_loss:[1.0123053, 1.0074707, 0.002417257]\n",
            "Batch:12\n",
            "d_loss_real:1.082375407218933\n",
            "d_loss_fake:0.1204386055469513\n",
            "d_loss_wrong:0.5200967788696289\n",
            "d_loss:0.701321542263031\n",
            "g_loss:[1.0053933, 1.0018282, 0.0017825232]\n",
            "Batch:13\n",
            "d_loss_real:1.0973883867263794\n",
            "d_loss_fake:0.049245718866586685\n",
            "d_loss_wrong:0.6049951910972595\n",
            "d_loss:0.7122544199228287\n",
            "g_loss:[0.84649104, 0.8428121, 0.0018394642]\n",
            "Batch:14\n",
            "d_loss_real:1.0589567422866821\n",
            "d_loss_fake:0.03846509009599686\n",
            "d_loss_wrong:0.5790448784828186\n",
            "d_loss:0.6838558614253998\n",
            "g_loss:[0.84622675, 0.8431591, 0.0015338368]\n",
            "Batch:15\n",
            "d_loss_real:1.0593276023864746\n",
            "d_loss_fake:0.14932028949260712\n",
            "d_loss_wrong:0.615544855594635\n",
            "d_loss:0.7208800911903381\n",
            "g_loss:[1.2740424, 1.2695448, 0.002248737]\n",
            "Batch:16\n",
            "d_loss_real:1.1497678756713867\n",
            "d_loss_fake:0.07580502331256866\n",
            "d_loss_wrong:0.7879061102867126\n",
            "d_loss:0.7908117175102234\n",
            "g_loss:[0.9831353, 0.9787522, 0.0021915552]\n",
            "Batch:17\n",
            "d_loss_real:0.9470161199569702\n",
            "d_loss_fake:0.07468322664499283\n",
            "d_loss_wrong:0.7647178769111633\n",
            "d_loss:0.6833583414554596\n",
            "g_loss:[1.0148532, 1.0108678, 0.0019927318]\n",
            "Batch:18\n",
            "d_loss_real:0.9364240169525146\n",
            "d_loss_fake:0.11242610216140747\n",
            "d_loss_wrong:0.6036085486412048\n",
            "d_loss:0.6472206711769104\n",
            "g_loss:[1.0259762, 1.0227635, 0.0016063632]\n",
            "Batch:19\n",
            "d_loss_real:0.9926790595054626\n",
            "d_loss_fake:0.05435003340244293\n",
            "d_loss_wrong:0.6309096217155457\n",
            "d_loss:0.6676544398069382\n",
            "g_loss:[0.9968033, 0.9931606, 0.0018213412]\n",
            "Batch:20\n",
            "d_loss_real:1.0068200826644897\n",
            "d_loss_fake:0.017477717250585556\n",
            "d_loss_wrong:0.64131098985672\n",
            "d_loss:0.6681072115898132\n",
            "g_loss:[0.8536855, 0.8501847, 0.0017503991]\n",
            "Batch:21\n",
            "d_loss_real:0.8830972909927368\n",
            "d_loss_fake:0.015294408425688744\n",
            "d_loss_wrong:0.6327764391899109\n",
            "d_loss:0.603566363453865\n",
            "g_loss:[0.8101774, 0.80670846, 0.0017344775]\n",
            "Batch:22\n",
            "d_loss_real:0.9138836860656738\n",
            "d_loss_fake:0.0447818823158741\n",
            "d_loss_wrong:0.7141636610031128\n",
            "d_loss:0.6466782242059708\n",
            "g_loss:[0.7909729, 0.7880734, 0.0014497439]\n",
            "Batch:23\n",
            "d_loss_real:0.9787378311157227\n",
            "d_loss_fake:0.02816489338874817\n",
            "d_loss_wrong:0.7043702006340027\n",
            "d_loss:0.6725026965141296\n",
            "g_loss:[0.8507274, 0.84747565, 0.0016258641]\n",
            "Batch:24\n",
            "d_loss_real:0.8337597250938416\n",
            "d_loss_fake:0.0363692045211792\n",
            "d_loss_wrong:0.6747832298278809\n",
            "d_loss:0.5946679711341858\n",
            "g_loss:[0.88373244, 0.87985325, 0.0019395946]\n",
            "Batch:25\n",
            "d_loss_real:1.0246033668518066\n",
            "d_loss_fake:0.04372653365135193\n",
            "d_loss_wrong:0.66531902551651\n",
            "d_loss:0.6895630657672882\n",
            "g_loss:[0.89610666, 0.89164984, 0.002228417]\n",
            "Batch:26\n",
            "d_loss_real:0.8348971605300903\n",
            "d_loss_fake:0.004260076209902763\n",
            "d_loss_wrong:0.6636890172958374\n",
            "d_loss:0.5844358503818512\n",
            "g_loss:[0.8323884, 0.82886386, 0.0017622804]\n",
            "Batch:27\n",
            "d_loss_real:0.9320127964019775\n",
            "d_loss_fake:0.013848556205630302\n",
            "d_loss_wrong:0.7307190299034119\n",
            "d_loss:0.6521482914686203\n",
            "g_loss:[0.83834887, 0.83510613, 0.0016213672]\n",
            "Batch:28\n",
            "d_loss_real:0.8081220984458923\n",
            "d_loss_fake:0.021853819489479065\n",
            "d_loss_wrong:0.6620408296585083\n",
            "d_loss:0.5750347077846527\n",
            "g_loss:[0.91463125, 0.90922105, 0.0027051042]\n",
            "Batch:29\n",
            "d_loss_real:0.9049454927444458\n",
            "d_loss_fake:0.03588953614234924\n",
            "d_loss_wrong:0.6446037888526917\n",
            "d_loss:0.6225960850715637\n",
            "g_loss:[0.9345335, 0.9308536, 0.0018399253]\n",
            "Batch:30\n",
            "d_loss_real:0.9287551045417786\n",
            "d_loss_fake:0.006971332244575024\n",
            "d_loss_wrong:0.7555532455444336\n",
            "d_loss:0.6550087034702301\n",
            "g_loss:[0.81840044, 0.81450963, 0.0019454121]\n",
            "Batch:31\n",
            "d_loss_real:0.8809416890144348\n",
            "d_loss_fake:0.015578377060592175\n",
            "d_loss_wrong:0.6658293008804321\n",
            "d_loss:0.6108227670192719\n",
            "g_loss:[0.8723038, 0.8681159, 0.0020939314]\n",
            "Batch:32\n",
            "d_loss_real:0.958458662033081\n",
            "d_loss_fake:0.09343720972537994\n",
            "d_loss_wrong:0.5989386439323425\n",
            "d_loss:0.6523232907056808\n",
            "g_loss:[0.93947196, 0.9350151, 0.0022284377]\n",
            "Batch:33\n",
            "d_loss_real:0.9664881229400635\n",
            "d_loss_fake:0.008351745083928108\n",
            "d_loss_wrong:0.6460409164428711\n",
            "d_loss:0.6468422263860703\n",
            "g_loss:[0.879066, 0.8752752, 0.0018953837]\n",
            "Batch:34\n",
            "d_loss_real:0.9025354981422424\n",
            "d_loss_fake:0.08041337132453918\n",
            "d_loss_wrong:0.608574628829956\n",
            "d_loss:0.6235147416591644\n",
            "g_loss:[0.8850486, 0.8810238, 0.0020124086]\n",
            "Batch:35\n",
            "d_loss_real:0.9404908418655396\n",
            "d_loss_fake:0.026191329583525658\n",
            "d_loss_wrong:0.6467157006263733\n",
            "d_loss:0.6384721845388412\n",
            "g_loss:[0.8862785, 0.8820488, 0.0021148715]\n",
            "Batch:36\n",
            "d_loss_real:0.8734208345413208\n",
            "d_loss_fake:0.02228485234081745\n",
            "d_loss_wrong:0.673617422580719\n",
            "d_loss:0.6106859892606735\n",
            "g_loss:[0.99069047, 0.9854266, 0.0026319216]\n",
            "Batch:37\n",
            "d_loss_real:1.0165059566497803\n",
            "d_loss_fake:0.08615639805793762\n",
            "d_loss_wrong:0.7184206247329712\n",
            "d_loss:0.7093972265720367\n",
            "g_loss:[0.9687948, 0.9635508, 0.0026220009]\n",
            "Batch:38\n",
            "d_loss_real:0.8580074310302734\n",
            "d_loss_fake:0.025400474667549133\n",
            "d_loss_wrong:0.7330688834190369\n",
            "d_loss:0.6186210513114929\n",
            "g_loss:[0.9112933, 0.9071343, 0.0020795055]\n",
            "Batch:39\n",
            "d_loss_real:0.9469053149223328\n",
            "d_loss_fake:0.019328683614730835\n",
            "d_loss_wrong:0.617552638053894\n",
            "d_loss:0.6326729953289032\n",
            "g_loss:[0.7961294, 0.79111665, 0.0025063767]\n",
            "Batch:40\n",
            "d_loss_real:0.9265404939651489\n",
            "d_loss_fake:0.04385649412870407\n",
            "d_loss_wrong:0.6520780920982361\n",
            "d_loss:0.6372538954019547\n",
            "g_loss:[0.86927056, 0.86479753, 0.0022365253]\n",
            "Batch:41\n",
            "d_loss_real:0.961923360824585\n",
            "d_loss_fake:0.03971431031823158\n",
            "d_loss_wrong:0.6171901822090149\n",
            "d_loss:0.6451878100633621\n",
            "g_loss:[0.8659788, 0.860607, 0.0026858742]\n",
            "Batch:42\n",
            "d_loss_real:0.9464653134346008\n",
            "d_loss_fake:0.02916339784860611\n",
            "d_loss_wrong:0.6971181035041809\n",
            "d_loss:0.6548030376434326\n",
            "g_loss:[0.873709, 0.86849976, 0.0026046387]\n",
            "Batch:43\n",
            "d_loss_real:0.839332103729248\n",
            "d_loss_fake:0.02028574049472809\n",
            "d_loss_wrong:0.6609472632408142\n",
            "d_loss:0.5899742990732193\n",
            "g_loss:[0.8482366, 0.8435455, 0.0023455704]\n",
            "Batch:44\n",
            "d_loss_real:0.876962423324585\n",
            "d_loss_fake:0.028256744146347046\n",
            "d_loss_wrong:0.6778838038444519\n",
            "d_loss:0.6150163412094116\n",
            "g_loss:[0.85411155, 0.8488231, 0.0026442506]\n",
            "Batch:45\n",
            "d_loss_real:0.9120684862136841\n",
            "d_loss_fake:0.002467020647600293\n",
            "d_loss_wrong:0.6290885806083679\n",
            "d_loss:0.6139231473207474\n",
            "g_loss:[0.8018851, 0.7958456, 0.0030197552]\n",
            "Batch:46\n",
            "d_loss_real:0.8923697471618652\n",
            "d_loss_fake:0.033005647361278534\n",
            "d_loss_wrong:0.6698639988899231\n",
            "d_loss:0.6219022870063782\n",
            "g_loss:[0.7180004, 0.71299016, 0.002505118]\n",
            "Batch:47\n",
            "d_loss_real:0.8983476758003235\n",
            "d_loss_fake:0.005786994472146034\n",
            "d_loss_wrong:0.6449403166770935\n",
            "d_loss:0.6118556708097458\n",
            "g_loss:[0.7647141, 0.7593776, 0.0026682485]\n",
            "Batch:48\n",
            "d_loss_real:0.8993241190910339\n",
            "d_loss_fake:0.018619954586029053\n",
            "d_loss_wrong:0.6623791456222534\n",
            "d_loss:0.6199118345975876\n",
            "g_loss:[0.8267277, 0.8216175, 0.0025550944]\n",
            "Batch:49\n",
            "d_loss_real:0.8444182872772217\n",
            "d_loss_fake:0.004122281447052956\n",
            "d_loss_wrong:0.6441793441772461\n",
            "d_loss:0.5842845439910889\n",
            "g_loss:[0.738863, 0.73302627, 0.0029183677]\n",
            "Batch:50\n",
            "d_loss_real:0.9531568884849548\n",
            "d_loss_fake:0.01483334880322218\n",
            "d_loss_wrong:0.6594945788383484\n",
            "d_loss:0.6451604217290878\n",
            "g_loss:[0.70441765, 0.7009263, 0.001745685]\n",
            "Batch:51\n",
            "d_loss_real:0.9029111862182617\n",
            "d_loss_fake:0.024231933057308197\n",
            "d_loss_wrong:0.7214035987854004\n",
            "d_loss:0.6378644704818726\n",
            "g_loss:[0.75242376, 0.7488531, 0.0017853491]\n",
            "Batch:52\n",
            "d_loss_real:0.877440333366394\n",
            "d_loss_fake:0.07980941236019135\n",
            "d_loss_wrong:0.691569983959198\n",
            "d_loss:0.6315650194883347\n",
            "g_loss:[0.77663845, 0.77368814, 0.0014751598]\n",
            "Batch:53\n",
            "d_loss_real:0.8108856678009033\n",
            "d_loss_fake:0.0034734595101326704\n",
            "d_loss_wrong:0.657108724117279\n",
            "d_loss:0.5705883800983429\n",
            "g_loss:[0.86058265, 0.8559935, 0.0022945567]\n",
            "Batch:54\n",
            "d_loss_real:0.9483106136322021\n",
            "d_loss_fake:0.025853518396615982\n",
            "d_loss_wrong:0.6918634176254272\n",
            "d_loss:0.6535845398902893\n",
            "g_loss:[0.67101747, 0.6667758, 0.002120822]\n",
            "Batch:55\n",
            "d_loss_real:0.8836942911148071\n",
            "d_loss_fake:0.016153965145349503\n",
            "d_loss_wrong:0.6325006484985352\n",
            "d_loss:0.6040108054876328\n",
            "g_loss:[0.6735175, 0.6692114, 0.002153054]\n",
            "Batch:56\n",
            "d_loss_real:0.9014690518379211\n",
            "d_loss_fake:0.005006466526538134\n",
            "d_loss_wrong:0.6489651203155518\n",
            "d_loss:0.6142274290323257\n",
            "g_loss:[0.77035475, 0.7660039, 0.002175417]\n",
            "Batch:57\n",
            "d_loss_real:0.8886393904685974\n",
            "d_loss_fake:0.012027169577777386\n",
            "d_loss_wrong:0.6606497764587402\n",
            "d_loss:0.6124889254570007\n",
            "g_loss:[0.66950434, 0.6646006, 0.0024518683]\n",
            "Batch:58\n",
            "d_loss_real:0.8424718379974365\n",
            "d_loss_fake:0.023696348071098328\n",
            "d_loss_wrong:0.6680593490600586\n",
            "d_loss:0.5941748470067978\n",
            "g_loss:[0.65564394, 0.6515727, 0.0020356204]\n",
            "Batch:59\n",
            "d_loss_real:0.8917030096054077\n",
            "d_loss_fake:0.008088731206953526\n",
            "d_loss_wrong:0.6909789443016052\n",
            "d_loss:0.6206184178590775\n",
            "g_loss:[0.6917111, 0.6875559, 0.002077614]\n",
            "Batch:60\n",
            "d_loss_real:0.8940587043762207\n",
            "d_loss_fake:0.005679004825651646\n",
            "d_loss_wrong:0.6437767148017883\n",
            "d_loss:0.6093932837247849\n",
            "g_loss:[0.6221986, 0.618259, 0.0019697873]\n",
            "Batch:61\n",
            "d_loss_real:0.8773630857467651\n",
            "d_loss_fake:0.04752657189965248\n",
            "d_loss_wrong:0.6582552194595337\n",
            "d_loss:0.6151269972324371\n",
            "g_loss:[0.8277114, 0.82403517, 0.0018381325]\n",
            "Batch:62\n",
            "d_loss_real:0.8823748826980591\n",
            "d_loss_fake:0.005956493318080902\n",
            "d_loss_wrong:0.6513227224349976\n",
            "d_loss:0.6055072396993637\n",
            "g_loss:[0.6420075, 0.63813496, 0.0019362855]\n",
            "Batch:63\n",
            "d_loss_real:0.9052143096923828\n",
            "d_loss_fake:0.007676859386265278\n",
            "d_loss_wrong:0.6371374130249023\n",
            "d_loss:0.6138107180595398\n",
            "g_loss:[0.8679369, 0.86397004, 0.0019834482]\n",
            "Batch:64\n",
            "d_loss_real:0.8585118055343628\n",
            "d_loss_fake:0.26160767674446106\n",
            "d_loss_wrong:0.5673642158508301\n",
            "d_loss:0.6364988684654236\n",
            "g_loss:[4.1579843, 4.1539154, 0.002034387]\n",
            "Batch:65\n",
            "d_loss_real:1.065429449081421\n",
            "d_loss_fake:0.23971492052078247\n",
            "d_loss_wrong:0.528926432132721\n",
            "d_loss:0.7248750627040863\n",
            "g_loss:[2.5860329, 2.5808322, 0.0026002978]\n",
            "Batch:66\n",
            "d_loss_real:1.2036727666854858\n",
            "d_loss_fake:0.05065634101629257\n",
            "d_loss_wrong:0.5705676674842834\n",
            "d_loss:0.7571423798799515\n",
            "g_loss:[1.2606955, 1.2568436, 0.0019259248]\n",
            "Batch:67\n",
            "d_loss_real:0.956601619720459\n",
            "d_loss_fake:0.021091021597385406\n",
            "d_loss_wrong:0.6076302528381348\n",
            "d_loss:0.635481134057045\n",
            "g_loss:[1.1256317, 1.1220237, 0.0018040091]\n",
            "Batch:68\n",
            "d_loss_real:0.8853306770324707\n",
            "d_loss_fake:0.022670898586511612\n",
            "d_loss_wrong:0.6697995662689209\n",
            "d_loss:0.6157829612493515\n",
            "g_loss:[1.2921149, 1.287107, 0.0025039162]\n",
            "Batch:69\n",
            "d_loss_real:0.9371471405029297\n",
            "d_loss_fake:0.28522586822509766\n",
            "d_loss_wrong:0.6187124252319336\n",
            "d_loss:0.6945581436157227\n",
            "g_loss:[2.698008, 2.692829, 0.0025896318]\n",
            "Batch:70\n",
            "d_loss_real:1.0379083156585693\n",
            "d_loss_fake:0.020672932267189026\n",
            "d_loss_wrong:0.606382429599762\n",
            "d_loss:0.6757179945707321\n",
            "g_loss:[2.2680633, 2.2630656, 0.0024989005]\n",
            "Batch:71\n",
            "d_loss_real:0.9283005595207214\n",
            "d_loss_fake:0.008040785789489746\n",
            "d_loss_wrong:0.6151928901672363\n",
            "d_loss:0.6199586987495422\n",
            "g_loss:[1.2889835, 1.285398, 0.0017927035]\n",
            "Batch:72\n",
            "d_loss_real:0.9487260580062866\n",
            "d_loss_fake:0.01483055017888546\n",
            "d_loss_wrong:0.643237829208374\n",
            "d_loss:0.638880118727684\n",
            "g_loss:[1.2699174, 1.2664537, 0.001731839]\n",
            "Batch:73\n",
            "d_loss_real:0.8559991121292114\n",
            "d_loss_fake:0.011801978573203087\n",
            "d_loss_wrong:0.6512148976325989\n",
            "d_loss:0.593753769993782\n",
            "g_loss:[1.0994526, 1.0964888, 0.0014818828]\n",
            "Batch:74\n",
            "d_loss_real:0.8282749652862549\n",
            "d_loss_fake:0.004166346974670887\n",
            "d_loss_wrong:0.6267420649528503\n",
            "d_loss:0.57186459004879\n",
            "g_loss:[1.1566081, 1.15365, 0.0014790508]\n",
            "Batch:75\n",
            "d_loss_real:0.9008906483650208\n",
            "d_loss_fake:0.006515516899526119\n",
            "d_loss_wrong:0.6414883136749268\n",
            "d_loss:0.6124462783336639\n",
            "g_loss:[1.0855844, 1.0825756, 0.0015044454]\n",
            "Batch:76\n",
            "d_loss_real:0.8658128380775452\n",
            "d_loss_fake:0.0037811927031725645\n",
            "d_loss_wrong:0.638603687286377\n",
            "d_loss:0.5935026407241821\n",
            "g_loss:[1.0217817, 1.0188202, 0.0014807589]\n",
            "Batch:77\n",
            "d_loss_real:0.8696691393852234\n",
            "d_loss_fake:0.0072963908314704895\n",
            "d_loss_wrong:0.6634840369224548\n",
            "d_loss:0.6025296747684479\n",
            "g_loss:[0.98325783, 0.98028624, 0.0014857915]\n",
            "Batch:78\n",
            "d_loss_real:0.8721638321876526\n",
            "d_loss_fake:0.016058113425970078\n",
            "d_loss_wrong:0.6503843069076538\n",
            "d_loss:0.6026925146579742\n",
            "g_loss:[0.96199393, 0.9588513, 0.0015713397]\n",
            "Batch:79\n",
            "d_loss_real:0.8883611559867859\n",
            "d_loss_fake:0.010150328278541565\n",
            "d_loss_wrong:0.6479334831237793\n",
            "d_loss:0.6087015271186829\n",
            "g_loss:[1.0018122, 0.9985315, 0.0016403676]\n",
            "Batch:80\n",
            "d_loss_real:0.8222492933273315\n",
            "d_loss_fake:0.006952364929020405\n",
            "d_loss_wrong:0.702162504196167\n",
            "d_loss:0.5884033590555191\n",
            "g_loss:[0.92658854, 0.9238454, 0.0013715699]\n",
            "Batch:81\n",
            "d_loss_real:0.8178544044494629\n",
            "d_loss_fake:0.00901404581964016\n",
            "d_loss_wrong:0.6205505132675171\n",
            "d_loss:0.5663183480501175\n",
            "g_loss:[0.9405757, 0.93705994, 0.001757885]\n",
            "Batch:82\n",
            "d_loss_real:0.9040199518203735\n",
            "d_loss_fake:0.02310982719063759\n",
            "d_loss_wrong:0.6200360655784607\n",
            "d_loss:0.6127964556217194\n",
            "g_loss:[0.9691707, 0.9661708, 0.0014999536]\n",
            "Batch:83\n",
            "d_loss_real:0.8521329164505005\n",
            "d_loss_fake:0.022904811426997185\n",
            "d_loss_wrong:0.6561314463615417\n",
            "d_loss:0.5958255231380463\n",
            "g_loss:[1.0976963, 1.094893, 0.0014016414]\n",
            "Batch:84\n",
            "d_loss_real:0.9344699382781982\n",
            "d_loss_fake:0.07759299129247665\n",
            "d_loss_wrong:0.588054358959198\n",
            "d_loss:0.6336468011140823\n",
            "g_loss:[3.4585001, 3.4553456, 0.0015772289]\n",
            "Batch:85\n",
            "d_loss_real:1.4074373245239258\n",
            "d_loss_fake:0.4199496805667877\n",
            "d_loss_wrong:0.6327217817306519\n",
            "d_loss:0.9668865203857422\n",
            "g_loss:[1.5408597, 1.5377679, 0.0015459136]\n",
            "Batch:86\n",
            "d_loss_real:0.9676107168197632\n",
            "d_loss_fake:0.23860695958137512\n",
            "d_loss_wrong:0.533006489276886\n",
            "d_loss:0.6767087280750275\n",
            "g_loss:[1.9135045, 1.9106832, 0.0014106419]\n",
            "Batch:87\n",
            "d_loss_real:0.9942054152488708\n",
            "d_loss_fake:0.10391828417778015\n",
            "d_loss_wrong:0.546149730682373\n",
            "d_loss:0.6596197187900543\n",
            "g_loss:[2.1607685, 2.15747, 0.0016493102]\n",
            "Batch:88\n",
            "d_loss_real:1.1480798721313477\n",
            "d_loss_fake:0.2334754467010498\n",
            "d_loss_wrong:0.5518842339515686\n",
            "d_loss:0.7703798562288284\n",
            "g_loss:[1.5606794, 1.5569704, 0.0018545615]\n",
            "Batch:89\n",
            "d_loss_real:1.1307249069213867\n",
            "d_loss_fake:0.22945234179496765\n",
            "d_loss_wrong:0.6182071566581726\n",
            "d_loss:0.7772773206233978\n",
            "g_loss:[1.4627212, 1.4576578, 0.0025317124]\n",
            "Batch:90\n",
            "d_loss_real:0.9943269491195679\n",
            "d_loss_fake:0.17634236812591553\n",
            "d_loss_wrong:0.5229045152664185\n",
            "d_loss:0.6719751954078674\n",
            "g_loss:[1.6504217, 1.6457937, 0.0023140549]\n",
            "Batch:91\n",
            "d_loss_real:1.116623878479004\n",
            "d_loss_fake:0.12443505227565765\n",
            "d_loss_wrong:0.5481170415878296\n",
            "d_loss:0.7264499664306641\n",
            "g_loss:[1.56034, 1.5563039, 0.0020181215]\n",
            "Batch:92\n",
            "d_loss_real:1.050025463104248\n",
            "d_loss_fake:0.07099983841180801\n",
            "d_loss_wrong:0.5847571492195129\n",
            "d_loss:0.6889519840478897\n",
            "g_loss:[1.2903969, 1.2852454, 0.0025757307]\n",
            "Batch:93\n",
            "d_loss_real:1.0297741889953613\n",
            "d_loss_fake:0.1262274533510208\n",
            "d_loss_wrong:0.5426338911056519\n",
            "d_loss:0.6821024268865585\n",
            "g_loss:[1.4266185, 1.4212307, 0.0026939132]\n",
            "Batch:94\n",
            "d_loss_real:1.000087022781372\n",
            "d_loss_fake:0.061008207499980927\n",
            "d_loss_wrong:0.5921280980110168\n",
            "d_loss:0.6633275896310806\n",
            "g_loss:[1.5974966, 1.592257, 0.0026198043]\n",
            "Batch:95\n",
            "d_loss_real:1.0574709177017212\n",
            "d_loss_fake:0.04010000079870224\n",
            "d_loss_wrong:0.5855622291564941\n",
            "d_loss:0.6851510107517242\n",
            "g_loss:[1.4282547, 1.4234469, 0.002403919]\n",
            "Batch:96\n",
            "d_loss_real:0.9444860219955444\n",
            "d_loss_fake:0.07245974242687225\n",
            "d_loss_wrong:0.6134120225906372\n",
            "d_loss:0.6437109559774399\n",
            "g_loss:[1.5588821, 1.5531898, 0.0028461916]\n",
            "Batch:97\n",
            "d_loss_real:0.9025602340698242\n",
            "d_loss_fake:0.06898237019777298\n",
            "d_loss_wrong:0.6199017763137817\n",
            "d_loss:0.6235011518001556\n",
            "g_loss:[1.7784448, 1.7731106, 0.0026670718]\n",
            "Batch:98\n",
            "d_loss_real:1.0213050842285156\n",
            "d_loss_fake:0.14196768403053284\n",
            "d_loss_wrong:0.5962943434715271\n",
            "d_loss:0.6952180564403534\n",
            "g_loss:[1.5690325, 1.5631287, 0.002951936]\n",
            "Batch:99\n",
            "d_loss_real:0.9826352596282959\n",
            "d_loss_fake:0.1403239369392395\n",
            "d_loss_wrong:0.5567859411239624\n",
            "d_loss:0.6655950993299484\n",
            "g_loss:[1.5235175, 1.5188384, 0.002339545]\n",
            "Batch:100\n",
            "d_loss_real:1.0739827156066895\n",
            "d_loss_fake:0.1611616611480713\n",
            "d_loss_wrong:0.5562335252761841\n",
            "d_loss:0.7163401544094086\n",
            "g_loss:[2.2944827, 2.290972, 0.0017553535]\n",
            "Batch:101\n",
            "d_loss_real:1.075283169746399\n",
            "d_loss_fake:0.1588141918182373\n",
            "d_loss_wrong:0.5798571705818176\n",
            "d_loss:0.7223094254732132\n",
            "g_loss:[1.8894978, 1.8858861, 0.0018058496]\n",
            "Batch:102\n",
            "d_loss_real:0.9163789749145508\n",
            "d_loss_fake:0.1328546404838562\n",
            "d_loss_wrong:0.5698535442352295\n",
            "d_loss:0.6338665336370468\n",
            "g_loss:[2.2306998, 2.2271452, 0.0017772819]\n",
            "Batch:103\n",
            "d_loss_real:1.0724035501480103\n",
            "d_loss_fake:0.12884443998336792\n",
            "d_loss_wrong:0.5672175288200378\n",
            "d_loss:0.7102172672748566\n",
            "g_loss:[2.0130978, 2.0096526, 0.0017225218]\n",
            "Batch:104\n",
            "d_loss_real:1.058030605316162\n",
            "d_loss_fake:0.07620950788259506\n",
            "d_loss_wrong:0.5981749892234802\n",
            "d_loss:0.6976114213466644\n",
            "g_loss:[1.7935543, 1.7899673, 0.0017934856]\n",
            "Batch:105\n",
            "d_loss_real:1.0287785530090332\n",
            "d_loss_fake:0.06944594532251358\n",
            "d_loss_wrong:0.5768406391143799\n",
            "d_loss:0.6759609282016754\n",
            "g_loss:[1.3263971, 1.3228695, 0.0017637903]\n",
            "Batch:106\n",
            "d_loss_real:1.0070397853851318\n",
            "d_loss_fake:0.05667620897293091\n",
            "d_loss_wrong:0.5804325938224792\n",
            "d_loss:0.6627970933914185\n",
            "g_loss:[0.9672701, 0.9632513, 0.0020093876]\n",
            "Batch:107\n",
            "d_loss_real:0.904422402381897\n",
            "d_loss_fake:0.1308012455701828\n",
            "d_loss_wrong:0.621779203414917\n",
            "d_loss:0.6403563171625137\n",
            "g_loss:[1.5715175, 1.5674468, 0.0020353214]\n",
            "Batch:108\n",
            "d_loss_real:0.960834264755249\n",
            "d_loss_fake:0.038791194558143616\n",
            "d_loss_wrong:0.6322139501571655\n",
            "d_loss:0.6481684148311615\n",
            "g_loss:[1.2212826, 1.2176926, 0.0017950066]\n",
            "Batch:109\n",
            "d_loss_real:1.0415730476379395\n",
            "d_loss_fake:0.014583990909159184\n",
            "d_loss_wrong:0.6331588625907898\n",
            "d_loss:0.6827222406864166\n",
            "g_loss:[0.94253755, 0.93910456, 0.0017165004]\n",
            "Batch:110\n",
            "d_loss_real:0.9375577569007874\n",
            "d_loss_fake:0.05230005830526352\n",
            "d_loss_wrong:0.6065815687179565\n",
            "d_loss:0.6334992796182632\n",
            "g_loss:[0.85023683, 0.8461057, 0.002065569]\n",
            "Batch:111\n",
            "d_loss_real:0.9200142025947571\n",
            "d_loss_fake:0.052922360599040985\n",
            "d_loss_wrong:0.666388988494873\n",
            "d_loss:0.6398349404335022\n",
            "g_loss:[1.0693696, 1.0653479, 0.0020108314]\n",
            "Batch:112\n",
            "d_loss_real:1.1017595529556274\n",
            "d_loss_fake:0.01511539239436388\n",
            "d_loss_wrong:0.8652052283287048\n",
            "d_loss:0.7709599286317825\n",
            "g_loss:[0.9612327, 0.9573859, 0.0019234116]\n",
            "Batch:113\n",
            "d_loss_real:0.8185118436813354\n",
            "d_loss_fake:0.005193127319216728\n",
            "d_loss_wrong:0.6667335033416748\n",
            "d_loss:0.5772375762462616\n",
            "g_loss:[0.96110046, 0.95690566, 0.002097406]\n",
            "Batch:114\n",
            "d_loss_real:0.8558396100997925\n",
            "d_loss_fake:0.0038690429646521807\n",
            "d_loss_wrong:0.6538087725639343\n",
            "d_loss:0.5923392623662949\n",
            "g_loss:[0.93517154, 0.93156374, 0.0018038998]\n",
            "Batch:115\n",
            "d_loss_real:0.8754895329475403\n",
            "d_loss_fake:0.002223038114607334\n",
            "d_loss_wrong:0.6413305401802063\n",
            "d_loss:0.5986331552267075\n",
            "g_loss:[0.84683186, 0.8432219, 0.0018049642]\n",
            "Batch:116\n",
            "d_loss_real:0.9386779069900513\n",
            "d_loss_fake:0.011173682287335396\n",
            "d_loss_wrong:0.7053225040435791\n",
            "d_loss:0.6484629958868027\n",
            "g_loss:[0.89994305, 0.8964349, 0.001754073]\n",
            "Batch:117\n",
            "d_loss_real:0.865953803062439\n",
            "d_loss_fake:0.028456149622797966\n",
            "d_loss_wrong:0.6274886131286621\n",
            "d_loss:0.5969630926847458\n",
            "g_loss:[1.0027251, 0.9991473, 0.0017888892]\n",
            "Batch:118\n",
            "d_loss_real:0.8370733261108398\n",
            "d_loss_fake:0.01296803168952465\n",
            "d_loss_wrong:0.6443900465965271\n",
            "d_loss:0.5828761756420135\n",
            "g_loss:[0.88633645, 0.88271445, 0.001810994]\n",
            "Batch:119\n",
            "d_loss_real:0.8639818429946899\n",
            "d_loss_fake:0.008647866547107697\n",
            "d_loss_wrong:0.6694848537445068\n",
            "d_loss:0.6015240997076035\n",
            "g_loss:[0.9388844, 0.9357959, 0.0015442452]\n",
            "Batch:120\n",
            "d_loss_real:0.8311901092529297\n",
            "d_loss_fake:0.006923342123627663\n",
            "d_loss_wrong:0.6455248594284058\n",
            "d_loss:0.5787070989608765\n",
            "g_loss:[0.81203264, 0.8082372, 0.0018977225]\n",
            "Batch:121\n",
            "d_loss_real:0.8715214729309082\n",
            "d_loss_fake:0.02775271050632\n",
            "d_loss_wrong:0.6613091230392456\n",
            "d_loss:0.6080261915922165\n",
            "g_loss:[0.9521051, 0.9483255, 0.0018898045]\n",
            "Batch:122\n",
            "d_loss_real:0.8810864686965942\n",
            "d_loss_fake:0.004629678092896938\n",
            "d_loss_wrong:0.6384356617927551\n",
            "d_loss:0.6013095676898956\n",
            "g_loss:[0.9324778, 0.9280258, 0.0022259909]\n",
            "Batch:123\n",
            "d_loss_real:0.9435052275657654\n",
            "d_loss_fake:0.0017871535383164883\n",
            "d_loss_wrong:0.6718461513519287\n",
            "d_loss:0.64016093313694\n",
            "g_loss:[0.8599578, 0.85652447, 0.0017166802]\n",
            "Batch:124\n",
            "d_loss_real:0.8368164300918579\n",
            "d_loss_fake:0.0013443347997963428\n",
            "d_loss_wrong:0.6433939933776855\n",
            "d_loss:0.5795927941799164\n",
            "g_loss:[0.86063457, 0.85719436, 0.0017201036]\n",
            "Batch:125\n",
            "d_loss_real:0.8394573330879211\n",
            "d_loss_fake:0.0019013953860849142\n",
            "d_loss_wrong:0.6548382043838501\n",
            "d_loss:0.5839135646820068\n",
            "g_loss:[0.88560015, 0.8817868, 0.0019066618]\n",
            "Batch:126\n",
            "d_loss_real:0.8617541790008545\n",
            "d_loss_fake:0.032952286303043365\n",
            "d_loss_wrong:0.6566053032875061\n",
            "d_loss:0.6032664924860001\n",
            "g_loss:[0.8775568, 0.87327933, 0.0021387252]\n",
            "Batch:127\n",
            "d_loss_real:0.8212890028953552\n",
            "d_loss_fake:0.001627317164093256\n",
            "d_loss_wrong:0.6553608775138855\n",
            "d_loss:0.5748915523290634\n",
            "g_loss:[0.87108135, 0.8671282, 0.0019765664]\n",
            "Batch:128\n",
            "d_loss_real:0.987232506275177\n",
            "d_loss_fake:0.0010398650774732232\n",
            "d_loss_wrong:0.6476609110832214\n",
            "d_loss:0.6557914465665817\n",
            "g_loss:[0.900248, 0.8956192, 0.0023144023]\n",
            "Batch:129\n",
            "d_loss_real:0.8483043909072876\n",
            "d_loss_fake:0.20185384154319763\n",
            "d_loss_wrong:0.5731908679008484\n",
            "d_loss:0.6179133653640747\n",
            "g_loss:[1.1021677, 1.0977727, 0.002197489]\n",
            "Batch:130\n",
            "d_loss_real:1.076389193534851\n",
            "d_loss_fake:0.005158687010407448\n",
            "d_loss_wrong:0.6315169334411621\n",
            "d_loss:0.6973634958267212\n",
            "g_loss:[1.0376606, 1.0342523, 0.0017041741]\n",
            "Batch:131\n",
            "d_loss_real:1.272080898284912\n",
            "d_loss_fake:0.5101473331451416\n",
            "d_loss_wrong:0.6307739019393921\n",
            "d_loss:0.9212707579135895\n",
            "g_loss:[1.2706945, 1.2664785, 0.00210799]\n",
            "Batch:132\n",
            "d_loss_real:0.8899340629577637\n",
            "d_loss_fake:0.2975589632987976\n",
            "d_loss_wrong:0.541143000125885\n",
            "d_loss:0.6546425223350525\n",
            "g_loss:[1.4609208, 1.4566547, 0.0021330775]\n",
            "Batch:133\n",
            "d_loss_real:1.0054614543914795\n",
            "d_loss_fake:0.2329573929309845\n",
            "d_loss_wrong:0.48705533146858215\n",
            "d_loss:0.6827339082956314\n",
            "g_loss:[1.4450567, 1.4416089, 0.001723888]\n",
            "Batch:134\n",
            "d_loss_real:1.144849419593811\n",
            "d_loss_fake:0.1826954036951065\n",
            "d_loss_wrong:0.4687158465385437\n",
            "d_loss:0.7352775186300278\n",
            "g_loss:[1.4852223, 1.4815584, 0.0018319708]\n",
            "Batch:135\n",
            "d_loss_real:1.0317436456680298\n",
            "d_loss_fake:0.1721322238445282\n",
            "d_loss_wrong:0.545757532119751\n",
            "d_loss:0.6953442692756653\n",
            "g_loss:[1.2746681, 1.2712445, 0.0017117959]\n",
            "Batch:136\n",
            "d_loss_real:0.9699269533157349\n",
            "d_loss_fake:0.22141924500465393\n",
            "d_loss_wrong:0.5208086371421814\n",
            "d_loss:0.6705204546451569\n",
            "g_loss:[1.2858071, 1.2826014, 0.0016028669]\n",
            "Batch:137\n",
            "d_loss_real:1.0720064640045166\n",
            "d_loss_fake:0.15656238794326782\n",
            "d_loss_wrong:0.5072318911552429\n",
            "d_loss:0.701951801776886\n",
            "g_loss:[1.39764, 1.3946438, 0.0014981184]\n",
            "Batch:138\n",
            "d_loss_real:1.0266810655593872\n",
            "d_loss_fake:0.12019374966621399\n",
            "d_loss_wrong:0.5035977959632874\n",
            "d_loss:0.6692884266376495\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "g_loss:[1.2654527, 1.2616684, 0.0018921387]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "========================================\n",
            "Epoch is: 5\n",
            "Number of batches 138\n",
            "Batch:1\n",
            "d_loss_real:1.3213300704956055\n",
            "d_loss_fake:0.17562302947044373\n",
            "d_loss_wrong:0.4695793092250824\n",
            "d_loss:0.8219656199216843\n",
            "g_loss:[1.2303056, 1.2266817, 0.0018119467]\n",
            "Batch:2\n",
            "d_loss_real:1.0599194765090942\n",
            "d_loss_fake:0.11758134514093399\n",
            "d_loss_wrong:0.557840883731842\n",
            "d_loss:0.6988153010606766\n",
            "g_loss:[1.4510612, 1.4470849, 0.0019881525]\n",
            "Batch:3\n",
            "d_loss_real:0.9878103137016296\n",
            "d_loss_fake:0.059930115938186646\n",
            "d_loss_wrong:0.6201582551002502\n",
            "d_loss:0.6639272570610046\n",
            "g_loss:[1.7910384, 1.7869699, 0.0020342348]\n",
            "Batch:4\n",
            "d_loss_real:0.9188488721847534\n",
            "d_loss_fake:0.01602872461080551\n",
            "d_loss_wrong:0.6522471308708191\n",
            "d_loss:0.6264933943748474\n",
            "g_loss:[1.3848816, 1.3813357, 0.0017729306]\n",
            "Batch:5\n",
            "d_loss_real:0.8527829051017761\n",
            "d_loss_fake:0.03544974699616432\n",
            "d_loss_wrong:0.6550471782684326\n",
            "d_loss:0.5990156829357147\n",
            "g_loss:[1.1206682, 1.1174309, 0.0016186535]\n",
            "Batch:6\n",
            "d_loss_real:0.9147307276725769\n",
            "d_loss_fake:0.14335133135318756\n",
            "d_loss_wrong:0.6766310334205627\n",
            "d_loss:0.6623609513044357\n",
            "g_loss:[1.3782204, 1.3745114, 0.0018545617]\n",
            "Batch:7\n",
            "d_loss_real:0.8602694272994995\n",
            "d_loss_fake:0.12672443687915802\n",
            "d_loss_wrong:0.6003199219703674\n",
            "d_loss:0.6118957996368408\n",
            "g_loss:[2.166527, 2.163396, 0.001565557]\n",
            "Batch:8\n",
            "d_loss_real:1.1806901693344116\n",
            "d_loss_fake:0.11391063779592514\n",
            "d_loss_wrong:0.48870348930358887\n",
            "d_loss:0.7409986108541489\n",
            "g_loss:[1.7973788, 1.7925719, 0.0024034576]\n",
            "Batch:9\n",
            "d_loss_real:1.2857608795166016\n",
            "d_loss_fake:0.09731285274028778\n",
            "d_loss_wrong:0.6233933568000793\n",
            "d_loss:0.8230569958686829\n",
            "g_loss:[1.1850749, 1.1781149, 0.0034800065]\n",
            "Batch:10\n",
            "d_loss_real:0.9821041822433472\n",
            "d_loss_fake:0.31471991539001465\n",
            "d_loss_wrong:0.5465287566184998\n",
            "d_loss:0.7063642591238022\n",
            "g_loss:[1.5198177, 1.5143945, 0.002711588]\n",
            "Batch:11\n",
            "d_loss_real:1.1280322074890137\n",
            "d_loss_fake:0.1274164617061615\n",
            "d_loss_wrong:0.5936701893806458\n",
            "d_loss:0.744287759065628\n",
            "g_loss:[1.7687987, 1.7646477, 0.0020755208]\n",
            "Batch:12\n",
            "d_loss_real:1.1892688274383545\n",
            "d_loss_fake:0.2521244287490845\n",
            "d_loss_wrong:0.48670512437820435\n",
            "d_loss:0.7793418020009995\n",
            "g_loss:[1.9242152, 1.9208024, 0.0017064193]\n",
            "Batch:13\n",
            "d_loss_real:1.1575231552124023\n",
            "d_loss_fake:0.07384687662124634\n",
            "d_loss_wrong:0.5838329792022705\n",
            "d_loss:0.7431815415620804\n",
            "g_loss:[2.5416298, 2.5384068, 0.0016114675]\n",
            "Batch:14\n",
            "d_loss_real:0.9587873816490173\n",
            "d_loss_fake:0.3030399978160858\n",
            "d_loss_wrong:0.5616302490234375\n",
            "d_loss:0.6955612599849701\n",
            "g_loss:[2.2647243, 2.262255, 0.0012346221]\n",
            "Batch:15\n",
            "d_loss_real:1.3504998683929443\n",
            "d_loss_fake:0.2824048697948456\n",
            "d_loss_wrong:0.5668864846229553\n",
            "d_loss:0.8875727653503418\n",
            "g_loss:[2.2466218, 2.2427769, 0.00192252]\n",
            "Batch:16\n",
            "d_loss_real:1.014223337173462\n",
            "d_loss_fake:0.08273963630199432\n",
            "d_loss_wrong:0.6271836757659912\n",
            "d_loss:0.6845925003290176\n",
            "g_loss:[1.5465715, 1.5425436, 0.0020139343]\n",
            "Batch:17\n",
            "d_loss_real:0.8994326591491699\n",
            "d_loss_fake:0.03732693940401077\n",
            "d_loss_wrong:0.6646462082862854\n",
            "d_loss:0.6252096146345139\n",
            "g_loss:[1.3868332, 1.3830996, 0.0018668448]\n",
            "Batch:18\n",
            "d_loss_real:0.9234120845794678\n",
            "d_loss_fake:0.19321763515472412\n",
            "d_loss_wrong:0.5761000514030457\n",
            "d_loss:0.6540354639291763\n",
            "g_loss:[1.5158802, 1.5129976, 0.0014412833]\n",
            "Batch:19\n",
            "d_loss_real:1.0125081539154053\n",
            "d_loss_fake:0.15422573685646057\n",
            "d_loss_wrong:0.5479470491409302\n",
            "d_loss:0.6817972660064697\n",
            "g_loss:[1.4651606, 1.4620323, 0.0015641461]\n",
            "Batch:20\n",
            "d_loss_real:1.009714126586914\n",
            "d_loss_fake:0.09450278431177139\n",
            "d_loss_wrong:0.5812618136405945\n",
            "d_loss:0.673798218369484\n",
            "g_loss:[1.4247708, 1.421432, 0.0016694185]\n",
            "Batch:21\n",
            "d_loss_real:1.0536242723464966\n",
            "d_loss_fake:0.09366520494222641\n",
            "d_loss_wrong:0.5736082792282104\n",
            "d_loss:0.6936305016279221\n",
            "g_loss:[1.7745733, 1.771791, 0.0013911633]\n",
            "Batch:22\n",
            "d_loss_real:1.2367209196090698\n",
            "d_loss_fake:0.07960112392902374\n",
            "d_loss_wrong:0.6588444709777832\n",
            "d_loss:0.8029718548059464\n",
            "g_loss:[0.98950464, 0.9872468, 0.0011289096]\n",
            "Batch:23\n",
            "d_loss_real:1.083348035812378\n",
            "d_loss_fake:0.23735001683235168\n",
            "d_loss_wrong:0.6560036540031433\n",
            "d_loss:0.7650124430656433\n",
            "g_loss:[1.221474, 1.2186661, 0.0014039885]\n",
            "Batch:24\n",
            "d_loss_real:0.8681640625\n",
            "d_loss_fake:0.13551688194274902\n",
            "d_loss_wrong:0.5951946973800659\n",
            "d_loss:0.6167599260807037\n",
            "g_loss:[1.6017964, 1.5984454, 0.0016755105]\n",
            "Batch:25\n",
            "d_loss_real:1.2433052062988281\n",
            "d_loss_fake:0.1480174958705902\n",
            "d_loss_wrong:0.61803138256073\n",
            "d_loss:0.8131648302078247\n",
            "g_loss:[1.3848317, 1.3803027, 0.002264507]\n",
            "Batch:26\n",
            "d_loss_real:0.8853669166564941\n",
            "d_loss_fake:0.11236464977264404\n",
            "d_loss_wrong:0.6212157011032104\n",
            "d_loss:0.6260785460472107\n",
            "g_loss:[1.3853114, 1.3821876, 0.001561853]\n",
            "Batch:27\n",
            "d_loss_real:0.9306811094284058\n",
            "d_loss_fake:0.2117787003517151\n",
            "d_loss_wrong:0.6606577038764954\n",
            "d_loss:0.6834496557712555\n",
            "g_loss:[1.4394418, 1.4366188, 0.0014114818]\n",
            "Batch:28\n",
            "d_loss_real:1.0268845558166504\n",
            "d_loss_fake:0.05100230872631073\n",
            "d_loss_wrong:0.6497683525085449\n",
            "d_loss:0.6886349469423294\n",
            "g_loss:[1.8187046, 1.8142872, 0.0022087097]\n",
            "Batch:29\n",
            "d_loss_real:1.0617185831069946\n",
            "d_loss_fake:0.09640337526798248\n",
            "d_loss_wrong:0.5882327556610107\n",
            "d_loss:0.7020183205604553\n",
            "g_loss:[1.4034534, 1.3998, 0.0018266899]\n",
            "Batch:30\n",
            "d_loss_real:1.149012565612793\n",
            "d_loss_fake:0.08513322472572327\n",
            "d_loss_wrong:0.7414631843566895\n",
            "d_loss:0.7811553776264191\n",
            "g_loss:[1.2523938, 1.2485404, 0.0019267185]\n",
            "Batch:31\n",
            "d_loss_real:0.9378856420516968\n",
            "d_loss_fake:0.067507803440094\n",
            "d_loss_wrong:0.6344414353370667\n",
            "d_loss:0.6444301307201385\n",
            "g_loss:[1.2762504, 1.2723331, 0.0019586068]\n",
            "Batch:32\n",
            "d_loss_real:1.1150168180465698\n",
            "d_loss_fake:0.11139688640832901\n",
            "d_loss_wrong:0.6142061352729797\n",
            "d_loss:0.7389091700315475\n",
            "g_loss:[1.2686857, 1.2648513, 0.0019171835]\n",
            "Batch:33\n",
            "d_loss_real:0.8485870361328125\n",
            "d_loss_fake:0.024671772494912148\n",
            "d_loss_wrong:0.6681315898895264\n",
            "d_loss:0.59749436378479\n",
            "g_loss:[1.1738925, 1.1702347, 0.0018289033]\n",
            "Batch:34\n",
            "d_loss_real:1.1202547550201416\n",
            "d_loss_fake:0.09012433886528015\n",
            "d_loss_wrong:0.5946375727653503\n",
            "d_loss:0.7313178479671478\n",
            "g_loss:[1.0736306, 1.0699707, 0.0018299138]\n",
            "Batch:35\n",
            "d_loss_real:0.9336680769920349\n",
            "d_loss_fake:0.06802450120449066\n",
            "d_loss_wrong:0.6137115359306335\n",
            "d_loss:0.6372680515050888\n",
            "g_loss:[1.0550598, 1.0513941, 0.0018328461]\n",
            "Batch:36\n",
            "d_loss_real:0.9626025557518005\n",
            "d_loss_fake:0.052225276827812195\n",
            "d_loss_wrong:0.6184507012367249\n",
            "d_loss:0.6489702761173248\n",
            "g_loss:[1.0969762, 1.0929074, 0.0020343468]\n",
            "Batch:37\n",
            "d_loss_real:1.063891887664795\n",
            "d_loss_fake:0.09010832011699677\n",
            "d_loss_wrong:0.6930205225944519\n",
            "d_loss:0.7277281582355499\n",
            "g_loss:[1.1415969, 1.1374712, 0.0020628495]\n",
            "Batch:38\n",
            "d_loss_real:0.9005181789398193\n",
            "d_loss_fake:0.127781942486763\n",
            "d_loss_wrong:0.6557724475860596\n",
            "d_loss:0.646147683262825\n",
            "g_loss:[1.3945981, 1.3905773, 0.0020103836]\n",
            "Batch:39\n",
            "d_loss_real:1.130537986755371\n",
            "d_loss_fake:0.07145290076732635\n",
            "d_loss_wrong:0.6484943628311157\n",
            "d_loss:0.7452558130025864\n",
            "g_loss:[1.655492, 1.6515058, 0.0019930429]\n",
            "Batch:40\n",
            "d_loss_real:0.8771628141403198\n",
            "d_loss_fake:0.06596876680850983\n",
            "d_loss_wrong:0.6963302493095398\n",
            "d_loss:0.629156157374382\n",
            "g_loss:[1.4587461, 1.4552071, 0.0017694624]\n",
            "Batch:41\n",
            "d_loss_real:0.9013274908065796\n",
            "d_loss_fake:0.01438158843666315\n",
            "d_loss_wrong:0.6427187323570251\n",
            "d_loss:0.6149388253688812\n",
            "g_loss:[1.3724805, 1.3681216, 0.0021794515]\n",
            "Batch:42\n",
            "d_loss_real:0.9248595237731934\n",
            "d_loss_fake:0.01991833932697773\n",
            "d_loss_wrong:0.6579028964042664\n",
            "d_loss:0.6318850666284561\n",
            "g_loss:[1.2451863, 1.2403494, 0.0024184666]\n",
            "Batch:43\n",
            "d_loss_real:1.0273094177246094\n",
            "d_loss_fake:0.11788181215524673\n",
            "d_loss_wrong:0.5865537524223328\n",
            "d_loss:0.689763605594635\n",
            "g_loss:[1.107916, 1.103509, 0.0022035188]\n",
            "Batch:44\n",
            "d_loss_real:0.9135815501213074\n",
            "d_loss_fake:0.05721673369407654\n",
            "d_loss_wrong:0.7099305391311646\n",
            "d_loss:0.6485776007175446\n",
            "g_loss:[1.292116, 1.2873544, 0.0023808503]\n",
            "Batch:45\n",
            "d_loss_real:1.011918306350708\n",
            "d_loss_fake:0.027163207530975342\n",
            "d_loss_wrong:0.5867687463760376\n",
            "d_loss:0.6594421416521072\n",
            "g_loss:[1.0620004, 1.056882, 0.0025591627]\n",
            "Batch:46\n",
            "d_loss_real:1.1470015048980713\n",
            "d_loss_fake:0.26904481649398804\n",
            "d_loss_wrong:0.6754797697067261\n",
            "d_loss:0.8096318989992142\n",
            "g_loss:[1.0951003, 1.0902196, 0.0024403352]\n",
            "Batch:47\n",
            "d_loss_real:0.8897217512130737\n",
            "d_loss_fake:0.24091216921806335\n",
            "d_loss_wrong:0.5719586610794067\n",
            "d_loss:0.648078590631485\n",
            "g_loss:[1.2364088, 1.2308774, 0.002765704]\n",
            "Batch:48\n",
            "d_loss_real:1.0616209506988525\n",
            "d_loss_fake:0.06788195669651031\n",
            "d_loss_wrong:0.5651078820228577\n",
            "d_loss:0.689057931303978\n",
            "g_loss:[1.2196251, 1.2149332, 0.0023460083]\n",
            "Batch:49\n",
            "d_loss_real:1.0530060529708862\n",
            "d_loss_fake:0.016342978924512863\n",
            "d_loss_wrong:0.5805309414863586\n",
            "d_loss:0.6757215112447739\n",
            "g_loss:[1.2042645, 1.1989894, 0.002637574]\n",
            "Batch:50\n",
            "d_loss_real:0.9836187362670898\n",
            "d_loss_fake:0.01085037924349308\n",
            "d_loss_wrong:0.6784356236457825\n",
            "d_loss:0.6641308665275574\n",
            "g_loss:[1.0341557, 1.030559, 0.0017983814]\n",
            "Batch:51\n",
            "d_loss_real:1.0858871936798096\n",
            "d_loss_fake:0.14382219314575195\n",
            "d_loss_wrong:0.7710761427879333\n",
            "d_loss:0.7716681808233261\n",
            "g_loss:[1.1410857, 1.1370969, 0.0019944073]\n",
            "Batch:52\n",
            "d_loss_real:1.0121026039123535\n",
            "d_loss_fake:0.14845766127109528\n",
            "d_loss_wrong:0.6097772717475891\n",
            "d_loss:0.6956100314855576\n",
            "g_loss:[1.1436653, 1.1405644, 0.0015504468]\n",
            "Batch:53\n",
            "d_loss_real:0.8583979606628418\n",
            "d_loss_fake:0.043489668518304825\n",
            "d_loss_wrong:0.6138196587562561\n",
            "d_loss:0.5935263186693192\n",
            "g_loss:[1.1320021, 1.1277015, 0.0021503023]\n",
            "Batch:54\n",
            "d_loss_real:1.0520145893096924\n",
            "d_loss_fake:0.09138785302639008\n",
            "d_loss_wrong:0.7055912613868713\n",
            "d_loss:0.7252520769834518\n",
            "g_loss:[1.3105046, 1.3065829, 0.0019608382]\n",
            "Batch:55\n",
            "d_loss_real:0.9703887701034546\n",
            "d_loss_fake:0.09273733198642731\n",
            "d_loss_wrong:0.5913085341453552\n",
            "d_loss:0.6562058478593826\n",
            "g_loss:[1.1960353, 1.1918373, 0.0020989818]\n",
            "Batch:56\n",
            "d_loss_real:0.9189882278442383\n",
            "d_loss_fake:0.03121817484498024\n",
            "d_loss_wrong:0.6729272603988647\n",
            "d_loss:0.6355304718017578\n",
            "g_loss:[1.1505361, 1.1455138, 0.0025111232]\n",
            "Batch:57\n",
            "d_loss_real:0.9844095706939697\n",
            "d_loss_fake:0.021221434697508812\n",
            "d_loss_wrong:0.6389375329017639\n",
            "d_loss:0.6572445333003998\n",
            "g_loss:[1.0640335, 1.0590776, 0.0024779402]\n",
            "Batch:58\n",
            "d_loss_real:0.9374288320541382\n",
            "d_loss_fake:0.01127537526190281\n",
            "d_loss_wrong:0.667752206325531\n",
            "d_loss:0.6384713053703308\n",
            "g_loss:[0.96313524, 0.95865893, 0.0022381651]\n",
            "Batch:59\n",
            "d_loss_real:0.9660419225692749\n",
            "d_loss_fake:0.04978631064295769\n",
            "d_loss_wrong:0.662886917591095\n",
            "d_loss:0.6611892729997635\n",
            "g_loss:[1.0057989, 1.0013597, 0.0022195906]\n",
            "Batch:60\n",
            "d_loss_real:0.9299585223197937\n",
            "d_loss_fake:0.014843093231320381\n",
            "d_loss_wrong:0.651862621307373\n",
            "d_loss:0.6316556930541992\n",
            "g_loss:[1.0076703, 1.0029249, 0.0023727044]\n",
            "Batch:61\n",
            "d_loss_real:0.9786810278892517\n",
            "d_loss_fake:0.047426093369722366\n",
            "d_loss_wrong:0.6713011264801025\n",
            "d_loss:0.6690223217010498\n",
            "g_loss:[0.9660964, 0.96261996, 0.0017382117]\n",
            "Batch:62\n",
            "d_loss_real:0.8810315132141113\n",
            "d_loss_fake:0.022786766290664673\n",
            "d_loss_wrong:0.6493284702301025\n",
            "d_loss:0.6085445582866669\n",
            "g_loss:[1.0911052, 1.0877193, 0.0016929673]\n",
            "Batch:63\n",
            "d_loss_real:0.9500054121017456\n",
            "d_loss_fake:0.002365669934079051\n",
            "d_loss_wrong:0.6269723773002625\n",
            "d_loss:0.632337212562561\n",
            "g_loss:[0.9695356, 0.96630454, 0.0016155263]\n",
            "Batch:64\n",
            "d_loss_real:0.821077823638916\n",
            "d_loss_fake:0.005873515270650387\n",
            "d_loss_wrong:0.6682537198066711\n",
            "d_loss:0.5790707170963287\n",
            "g_loss:[1.0095942, 1.0054892, 0.0020524622]\n",
            "Batch:65\n",
            "d_loss_real:0.9789824485778809\n",
            "d_loss_fake:0.01657487079501152\n",
            "d_loss_wrong:0.6582890152931213\n",
            "d_loss:0.6582071930170059\n",
            "g_loss:[0.86275256, 0.8563746, 0.0031889724]\n",
            "Batch:66\n",
            "d_loss_real:0.8656612038612366\n",
            "d_loss_fake:0.013423106633126736\n",
            "d_loss_wrong:0.6591972708702087\n",
            "d_loss:0.6009856909513474\n",
            "g_loss:[0.8317615, 0.8277074, 0.0020270245]\n",
            "Batch:67\n",
            "d_loss_real:0.8544155359268188\n",
            "d_loss_fake:0.01664629764854908\n",
            "d_loss_wrong:0.6655925512313843\n",
            "d_loss:0.5977674871683121\n",
            "g_loss:[0.83190614, 0.82826555, 0.0018202881]\n",
            "Batch:68\n",
            "d_loss_real:0.9258379936218262\n",
            "d_loss_fake:0.005309761501848698\n",
            "d_loss_wrong:0.6537508368492126\n",
            "d_loss:0.6276841461658478\n",
            "g_loss:[0.8602705, 0.85662425, 0.0018231173]\n",
            "Batch:69\n",
            "d_loss_real:0.875929594039917\n",
            "d_loss_fake:0.047214314341545105\n",
            "d_loss_wrong:0.6776691675186157\n",
            "d_loss:0.619185671210289\n",
            "g_loss:[0.7857558, 0.7813194, 0.0022182153]\n",
            "Batch:70\n",
            "d_loss_real:0.9240586161613464\n",
            "d_loss_fake:0.009742159396409988\n",
            "d_loss_wrong:0.6996275782585144\n",
            "d_loss:0.6393717378377914\n",
            "g_loss:[0.85236216, 0.8479854, 0.002188376]\n",
            "Batch:71\n",
            "d_loss_real:0.8451355695724487\n",
            "d_loss_fake:0.005402986891567707\n",
            "d_loss_wrong:0.6465722322463989\n",
            "d_loss:0.5855615884065628\n",
            "g_loss:[0.8045331, 0.8012539, 0.0016395943]\n",
            "Batch:72\n",
            "d_loss_real:0.9296993017196655\n",
            "d_loss_fake:0.08485165238380432\n",
            "d_loss_wrong:0.7556464076042175\n",
            "d_loss:0.6749741733074188\n",
            "g_loss:[0.8210594, 0.8180108, 0.0015243047]\n",
            "Batch:73\n",
            "d_loss_real:1.0418055057525635\n",
            "d_loss_fake:0.04333928972482681\n",
            "d_loss_wrong:0.726975679397583\n",
            "d_loss:0.7134815007448196\n",
            "g_loss:[0.9023562, 0.8994554, 0.0014503924]\n",
            "Batch:74\n",
            "d_loss_real:0.8617218136787415\n",
            "d_loss_fake:0.0069199674762785435\n",
            "d_loss_wrong:0.6365063190460205\n",
            "d_loss:0.5917174816131592\n",
            "g_loss:[0.90838706, 0.90489346, 0.0017467934]\n",
            "Batch:75\n",
            "d_loss_real:0.9280349016189575\n",
            "d_loss_fake:0.009445339441299438\n",
            "d_loss_wrong:0.6089339256286621\n",
            "d_loss:0.6186122596263885\n",
            "g_loss:[0.83729005, 0.83359206, 0.0018490059]\n",
            "Batch:76\n",
            "d_loss_real:0.8752409219741821\n",
            "d_loss_fake:0.03239034488797188\n",
            "d_loss_wrong:0.6572186946868896\n",
            "d_loss:0.6100227236747742\n",
            "g_loss:[0.8482956, 0.84489906, 0.0016982908]\n",
            "Batch:77\n",
            "d_loss_real:0.8937811255455017\n",
            "d_loss_fake:0.002746007638052106\n",
            "d_loss_wrong:0.635374903678894\n",
            "d_loss:0.6064207851886749\n",
            "g_loss:[0.8720571, 0.8688892, 0.0015839388]\n",
            "Batch:78\n",
            "d_loss_real:0.8956636190414429\n",
            "d_loss_fake:0.003094448707997799\n",
            "d_loss_wrong:0.6838354468345642\n",
            "d_loss:0.6195642799139023\n",
            "g_loss:[0.81631476, 0.81263024, 0.0018422621]\n",
            "Batch:79\n",
            "d_loss_real:0.8402490019798279\n",
            "d_loss_fake:0.006637060549110174\n",
            "d_loss_wrong:0.6564396619796753\n",
            "d_loss:0.5858936756849289\n",
            "g_loss:[0.8953501, 0.8916786, 0.0018357531]\n",
            "Batch:80\n",
            "d_loss_real:0.8233551979064941\n",
            "d_loss_fake:0.0034603262320160866\n",
            "d_loss_wrong:0.7089768648147583\n",
            "d_loss:0.5897869020700455\n",
            "g_loss:[0.8303133, 0.8273152, 0.0014990522]\n",
            "Batch:81\n",
            "d_loss_real:0.8246207237243652\n",
            "d_loss_fake:0.001580403302796185\n",
            "d_loss_wrong:0.6204314231872559\n",
            "d_loss:0.5678133219480515\n",
            "g_loss:[0.8236849, 0.81989306, 0.0018959027]\n",
            "Batch:82\n",
            "d_loss_real:0.8297778367996216\n",
            "d_loss_fake:0.002574850805103779\n",
            "d_loss_wrong:0.6605507731437683\n",
            "d_loss:0.5806703269481659\n",
            "g_loss:[0.77974415, 0.7762983, 0.0017229394]\n",
            "Batch:83\n",
            "d_loss_real:0.777021586894989\n",
            "d_loss_fake:0.007929269224405289\n",
            "d_loss_wrong:0.6575568318367004\n",
            "d_loss:0.5548823177814484\n",
            "g_loss:[0.7676064, 0.7643559, 0.001625238]\n",
            "Batch:84\n",
            "d_loss_real:0.8212304711341858\n",
            "d_loss_fake:0.02237941138446331\n",
            "d_loss_wrong:0.6527805924415588\n",
            "d_loss:0.5794052332639694\n",
            "g_loss:[0.78464526, 0.78101766, 0.0018138031]\n",
            "Batch:85\n",
            "d_loss_real:0.8624962568283081\n",
            "d_loss_fake:0.010811863467097282\n",
            "d_loss_wrong:0.6693533062934875\n",
            "d_loss:0.6012894213199615\n",
            "g_loss:[0.734193, 0.7309829, 0.0016050525]\n",
            "Batch:86\n",
            "d_loss_real:0.8497660160064697\n",
            "d_loss_fake:0.026967260986566544\n",
            "d_loss_wrong:0.6384509205818176\n",
            "d_loss:0.5912375599145889\n",
            "g_loss:[0.6984429, 0.6955876, 0.0014276372]\n",
            "Batch:87\n",
            "d_loss_real:0.8806801438331604\n",
            "d_loss_fake:0.01817759871482849\n",
            "d_loss_wrong:0.6338436603546143\n",
            "d_loss:0.6033453941345215\n",
            "g_loss:[0.70830977, 0.70469785, 0.0018059544]\n",
            "Batch:88\n",
            "d_loss_real:0.9670446515083313\n",
            "d_loss_fake:0.0036771621089428663\n",
            "d_loss_wrong:0.6376562118530273\n",
            "d_loss:0.6438556760549545\n",
            "g_loss:[0.8401991, 0.83621025, 0.0019944198]\n",
            "Batch:89\n",
            "d_loss_real:0.9027009606361389\n",
            "d_loss_fake:0.0008385658729821444\n",
            "d_loss_wrong:0.7448157668113708\n",
            "d_loss:0.6377640664577484\n",
            "g_loss:[0.7147787, 0.71005166, 0.0023635398]\n",
            "Batch:90\n",
            "d_loss_real:0.808968186378479\n",
            "d_loss_fake:0.021367568522691727\n",
            "d_loss_wrong:0.6634211540222168\n",
            "d_loss:0.5756812691688538\n",
            "g_loss:[0.7726148, 0.76886, 0.0018774092]\n",
            "Batch:91\n",
            "d_loss_real:0.9119361639022827\n",
            "d_loss_fake:0.03439010679721832\n",
            "d_loss_wrong:0.7621464133262634\n",
            "d_loss:0.6551022082567215\n",
            "g_loss:[0.7358378, 0.7324638, 0.001687033]\n",
            "Batch:92\n",
            "d_loss_real:0.8861967325210571\n",
            "d_loss_fake:0.012000924907624722\n",
            "d_loss_wrong:0.6251534819602966\n",
            "d_loss:0.6023869663476944\n",
            "g_loss:[0.7636704, 0.7602997, 0.0016853572]\n",
            "Batch:93\n",
            "d_loss_real:0.8857627511024475\n",
            "d_loss_fake:0.038929782807826996\n",
            "d_loss_wrong:0.6164873242378235\n",
            "d_loss:0.6067356467247009\n",
            "g_loss:[0.7423854, 0.73847044, 0.001957465]\n",
            "Batch:94\n",
            "d_loss_real:0.8978455066680908\n",
            "d_loss_fake:0.004631177522242069\n",
            "d_loss_wrong:0.6553586721420288\n",
            "d_loss:0.6139202117919922\n",
            "g_loss:[0.96211267, 0.95814145, 0.0019856084]\n",
            "Batch:95\n",
            "d_loss_real:0.8926489353179932\n",
            "d_loss_fake:0.022235391661524773\n",
            "d_loss_wrong:0.7357916235923767\n",
            "d_loss:0.6358312219381332\n",
            "g_loss:[0.76976216, 0.76602733, 0.0018674156]\n",
            "Batch:96\n",
            "d_loss_real:0.8136541843414307\n",
            "d_loss_fake:0.06875412166118622\n",
            "d_loss_wrong:0.6749870777130127\n",
            "d_loss:0.5927623957395554\n",
            "g_loss:[0.76873964, 0.7644559, 0.0021418692]\n",
            "Batch:97\n",
            "d_loss_real:0.9012563824653625\n",
            "d_loss_fake:0.06337793171405792\n",
            "d_loss_wrong:0.6580354571342468\n",
            "d_loss:0.6309815347194672\n",
            "g_loss:[0.8544954, 0.8506956, 0.0018998835]\n",
            "Batch:98\n",
            "d_loss_real:0.902929961681366\n",
            "d_loss_fake:0.004424580372869968\n",
            "d_loss_wrong:0.6633250713348389\n",
            "d_loss:0.6184023916721344\n",
            "g_loss:[0.8393338, 0.8352504, 0.0020417096]\n",
            "Batch:99\n",
            "d_loss_real:0.84578937292099\n",
            "d_loss_fake:0.006120034959167242\n",
            "d_loss_wrong:0.6155821084976196\n",
            "d_loss:0.5783202201128006\n",
            "g_loss:[0.8171354, 0.81328297, 0.0019262005]\n",
            "Batch:100\n",
            "d_loss_real:0.8582547903060913\n",
            "d_loss_fake:0.0015566721558570862\n",
            "d_loss_wrong:0.6093117594718933\n",
            "d_loss:0.5818445086479187\n",
            "g_loss:[0.8163418, 0.8129244, 0.0017087273]\n",
            "Batch:101\n",
            "d_loss_real:0.8645559549331665\n",
            "d_loss_fake:0.0010513446759432554\n",
            "d_loss_wrong:0.6564306020736694\n",
            "d_loss:0.5966484695672989\n",
            "g_loss:[0.806142, 0.8027873, 0.0016773288]\n",
            "Batch:102\n",
            "d_loss_real:0.8457653522491455\n",
            "d_loss_fake:0.0016877243760973215\n",
            "d_loss_wrong:0.6389680504798889\n",
            "d_loss:0.5830466151237488\n",
            "g_loss:[0.7646366, 0.7613623, 0.001637135]\n",
            "Batch:103\n",
            "d_loss_real:0.9164109826087952\n",
            "d_loss_fake:0.0009114672429859638\n",
            "d_loss_wrong:0.6257341504096985\n",
            "d_loss:0.6148668974637985\n",
            "g_loss:[0.68298227, 0.6794882, 0.0017470284]\n",
            "Batch:104\n",
            "d_loss_real:0.8531656861305237\n",
            "d_loss_fake:0.0018726130947470665\n",
            "d_loss_wrong:0.6251270771026611\n",
            "d_loss:0.5833327621221542\n",
            "g_loss:[0.7400528, 0.7366754, 0.0016887255]\n",
            "Batch:105\n",
            "d_loss_real:0.8536397814750671\n",
            "d_loss_fake:0.003778160084038973\n",
            "d_loss_wrong:0.6560299396514893\n",
            "d_loss:0.5917719155550003\n",
            "g_loss:[0.6826976, 0.68010527, 0.0012961704]\n",
            "Batch:106\n",
            "d_loss_real:0.828919529914856\n",
            "d_loss_fake:0.007986288517713547\n",
            "d_loss_wrong:0.6716483235359192\n",
            "d_loss:0.584368422627449\n",
            "g_loss:[0.64975864, 0.646911, 0.0014238192]\n",
            "Batch:107\n",
            "d_loss_real:0.8250192999839783\n",
            "d_loss_fake:0.0012612699065357447\n",
            "d_loss_wrong:0.6546478271484375\n",
            "d_loss:0.5764869302511215\n",
            "g_loss:[0.6140604, 0.611127, 0.0014667052]\n",
            "Batch:108\n",
            "d_loss_real:0.8407453298568726\n",
            "d_loss_fake:0.0020059323869645596\n",
            "d_loss_wrong:0.6307381391525269\n",
            "d_loss:0.5785586833953857\n",
            "g_loss:[0.63218415, 0.6296537, 0.0012652361]\n",
            "Batch:109\n",
            "d_loss_real:0.8497453331947327\n",
            "d_loss_fake:0.002492656698450446\n",
            "d_loss_wrong:0.6663090586662292\n",
            "d_loss:0.5920730978250504\n",
            "g_loss:[0.5499203, 0.5469261, 0.00149711]\n",
            "Batch:110\n",
            "d_loss_real:0.8397464752197266\n",
            "d_loss_fake:0.004809818230569363\n",
            "d_loss_wrong:0.6450768113136292\n",
            "d_loss:0.5823448896408081\n",
            "g_loss:[0.59094596, 0.587815, 0.0015654779]\n",
            "Batch:111\n",
            "d_loss_real:0.8551375865936279\n",
            "d_loss_fake:0.0074119484052062035\n",
            "d_loss_wrong:0.6152421236038208\n",
            "d_loss:0.5832323133945465\n",
            "g_loss:[0.5960709, 0.5929082, 0.0015813387]\n",
            "Batch:112\n",
            "d_loss_real:0.8808091282844543\n",
            "d_loss_fake:0.01156945712864399\n",
            "d_loss_wrong:0.7735278606414795\n",
            "d_loss:0.6366788893938065\n",
            "g_loss:[0.6349807, 0.6313416, 0.0018195368]\n",
            "Batch:113\n",
            "d_loss_real:0.8118090629577637\n",
            "d_loss_fake:0.006503252312541008\n",
            "d_loss_wrong:0.634974479675293\n",
            "d_loss:0.566273957490921\n",
            "g_loss:[0.65630203, 0.6526401, 0.0018309542]\n",
            "Batch:114\n",
            "d_loss_real:0.8631502985954285\n",
            "d_loss_fake:0.004040460102260113\n",
            "d_loss_wrong:0.6035559773445129\n",
            "d_loss:0.583474263548851\n",
            "g_loss:[0.5139831, 0.51087666, 0.0015532079]\n",
            "Batch:115\n",
            "d_loss_real:0.8551733493804932\n",
            "d_loss_fake:0.01037580706179142\n",
            "d_loss_wrong:0.6368052363395691\n",
            "d_loss:0.5893819332122803\n",
            "g_loss:[0.51956046, 0.5162556, 0.0016524318]\n",
            "Batch:116\n",
            "d_loss_real:0.9008256196975708\n",
            "d_loss_fake:0.004566268064081669\n",
            "d_loss_wrong:0.6816062331199646\n",
            "d_loss:0.621955931186676\n",
            "g_loss:[0.59786594, 0.59472567, 0.0015701472]\n",
            "Batch:117\n",
            "d_loss_real:0.81387859582901\n",
            "d_loss_fake:0.0020994250662624836\n",
            "d_loss_wrong:0.6673771142959595\n",
            "d_loss:0.5743084400892258\n",
            "g_loss:[0.59529144, 0.5923672, 0.0014621355]\n",
            "Batch:118\n",
            "d_loss_real:0.7983794808387756\n",
            "d_loss_fake:0.01118466630578041\n",
            "d_loss_wrong:0.6502355337142944\n",
            "d_loss:0.5645447969436646\n",
            "g_loss:[0.6131817, 0.6098088, 0.0016864481]\n",
            "Batch:119\n",
            "d_loss_real:0.8494949340820312\n",
            "d_loss_fake:0.004412573762238026\n",
            "d_loss_wrong:0.6327071189880371\n",
            "d_loss:0.5840273946523666\n",
            "g_loss:[0.62162745, 0.6189491, 0.0013391646]\n",
            "Batch:120\n",
            "d_loss_real:0.7999239563941956\n",
            "d_loss_fake:0.004036174155771732\n",
            "d_loss_wrong:0.6731598377227783\n",
            "d_loss:0.569260984659195\n",
            "g_loss:[0.5545356, 0.55135703, 0.0015892987]\n",
            "Batch:121\n",
            "d_loss_real:0.8621782064437866\n",
            "d_loss_fake:0.0032458635978400707\n",
            "d_loss_wrong:0.6394269466400146\n",
            "d_loss:0.5917573124170303\n",
            "g_loss:[0.61586356, 0.6125802, 0.0016416856]\n",
            "Batch:122\n",
            "d_loss_real:0.8552887439727783\n",
            "d_loss_fake:0.0028427494689822197\n",
            "d_loss_wrong:0.6358434557914734\n",
            "d_loss:0.5873159170150757\n",
            "g_loss:[0.4827866, 0.47947043, 0.0016580757]\n",
            "Batch:123\n",
            "d_loss_real:0.9059767723083496\n",
            "d_loss_fake:0.008245506323873997\n",
            "d_loss_wrong:0.6585850119590759\n",
            "d_loss:0.6196960210800171\n",
            "g_loss:[0.5289316, 0.52629495, 0.0013183246]\n",
            "Batch:124\n",
            "d_loss_real:0.8172228932380676\n",
            "d_loss_fake:0.002842507790774107\n",
            "d_loss_wrong:0.6396508812904358\n",
            "d_loss:0.5692347884178162\n",
            "g_loss:[0.5119814, 0.50930023, 0.0013405951]\n",
            "Batch:125\n",
            "d_loss_real:0.8094083666801453\n",
            "d_loss_fake:0.04647139459848404\n",
            "d_loss_wrong:0.6270186305046082\n",
            "d_loss:0.5730766952037811\n",
            "g_loss:[0.5513895, 0.54823124, 0.0015791499]\n",
            "Batch:126\n",
            "d_loss_real:0.9074544906616211\n",
            "d_loss_fake:0.015841329470276833\n",
            "d_loss_wrong:0.6424745917320251\n",
            "d_loss:0.6183062195777893\n",
            "g_loss:[0.7112558, 0.7079723, 0.0016417464]\n",
            "Batch:127\n",
            "d_loss_real:0.8409284949302673\n",
            "d_loss_fake:0.005016373936086893\n",
            "d_loss_wrong:0.6247271299362183\n",
            "d_loss:0.5779001265764236\n",
            "g_loss:[0.6033938, 0.60042983, 0.0014819656]\n",
            "Batch:128\n",
            "d_loss_real:0.8306361436843872\n",
            "d_loss_fake:0.0030847517773509026\n",
            "d_loss_wrong:0.6408928632736206\n",
            "d_loss:0.5763124823570251\n",
            "g_loss:[0.47727492, 0.47322482, 0.0020250492]\n",
            "Batch:129\n",
            "d_loss_real:0.8265505433082581\n",
            "d_loss_fake:0.005585371516644955\n",
            "d_loss_wrong:0.639315664768219\n",
            "d_loss:0.5745005309581757\n",
            "g_loss:[0.5676308, 0.563605, 0.0020129138]\n",
            "Batch:130\n",
            "d_loss_real:0.8166131973266602\n",
            "d_loss_fake:0.004964950028806925\n",
            "d_loss_wrong:0.688161313533783\n",
            "d_loss:0.5815881639719009\n",
            "g_loss:[0.54677624, 0.5439882, 0.001394015]\n",
            "Batch:131\n",
            "d_loss_real:0.8731729388237\n",
            "d_loss_fake:0.005687262862920761\n",
            "d_loss_wrong:0.6744544506072998\n",
            "d_loss:0.6066218912601471\n",
            "g_loss:[0.52777773, 0.52439094, 0.0016933954]\n",
            "Batch:132\n",
            "d_loss_real:0.8022913932800293\n",
            "d_loss_fake:0.0016998103819787502\n",
            "d_loss_wrong:0.6483782529830933\n",
            "d_loss:0.5636652112007141\n",
            "g_loss:[0.5623636, 0.55902183, 0.0016708879]\n",
            "Batch:133\n",
            "d_loss_real:0.8191918134689331\n",
            "d_loss_fake:0.008786415681242943\n",
            "d_loss_wrong:0.6620373129844666\n",
            "d_loss:0.5773018449544907\n",
            "g_loss:[0.582405, 0.5797936, 0.0013057012]\n",
            "Batch:134\n",
            "d_loss_real:0.8453664779663086\n",
            "d_loss_fake:0.0007605259888805449\n",
            "d_loss_wrong:0.6720024943351746\n",
            "d_loss:0.5908740013837814\n",
            "g_loss:[0.42699245, 0.42414314, 0.00142465]\n",
            "Batch:135\n",
            "d_loss_real:0.875296413898468\n",
            "d_loss_fake:0.0038097556680440903\n",
            "d_loss_wrong:0.6380593180656433\n",
            "d_loss:0.598115473985672\n",
            "g_loss:[0.44461077, 0.4418637, 0.0013735492]\n",
            "Batch:136\n",
            "d_loss_real:0.8265876173973083\n",
            "d_loss_fake:0.0034069912508130074\n",
            "d_loss_wrong:0.6267563104629517\n",
            "d_loss:0.5708346366882324\n",
            "g_loss:[0.4997092, 0.4970973, 0.0013059415]\n",
            "Batch:137\n",
            "d_loss_real:0.8182028532028198\n",
            "d_loss_fake:0.0004198868991807103\n",
            "d_loss_wrong:0.6566200852394104\n",
            "d_loss:0.5733614265918732\n",
            "g_loss:[0.4854833, 0.48304468, 0.0012192989]\n",
            "Batch:138\n",
            "d_loss_real:0.8499406576156616\n",
            "d_loss_fake:0.002839788096025586\n",
            "d_loss_wrong:0.618911862373352\n",
            "d_loss:0.5804082453250885\n",
            "g_loss:[0.5022807, 0.49944794, 0.0014163816]\n",
            "========================================\n",
            "Epoch is: 6\n",
            "Number of batches 138\n",
            "Batch:1\n",
            "d_loss_real:0.8479324579238892\n",
            "d_loss_fake:0.007935249246656895\n",
            "d_loss_wrong:0.7053212523460388\n",
            "d_loss:0.6022803485393524\n",
            "g_loss:[0.52632743, 0.5229881, 0.0016696726]\n",
            "Batch:2\n",
            "d_loss_real:0.8075755834579468\n",
            "d_loss_fake:0.0035550319589674473\n",
            "d_loss_wrong:0.6809698343276978\n",
            "d_loss:0.5749190151691437\n",
            "g_loss:[0.4570783, 0.4533466, 0.0018658444]\n",
            "Batch:3\n",
            "d_loss_real:0.8944096565246582\n",
            "d_loss_fake:0.003602821147069335\n",
            "d_loss_wrong:0.6220765709877014\n",
            "d_loss:0.6036246716976166\n",
            "g_loss:[0.5212441, 0.5176618, 0.0017911422]\n",
            "Batch:4\n",
            "d_loss_real:0.8392618894577026\n",
            "d_loss_fake:0.0034830719232559204\n",
            "d_loss_wrong:0.6584181189537048\n",
            "d_loss:0.5851062387228012\n",
            "g_loss:[0.4754988, 0.47285473, 0.0013220315]\n",
            "Batch:5\n",
            "d_loss_real:0.7953076362609863\n",
            "d_loss_fake:0.005176867358386517\n",
            "d_loss_wrong:0.675734281539917\n",
            "d_loss:0.5678815990686417\n",
            "g_loss:[0.4466906, 0.4441681, 0.0012612448]\n",
            "Batch:6\n",
            "d_loss_real:0.8328205347061157\n",
            "d_loss_fake:0.005475896410644054\n",
            "d_loss_wrong:0.670640230178833\n",
            "d_loss:0.5854392945766449\n",
            "g_loss:[0.5372196, 0.53435385, 0.0014328525]\n",
            "Batch:7\n",
            "d_loss_real:0.8115456700325012\n",
            "d_loss_fake:0.00409584678709507\n",
            "d_loss_wrong:0.633948802947998\n",
            "d_loss:0.5652839988470078\n",
            "g_loss:[0.4911077, 0.48865777, 0.0012249661]\n",
            "Batch:8\n",
            "d_loss_real:0.86493980884552\n",
            "d_loss_fake:0.003427421674132347\n",
            "d_loss_wrong:0.6194685101509094\n",
            "d_loss:0.5881938934326172\n",
            "g_loss:[0.47668013, 0.47249776, 0.0020911775]\n",
            "Batch:9\n",
            "d_loss_real:0.9244452714920044\n",
            "d_loss_fake:0.0012117058504372835\n",
            "d_loss_wrong:0.6518979668617249\n",
            "d_loss:0.6255000531673431\n",
            "g_loss:[0.43475387, 0.42933923, 0.0027073245]\n",
            "Batch:10\n",
            "d_loss_real:0.8379754424095154\n",
            "d_loss_fake:0.011221466585993767\n",
            "d_loss_wrong:0.6286600232124329\n",
            "d_loss:0.5789580941200256\n",
            "g_loss:[0.3814493, 0.37768853, 0.0018803946]\n",
            "Batch:11\n",
            "d_loss_real:0.9686086177825928\n",
            "d_loss_fake:0.008355749770998955\n",
            "d_loss_wrong:0.6466037034988403\n",
            "d_loss:0.6480441689491272\n",
            "g_loss:[0.436633, 0.43334842, 0.001642287]\n",
            "Batch:12\n",
            "d_loss_real:0.811121940612793\n",
            "d_loss_fake:0.03261784464120865\n",
            "d_loss_wrong:0.6346930265426636\n",
            "d_loss:0.5723886936903\n",
            "g_loss:[0.5753263, 0.5727202, 0.0013030454]\n",
            "Batch:13\n",
            "d_loss_real:0.823064386844635\n",
            "d_loss_fake:0.012005886062979698\n",
            "d_loss_wrong:0.645206093788147\n",
            "d_loss:0.575835183262825\n",
            "g_loss:[0.6110142, 0.6083152, 0.0013494935]\n",
            "Batch:14\n",
            "d_loss_real:0.8367272615432739\n",
            "d_loss_fake:0.004533750936388969\n",
            "d_loss_wrong:0.6271734237670898\n",
            "d_loss:0.5762904286384583\n",
            "g_loss:[0.5715272, 0.5689044, 0.0013114021]\n",
            "Batch:15\n",
            "d_loss_real:0.8744885325431824\n",
            "d_loss_fake:0.01067071221768856\n",
            "d_loss_wrong:0.689933180809021\n",
            "d_loss:0.612395241856575\n",
            "g_loss:[0.5362345, 0.5320809, 0.002076808]\n",
            "Batch:16\n",
            "d_loss_real:0.8058279752731323\n",
            "d_loss_fake:0.0012985150096938014\n",
            "d_loss_wrong:0.6941241025924683\n",
            "d_loss:0.5767696350812912\n",
            "g_loss:[0.5589453, 0.5548685, 0.0020383806]\n",
            "Batch:17\n",
            "d_loss_real:0.8102232813835144\n",
            "d_loss_fake:0.0009676494519226253\n",
            "d_loss_wrong:0.6703864336013794\n",
            "d_loss:0.572950154542923\n",
            "g_loss:[0.5191545, 0.51594555, 0.0016044651]\n",
            "Batch:18\n",
            "d_loss_real:0.8486172556877136\n",
            "d_loss_fake:0.0009597708703950047\n",
            "d_loss_wrong:0.6412532329559326\n",
            "d_loss:0.5848618745803833\n",
            "g_loss:[0.4596948, 0.4573335, 0.001180653]\n",
            "Batch:19\n",
            "d_loss_real:0.84134840965271\n",
            "d_loss_fake:0.0036998610012233257\n",
            "d_loss_wrong:0.6502864956855774\n",
            "d_loss:0.584170788526535\n",
            "g_loss:[0.52199715, 0.5193498, 0.0013236773]\n",
            "Batch:20\n",
            "d_loss_real:0.8201117515563965\n",
            "d_loss_fake:0.004237758461385965\n",
            "d_loss_wrong:0.6745972037315369\n",
            "d_loss:0.5797646194696426\n",
            "g_loss:[0.48430967, 0.4817472, 0.0012812363]\n",
            "Batch:21\n",
            "d_loss_real:0.8678471446037292\n",
            "d_loss_fake:0.0026895967312157154\n",
            "d_loss_wrong:0.5976516008377075\n",
            "d_loss:0.5840088725090027\n",
            "g_loss:[0.44935375, 0.4467151, 0.0013193337]\n",
            "Batch:22\n",
            "d_loss_real:0.8386107087135315\n",
            "d_loss_fake:0.005864089820533991\n",
            "d_loss_wrong:0.7039981484413147\n",
            "d_loss:0.5967709124088287\n",
            "g_loss:[0.39889145, 0.39671135, 0.0010900544]\n",
            "Batch:23\n",
            "d_loss_real:0.8314846754074097\n",
            "d_loss_fake:0.011789646930992603\n",
            "d_loss_wrong:0.6928884983062744\n",
            "d_loss:0.5919118672609329\n",
            "g_loss:[0.48283777, 0.48034418, 0.0012467887]\n",
            "Batch:24\n",
            "d_loss_real:0.8327968120574951\n",
            "d_loss_fake:0.003877653507515788\n",
            "d_loss_wrong:0.6236473917961121\n",
            "d_loss:0.5732796639204025\n",
            "g_loss:[0.46103466, 0.45813715, 0.0014487548]\n",
            "Batch:25\n",
            "d_loss_real:0.8570051789283752\n",
            "d_loss_fake:0.0035565397702157497\n",
            "d_loss_wrong:0.7134039998054504\n",
            "d_loss:0.6077427268028259\n",
            "g_loss:[0.4342676, 0.43088955, 0.0016890285]\n",
            "Batch:26\n",
            "d_loss_real:0.8207545280456543\n",
            "d_loss_fake:0.00562558276578784\n",
            "d_loss_wrong:0.6445823907852173\n",
            "d_loss:0.5729292631149292\n",
            "g_loss:[0.43196735, 0.42932415, 0.0013215999]\n",
            "Batch:27\n",
            "d_loss_real:0.8614770174026489\n",
            "d_loss_fake:0.007383011281490326\n",
            "d_loss_wrong:0.6813848614692688\n",
            "d_loss:0.6029304713010788\n",
            "g_loss:[0.4563798, 0.4538434, 0.0012681987]\n",
            "Batch:28\n",
            "d_loss_real:0.8829584717750549\n",
            "d_loss_fake:0.005862372927367687\n",
            "d_loss_wrong:0.5836575031280518\n",
            "d_loss:0.5888592004776001\n",
            "g_loss:[0.51504207, 0.5114046, 0.0018187547]\n",
            "Batch:29\n",
            "d_loss_real:0.860412061214447\n",
            "d_loss_fake:0.0025603279937058687\n",
            "d_loss_wrong:0.6425555348396301\n",
            "d_loss:0.5914849936962128\n",
            "g_loss:[0.401749, 0.39832208, 0.0017134628]\n",
            "Batch:30\n",
            "d_loss_real:0.8639588356018066\n",
            "d_loss_fake:0.004034273326396942\n",
            "d_loss_wrong:0.7220999002456665\n",
            "d_loss:0.6135129630565643\n",
            "g_loss:[0.44800496, 0.4446989, 0.0016530277]\n",
            "Batch:31\n",
            "d_loss_real:0.8327320218086243\n",
            "d_loss_fake:0.013914691284298897\n",
            "d_loss_wrong:0.6448823809623718\n",
            "d_loss:0.5810652822256088\n",
            "g_loss:[0.5383432, 0.53482926, 0.0017569736]\n",
            "Batch:32\n",
            "d_loss_real:0.9225845336914062\n",
            "d_loss_fake:0.00348177133128047\n",
            "d_loss_wrong:0.6207237839698792\n",
            "d_loss:0.6173436492681503\n",
            "g_loss:[0.51339513, 0.50962734, 0.0018838836]\n",
            "Batch:33\n",
            "d_loss_real:0.7989586591720581\n",
            "d_loss_fake:0.008643435314297676\n",
            "d_loss_wrong:0.6358977556228638\n",
            "d_loss:0.5606146305799484\n",
            "g_loss:[0.58660764, 0.5831263, 0.0017406498]\n",
            "Batch:34\n",
            "d_loss_real:0.8483777046203613\n",
            "d_loss_fake:0.004506486468017101\n",
            "d_loss_wrong:0.6236397624015808\n",
            "d_loss:0.5812254101037979\n",
            "g_loss:[0.40816948, 0.40467167, 0.0017489011]\n",
            "Batch:35\n",
            "d_loss_real:0.8319991230964661\n",
            "d_loss_fake:0.005185299552977085\n",
            "d_loss_wrong:0.6454066634178162\n",
            "d_loss:0.5786475539207458\n",
            "g_loss:[0.4432201, 0.440113, 0.0015535548]\n",
            "Batch:36\n",
            "d_loss_real:0.8498533964157104\n",
            "d_loss_fake:0.0070806145668029785\n",
            "d_loss_wrong:0.6431195735931396\n",
            "d_loss:0.5874767452478409\n",
            "g_loss:[0.49635953, 0.49312833, 0.0016156019]\n",
            "Batch:37\n",
            "d_loss_real:0.8353617191314697\n",
            "d_loss_fake:0.030407927930355072\n",
            "d_loss_wrong:0.6294485330581665\n",
            "d_loss:0.5826449692249298\n",
            "g_loss:[0.76444834, 0.7610023, 0.0017230082]\n",
            "Batch:38\n",
            "d_loss_real:0.8703697919845581\n",
            "d_loss_fake:0.0051139406859874725\n",
            "d_loss_wrong:0.6568350195884705\n",
            "d_loss:0.6006721407175064\n",
            "g_loss:[0.7913639, 0.788224, 0.0015699668]\n",
            "Batch:39\n",
            "d_loss_real:0.8558700084686279\n",
            "d_loss_fake:0.011737905442714691\n",
            "d_loss_wrong:0.6503430604934692\n",
            "d_loss:0.5934552401304245\n",
            "g_loss:[0.8170508, 0.8137791, 0.0016358575]\n",
            "Batch:40\n",
            "d_loss_real:0.8519508242607117\n",
            "d_loss_fake:0.021295711398124695\n",
            "d_loss_wrong:0.6805065274238586\n",
            "d_loss:0.601425975561142\n",
            "g_loss:[0.8785733, 0.87573576, 0.0014187584]\n",
            "Batch:41\n",
            "d_loss_real:0.8777222633361816\n",
            "d_loss_fake:0.05205988138914108\n",
            "d_loss_wrong:0.6078680157661438\n",
            "d_loss:0.6038431078195572\n",
            "g_loss:[1.375646, 1.3722184, 0.0017138063]\n",
            "Batch:42\n",
            "d_loss_real:0.9272128343582153\n",
            "d_loss_fake:0.01464146375656128\n",
            "d_loss_wrong:0.6654853820800781\n",
            "d_loss:0.6336381286382675\n",
            "g_loss:[1.2469566, 1.2432551, 0.0018507417]\n",
            "Batch:43\n",
            "d_loss_real:1.0792901515960693\n",
            "d_loss_fake:0.060579814016819\n",
            "d_loss_wrong:0.6208364367485046\n",
            "d_loss:0.709999144077301\n",
            "g_loss:[1.1718864, 1.1677773, 0.002054543]\n",
            "Batch:44\n",
            "d_loss_real:0.8369191288948059\n",
            "d_loss_fake:0.15106305480003357\n",
            "d_loss_wrong:0.5989896059036255\n",
            "d_loss:0.6059727370738983\n",
            "g_loss:[3.4411077, 3.4366891, 0.0022093276]\n",
            "Batch:45\n",
            "d_loss_real:0.9679136276245117\n",
            "d_loss_fake:0.056442711502313614\n",
            "d_loss_wrong:0.538598895072937\n",
            "d_loss:0.6327172219753265\n",
            "g_loss:[5.835333, 5.8302183, 0.0025572611]\n",
            "Batch:46\n",
            "d_loss_real:0.9739169478416443\n",
            "d_loss_fake:0.02927478402853012\n",
            "d_loss_wrong:0.651861310005188\n",
            "d_loss:0.6572424918413162\n",
            "g_loss:[3.230975, 3.225989, 0.0024929394]\n",
            "Batch:47\n",
            "d_loss_real:0.8316801190376282\n",
            "d_loss_fake:0.13417188823223114\n",
            "d_loss_wrong:0.5886489748954773\n",
            "d_loss:0.5965452790260315\n",
            "g_loss:[5.650317, 5.6437607, 0.0032783728]\n",
            "Batch:48\n",
            "d_loss_real:1.0384752750396729\n",
            "d_loss_fake:0.193617045879364\n",
            "d_loss_wrong:0.542651355266571\n",
            "d_loss:0.7033047378063202\n",
            "g_loss:[4.5452485, 4.5358353, 0.004706667]\n",
            "Batch:49\n",
            "d_loss_real:1.0895638465881348\n",
            "d_loss_fake:0.05993635207414627\n",
            "d_loss_wrong:0.532982587814331\n",
            "d_loss:0.6930116564035416\n",
            "g_loss:[2.6648583, 2.6538572, 0.005500501]\n",
            "Batch:50\n",
            "d_loss_real:1.2956867218017578\n",
            "d_loss_fake:0.14815843105316162\n",
            "d_loss_wrong:0.6345046758651733\n",
            "d_loss:0.8435091376304626\n",
            "g_loss:[1.4753042, 1.4686387, 0.0033328168]\n",
            "Batch:51\n",
            "d_loss_real:0.9419293403625488\n",
            "d_loss_fake:0.1241392120718956\n",
            "d_loss_wrong:0.5859656929969788\n",
            "d_loss:0.6484908908605576\n",
            "g_loss:[2.2497623, 2.241898, 0.0039321324]\n",
            "Batch:52\n",
            "d_loss_real:1.0084474086761475\n",
            "d_loss_fake:0.023494238033890724\n",
            "d_loss_wrong:0.6609376668930054\n",
            "d_loss:0.6753316819667816\n",
            "g_loss:[1.5355663, 1.5289985, 0.003283914]\n",
            "Batch:53\n",
            "d_loss_real:0.8452028632164001\n",
            "d_loss_fake:0.05100081115961075\n",
            "d_loss_wrong:0.602016270160675\n",
            "d_loss:0.585855707526207\n",
            "g_loss:[2.4014447, 2.389893, 0.0057758596]\n",
            "Batch:54\n",
            "d_loss_real:0.924281120300293\n",
            "d_loss_fake:0.033552639186382294\n",
            "d_loss_wrong:0.6386963129043579\n",
            "d_loss:0.6302028000354767\n",
            "g_loss:[2.1273117, 2.119217, 0.00404735]\n",
            "Batch:55\n",
            "d_loss_real:0.9457859992980957\n",
            "d_loss_fake:0.039105355739593506\n",
            "d_loss_wrong:0.6041504144668579\n",
            "d_loss:0.6337069422006607\n",
            "g_loss:[2.106939, 2.1012237, 0.0028576348]\n",
            "Batch:56\n",
            "d_loss_real:1.0350568294525146\n",
            "d_loss_fake:0.07502247393131256\n",
            "d_loss_wrong:0.6842584609985352\n",
            "d_loss:0.707348644733429\n",
            "g_loss:[1.8871125, 1.8822021, 0.0024551898]\n",
            "Batch:57\n",
            "d_loss_real:0.8825993537902832\n",
            "d_loss_fake:0.035676538944244385\n",
            "d_loss_wrong:0.6299237608909607\n",
            "d_loss:0.6076997518539429\n",
            "g_loss:[2.1120348, 2.1073341, 0.0023502717]\n",
            "Batch:58\n",
            "d_loss_real:0.8706215620040894\n",
            "d_loss_fake:0.03276899456977844\n",
            "d_loss_wrong:0.640620768070221\n",
            "d_loss:0.6036582291126251\n",
            "g_loss:[2.1028647, 2.098823, 0.0020208235]\n",
            "Batch:59\n",
            "d_loss_real:0.9573335647583008\n",
            "d_loss_fake:0.028021739795804024\n",
            "d_loss_wrong:0.6645809412002563\n",
            "d_loss:0.6518174558877945\n",
            "g_loss:[1.5900581, 1.5863578, 0.0018501172]\n",
            "Batch:60\n",
            "d_loss_real:0.9020442366600037\n",
            "d_loss_fake:0.009032025933265686\n",
            "d_loss_wrong:0.6464794874191284\n",
            "d_loss:0.6148999929428101\n",
            "g_loss:[1.5886723, 1.584907, 0.001882602]\n",
            "Batch:61\n",
            "d_loss_real:0.8941252827644348\n",
            "d_loss_fake:0.03612858057022095\n",
            "d_loss_wrong:0.63956218957901\n",
            "d_loss:0.6159853339195251\n",
            "g_loss:[1.5280988, 1.5247631, 0.0016678382]\n",
            "Batch:62\n",
            "d_loss_real:0.9264887571334839\n",
            "d_loss_fake:0.055482394993305206\n",
            "d_loss_wrong:0.6306376457214355\n",
            "d_loss:0.634774386882782\n",
            "g_loss:[1.4703431, 1.4661845, 0.0020793304]\n",
            "Batch:63\n",
            "d_loss_real:0.9437621831893921\n",
            "d_loss_fake:0.020124362781643867\n",
            "d_loss_wrong:0.6554635763168335\n",
            "d_loss:0.6407780796289444\n",
            "g_loss:[1.34136, 1.3374637, 0.0019481012]\n",
            "Batch:64\n",
            "d_loss_real:0.8723390102386475\n",
            "d_loss_fake:0.06191013753414154\n",
            "d_loss_wrong:0.6224953532218933\n",
            "d_loss:0.6072708815336227\n",
            "g_loss:[1.4094057, 1.4051687, 0.0021185437]\n",
            "Batch:65\n",
            "d_loss_real:0.905746340751648\n",
            "d_loss_fake:0.03269221633672714\n",
            "d_loss_wrong:0.7126885652542114\n",
            "d_loss:0.6392183601856232\n",
            "g_loss:[1.4695143, 1.4648196, 0.002347332]\n",
            "Batch:66\n",
            "d_loss_real:0.9115334749221802\n",
            "d_loss_fake:0.03321545943617821\n",
            "d_loss_wrong:0.6749788522720337\n",
            "d_loss:0.6328153163194656\n",
            "g_loss:[1.2076664, 1.2044942, 0.0015860932]\n",
            "Batch:67\n",
            "d_loss_real:0.9669228792190552\n",
            "d_loss_fake:0.041133880615234375\n",
            "d_loss_wrong:0.6305168867111206\n",
            "d_loss:0.6513741314411163\n",
            "g_loss:[1.2232548, 1.2202809, 0.0014869797]\n",
            "Batch:68\n",
            "d_loss_real:0.8860244154930115\n",
            "d_loss_fake:0.018532466143369675\n",
            "d_loss_wrong:0.6803713440895081\n",
            "d_loss:0.6177381575107574\n",
            "g_loss:[1.1319404, 1.1288183, 0.001561072]\n",
            "Batch:69\n",
            "d_loss_real:0.9692090749740601\n",
            "d_loss_fake:0.04577682912349701\n",
            "d_loss_wrong:0.7172231674194336\n",
            "d_loss:0.675354540348053\n",
            "g_loss:[1.1467506, 1.143625, 0.0015627603]\n",
            "Batch:70\n",
            "d_loss_real:0.8451389670372009\n",
            "d_loss_fake:0.02102997899055481\n",
            "d_loss_wrong:0.6522188782691956\n",
            "d_loss:0.5908817052841187\n",
            "g_loss:[0.9913952, 0.9879672, 0.0017139864]\n",
            "Batch:71\n",
            "d_loss_real:0.9265103340148926\n",
            "d_loss_fake:0.0057748788967728615\n",
            "d_loss_wrong:0.6464581489562988\n",
            "d_loss:0.6263134181499481\n",
            "g_loss:[1.0423926, 1.0394216, 0.00148552]\n",
            "Batch:72\n",
            "d_loss_real:0.8880530595779419\n",
            "d_loss_fake:0.004330901894718409\n",
            "d_loss_wrong:0.6653569340705872\n",
            "d_loss:0.6114484816789627\n",
            "g_loss:[0.9603339, 0.95730126, 0.0015163111]\n",
            "Batch:73\n",
            "d_loss_real:0.7937582731246948\n",
            "d_loss_fake:0.006267820950597525\n",
            "d_loss_wrong:0.6815872192382812\n",
            "d_loss:0.5688429027795792\n",
            "g_loss:[0.9598092, 0.9570927, 0.0013582427]\n",
            "Batch:74\n",
            "d_loss_real:0.8123322129249573\n",
            "d_loss_fake:0.0076995897106826305\n",
            "d_loss_wrong:0.6358080506324768\n",
            "d_loss:0.5670430213212967\n",
            "g_loss:[0.8064315, 0.8036909, 0.0013702696]\n",
            "Batch:75\n",
            "d_loss_real:0.8614400625228882\n",
            "d_loss_fake:0.004450998269021511\n",
            "d_loss_wrong:0.6635286808013916\n",
            "d_loss:0.5977149456739426\n",
            "g_loss:[0.80615443, 0.8028554, 0.0016495385]\n",
            "Batch:76\n",
            "d_loss_real:0.942432701587677\n",
            "d_loss_fake:0.030574047937989235\n",
            "d_loss_wrong:0.6735790967941284\n",
            "d_loss:0.6472546309232712\n",
            "g_loss:[0.7482099, 0.74534434, 0.0014327718]\n",
            "Batch:77\n",
            "d_loss_real:0.8244324326515198\n",
            "d_loss_fake:0.01168905757367611\n",
            "d_loss_wrong:0.6742518544197083\n",
            "d_loss:0.5837014466524124\n",
            "g_loss:[0.8847333, 0.88194215, 0.0013955695]\n",
            "Batch:78\n",
            "d_loss_real:0.921008825302124\n",
            "d_loss_fake:0.00716693140566349\n",
            "d_loss_wrong:0.6639395356178284\n",
            "d_loss:0.6282810270786285\n",
            "g_loss:[0.7862935, 0.7834063, 0.0014436042]\n",
            "Batch:79\n",
            "d_loss_real:0.8213177919387817\n",
            "d_loss_fake:0.0033454112708568573\n",
            "d_loss_wrong:0.6784160733222961\n",
            "d_loss:0.581099271774292\n",
            "g_loss:[0.84004325, 0.83684915, 0.0015970487]\n",
            "Batch:80\n",
            "d_loss_real:0.8725677728652954\n",
            "d_loss_fake:0.0036468550097197294\n",
            "d_loss_wrong:0.6693204045295715\n",
            "d_loss:0.604525700211525\n",
            "g_loss:[0.9172602, 0.91451466, 0.0013727988]\n",
            "Batch:81\n",
            "d_loss_real:0.7901712656021118\n",
            "d_loss_fake:0.007000789977610111\n",
            "d_loss_wrong:0.6368440389633179\n",
            "d_loss:0.5560468435287476\n",
            "g_loss:[0.7529411, 0.7491133, 0.0019138677]\n",
            "Batch:82\n",
            "d_loss_real:0.847728967666626\n",
            "d_loss_fake:0.0053722248412668705\n",
            "d_loss_wrong:0.6367197036743164\n",
            "d_loss:0.5843874663114548\n",
            "g_loss:[0.6999999, 0.69705844, 0.0014707407]\n",
            "Batch:83\n",
            "d_loss_real:0.8151849508285522\n",
            "d_loss_fake:0.008555371314287186\n",
            "d_loss_wrong:0.6483161449432373\n",
            "d_loss:0.5718103498220444\n",
            "g_loss:[0.8344493, 0.831315, 0.0015671641]\n",
            "Batch:84\n",
            "d_loss_real:0.8434818983078003\n",
            "d_loss_fake:0.0021653450094163418\n",
            "d_loss_wrong:0.6454063057899475\n",
            "d_loss:0.5836338549852371\n",
            "g_loss:[0.75557953, 0.75236595, 0.0016067959]\n",
            "Batch:85\n",
            "d_loss_real:0.8542259931564331\n",
            "d_loss_fake:0.008999675512313843\n",
            "d_loss_wrong:0.6387850046157837\n",
            "d_loss:0.5890591740608215\n",
            "g_loss:[0.7759804, 0.7730184, 0.0014809864]\n",
            "Batch:86\n",
            "d_loss_real:0.829939603805542\n",
            "d_loss_fake:0.003785943379625678\n",
            "d_loss_wrong:0.6476025581359863\n",
            "d_loss:0.5778169333934784\n",
            "g_loss:[0.79122114, 0.7886534, 0.0012838838]\n",
            "Batch:87\n",
            "d_loss_real:0.8169898986816406\n",
            "d_loss_fake:0.0027835629880428314\n",
            "d_loss_wrong:0.6341018676757812\n",
            "d_loss:0.5677163004875183\n",
            "g_loss:[0.841944, 0.83854455, 0.0016997308]\n",
            "Batch:88\n",
            "d_loss_real:0.9992392063140869\n",
            "d_loss_fake:0.013062085956335068\n",
            "d_loss_wrong:0.6512942910194397\n",
            "d_loss:0.6657086908817291\n",
            "g_loss:[0.6546923, 0.65045476, 0.0021187589]\n",
            "Batch:89\n",
            "d_loss_real:0.8577929735183716\n",
            "d_loss_fake:0.0030350424349308014\n",
            "d_loss_wrong:0.7171362042427063\n",
            "d_loss:0.6089393049478531\n",
            "g_loss:[0.7422013, 0.7368654, 0.0026679607]\n",
            "Batch:90\n",
            "d_loss_real:0.7939367294311523\n",
            "d_loss_fake:0.0024942592717707157\n",
            "d_loss_wrong:0.679056704044342\n",
            "d_loss:0.5673561096191406\n",
            "g_loss:[0.7449683, 0.7404048, 0.0022817492]\n",
            "Batch:91\n",
            "d_loss_real:0.8748937249183655\n",
            "d_loss_fake:0.005868050269782543\n",
            "d_loss_wrong:0.7033942937850952\n",
            "d_loss:0.6147624552249908\n",
            "g_loss:[0.69256693, 0.68893784, 0.0018145369]\n",
            "Batch:92\n",
            "d_loss_real:0.853406548500061\n",
            "d_loss_fake:0.0016512642614543438\n",
            "d_loss_wrong:0.6869368553161621\n",
            "d_loss:0.5988503098487854\n",
            "g_loss:[0.74426097, 0.7404005, 0.0019302228]\n",
            "Batch:93\n",
            "d_loss_real:0.865585446357727\n",
            "d_loss_fake:0.001972610829398036\n",
            "d_loss_wrong:0.6587671041488647\n",
            "d_loss:0.5979776531457901\n",
            "g_loss:[0.66205233, 0.65755904, 0.0022466336]\n",
            "Batch:94\n",
            "d_loss_real:0.8652673363685608\n",
            "d_loss_fake:0.0011796557810157537\n",
            "d_loss_wrong:0.6672354936599731\n",
            "d_loss:0.5997374504804611\n",
            "g_loss:[0.7097418, 0.70551413, 0.0021138333]\n",
            "Batch:95\n",
            "d_loss_real:0.8868234157562256\n",
            "d_loss_fake:0.003561988938599825\n",
            "d_loss_wrong:0.6676853895187378\n",
            "d_loss:0.6112235486507416\n",
            "g_loss:[0.6486786, 0.64459157, 0.0020435133]\n",
            "Batch:96\n",
            "d_loss_real:0.8264124393463135\n",
            "d_loss_fake:0.002905342262238264\n",
            "d_loss_wrong:0.6823451519012451\n",
            "d_loss:0.5845188498497009\n",
            "g_loss:[0.6597417, 0.6550033, 0.0023691875]\n",
            "Batch:97\n",
            "d_loss_real:0.8273534774780273\n",
            "d_loss_fake:0.001576181035488844\n",
            "d_loss_wrong:0.6760399341583252\n",
            "d_loss:0.5830807685852051\n",
            "g_loss:[0.66610897, 0.6615952, 0.002256867]\n",
            "Batch:98\n",
            "d_loss_real:0.885757565498352\n",
            "d_loss_fake:0.004617210477590561\n",
            "d_loss_wrong:0.6648861765861511\n",
            "d_loss:0.610254630446434\n",
            "g_loss:[0.676817, 0.67204463, 0.0023861835]\n",
            "Batch:99\n",
            "d_loss_real:0.8144649267196655\n",
            "d_loss_fake:0.0020213171374052763\n",
            "d_loss_wrong:0.6538340449333191\n",
            "d_loss:0.5711963027715683\n",
            "g_loss:[0.5883284, 0.58370006, 0.0023141797]\n",
            "Batch:100\n",
            "d_loss_real:0.8067045211791992\n",
            "d_loss_fake:0.0009435457759536803\n",
            "d_loss_wrong:0.6507443785667419\n",
            "d_loss:0.5662742406129837\n",
            "g_loss:[0.70835644, 0.7046194, 0.0018685177]\n",
            "Batch:101\n",
            "d_loss_real:0.8511832356452942\n",
            "d_loss_fake:0.002091711852699518\n",
            "d_loss_wrong:0.6491690874099731\n",
            "d_loss:0.5884068161249161\n",
            "g_loss:[0.6784097, 0.67489564, 0.0017570397]\n",
            "Batch:102\n",
            "d_loss_real:0.814632773399353\n",
            "d_loss_fake:0.0028408037032932043\n",
            "d_loss_wrong:0.6624345183372498\n",
            "d_loss:0.5736352205276489\n",
            "g_loss:[0.6817391, 0.6773741, 0.0021824855]\n",
            "Batch:103\n",
            "d_loss_real:0.8520950078964233\n",
            "d_loss_fake:0.0007567978464066982\n",
            "d_loss_wrong:0.6532868146896362\n",
            "d_loss:0.589558407664299\n",
            "g_loss:[0.6737122, 0.66964567, 0.0020332623]\n",
            "Batch:104\n",
            "d_loss_real:0.8296190500259399\n",
            "d_loss_fake:0.0002837238716892898\n",
            "d_loss_wrong:0.6734374761581421\n",
            "d_loss:0.5832398235797882\n",
            "g_loss:[0.58472645, 0.5807954, 0.0019655179]\n",
            "Batch:105\n",
            "d_loss_real:0.8399410843849182\n",
            "d_loss_fake:0.0009348719613626599\n",
            "d_loss_wrong:0.6395758986473083\n",
            "d_loss:0.5800982415676117\n",
            "g_loss:[0.50897944, 0.5056548, 0.0016623131]\n",
            "Batch:106\n",
            "d_loss_real:0.854568362236023\n",
            "d_loss_fake:0.0010460898047313094\n",
            "d_loss_wrong:0.646138608455658\n",
            "d_loss:0.589080348610878\n",
            "g_loss:[0.51475143, 0.5110743, 0.0018385624]\n",
            "Batch:107\n",
            "d_loss_real:0.8302117586135864\n",
            "d_loss_fake:0.0017950974870473146\n",
            "d_loss_wrong:0.6572251319885254\n",
            "d_loss:0.5798609405755997\n",
            "g_loss:[0.5447187, 0.54055953, 0.0020795856]\n",
            "Batch:108\n",
            "d_loss_real:0.8101282119750977\n",
            "d_loss_fake:0.0020650518126785755\n",
            "d_loss_wrong:0.6787369251251221\n",
            "d_loss:0.5752646028995514\n",
            "g_loss:[0.55002916, 0.5461771, 0.0019260367]\n",
            "Batch:109\n",
            "d_loss_real:0.853294312953949\n",
            "d_loss_fake:0.0007157203508540988\n",
            "d_loss_wrong:0.6436716914176941\n",
            "d_loss:0.5877440124750137\n",
            "g_loss:[0.57133937, 0.5666553, 0.0023420374]\n",
            "Batch:110\n",
            "d_loss_real:0.845763623714447\n",
            "d_loss_fake:0.0013430498074740171\n",
            "d_loss_wrong:0.6395202279090881\n",
            "d_loss:0.5830976366996765\n",
            "g_loss:[0.5738059, 0.5690409, 0.0023825099]\n",
            "Batch:111\n",
            "d_loss_real:0.8332184553146362\n",
            "d_loss_fake:0.0008291003759950399\n",
            "d_loss_wrong:0.6465014219284058\n",
            "d_loss:0.578441858291626\n",
            "g_loss:[0.5095204, 0.5053314, 0.0020944923]\n",
            "Batch:112\n",
            "d_loss_real:0.8848581910133362\n",
            "d_loss_fake:0.0007529315771535039\n",
            "d_loss_wrong:0.7979862093925476\n",
            "d_loss:0.6421138793230057\n",
            "g_loss:[0.7455614, 0.7400954, 0.0027330187]\n",
            "Batch:113\n",
            "d_loss_real:0.7863367199897766\n",
            "d_loss_fake:0.0005927879828959703\n",
            "d_loss_wrong:0.6453668475151062\n",
            "d_loss:0.5546582639217377\n",
            "g_loss:[0.509418, 0.5040419, 0.002688061]\n",
            "Batch:114\n",
            "d_loss_real:0.8302316665649414\n",
            "d_loss_fake:0.0015900315484032035\n",
            "d_loss_wrong:0.632731020450592\n",
            "d_loss:0.5736960917711258\n",
            "g_loss:[0.5809236, 0.5767001, 0.002111767]\n",
            "Batch:115\n",
            "d_loss_real:0.8372923135757446\n",
            "d_loss_fake:0.0009396899258717895\n",
            "d_loss_wrong:0.6329697966575623\n",
            "d_loss:0.5771235227584839\n",
            "g_loss:[0.5440503, 0.53961766, 0.002216318]\n",
            "Batch:116\n",
            "d_loss_real:0.9396516680717468\n",
            "d_loss_fake:0.00178802281152457\n",
            "d_loss_wrong:0.6624485850334167\n",
            "d_loss:0.6358849853277206\n",
            "g_loss:[0.62389183, 0.61992633, 0.0019827525]\n",
            "Batch:117\n",
            "d_loss_real:0.8058712482452393\n",
            "d_loss_fake:0.00401294743642211\n",
            "d_loss_wrong:0.6745612621307373\n",
            "d_loss:0.5725791752338409\n",
            "g_loss:[0.5455508, 0.54168046, 0.001935189]\n",
            "Batch:118\n",
            "d_loss_real:0.7999818921089172\n",
            "d_loss_fake:0.002117717172950506\n",
            "d_loss_wrong:0.6430960297584534\n",
            "d_loss:0.5612943768501282\n",
            "g_loss:[0.5797711, 0.5757785, 0.0019963067]\n",
            "Batch:119\n",
            "d_loss_real:0.8318160176277161\n",
            "d_loss_fake:0.0014683532062917948\n",
            "d_loss_wrong:0.6488721966743469\n",
            "d_loss:0.5784931480884552\n",
            "g_loss:[0.44883794, 0.44518578, 0.0018260777]\n",
            "Batch:120\n",
            "d_loss_real:0.8094174861907959\n",
            "d_loss_fake:0.0008044842397794127\n",
            "d_loss_wrong:0.6332812309265137\n",
            "d_loss:0.5632301717996597\n",
            "g_loss:[0.54178834, 0.5373468, 0.0022207662]\n",
            "Batch:121\n",
            "d_loss_real:0.8214462995529175\n",
            "d_loss_fake:0.0019281393615528941\n",
            "d_loss_wrong:0.6563339233398438\n",
            "d_loss:0.5752886682748795\n",
            "g_loss:[0.5894339, 0.58471185, 0.0023610392]\n",
            "Batch:122\n",
            "d_loss_real:0.8238316774368286\n",
            "d_loss_fake:0.004178790841251612\n",
            "d_loss_wrong:0.6440173983573914\n",
            "d_loss:0.5739648789167404\n",
            "g_loss:[0.56858593, 0.56378895, 0.002398497]\n",
            "Batch:123\n",
            "d_loss_real:0.8744415640830994\n",
            "d_loss_fake:0.0012822023127228022\n",
            "d_loss_wrong:0.670866847038269\n",
            "d_loss:0.605258047580719\n",
            "g_loss:[0.46981445, 0.4657486, 0.002032925]\n",
            "Batch:124\n",
            "d_loss_real:0.7988458275794983\n",
            "d_loss_fake:0.005966370925307274\n",
            "d_loss_wrong:0.6300838589668274\n",
            "d_loss:0.558435469865799\n",
            "g_loss:[0.6911433, 0.6869091, 0.002117084]\n",
            "Batch:125\n",
            "d_loss_real:0.8301951885223389\n",
            "d_loss_fake:0.0022602223325520754\n",
            "d_loss_wrong:0.629300057888031\n",
            "d_loss:0.5729876607656479\n",
            "g_loss:[0.59233254, 0.58749104, 0.0024207481]\n",
            "Batch:126\n",
            "d_loss_real:0.8347598910331726\n",
            "d_loss_fake:0.0006733021000400186\n",
            "d_loss_wrong:0.6462715864181519\n",
            "d_loss:0.57911616563797\n",
            "g_loss:[0.57339895, 0.5682113, 0.0025938125]\n",
            "Batch:127\n",
            "d_loss_real:0.804222583770752\n",
            "d_loss_fake:0.0032094144262373447\n",
            "d_loss_wrong:0.6463366746902466\n",
            "d_loss:0.5644978135824203\n",
            "g_loss:[0.6287343, 0.62451804, 0.0021081404]\n",
            "Batch:128\n",
            "d_loss_real:0.8607872724533081\n",
            "d_loss_fake:0.0034587476402521133\n",
            "d_loss_wrong:0.6768118143081665\n",
            "d_loss:0.6004612743854523\n",
            "g_loss:[0.650006, 0.64537853, 0.0023137436]\n",
            "Batch:129\n",
            "d_loss_real:0.8294180631637573\n",
            "d_loss_fake:0.0013550461735576391\n",
            "d_loss_wrong:0.6401872634887695\n",
            "d_loss:0.575094610452652\n",
            "g_loss:[0.66139466, 0.65647817, 0.0024582322]\n",
            "Batch:130\n",
            "d_loss_real:0.883354902267456\n",
            "d_loss_fake:0.0020406250841915607\n",
            "d_loss_wrong:0.6604941487312317\n",
            "d_loss:0.6073111444711685\n",
            "g_loss:[0.59030133, 0.5867567, 0.0017723071]\n",
            "Batch:131\n",
            "d_loss_real:0.8262240886688232\n",
            "d_loss_fake:0.0011147955665364861\n",
            "d_loss_wrong:0.6751097440719604\n",
            "d_loss:0.5821681767702103\n",
            "g_loss:[0.55773944, 0.55354893, 0.002095242]\n",
            "Batch:132\n",
            "d_loss_real:0.8114555478096008\n",
            "d_loss_fake:0.005485620349645615\n",
            "d_loss_wrong:0.6492493748664856\n",
            "d_loss:0.5694115161895752\n",
            "g_loss:[0.60973823, 0.60522264, 0.0022577806]\n",
            "Batch:133\n",
            "d_loss_real:0.8349640965461731\n",
            "d_loss_fake:0.002773162443190813\n",
            "d_loss_wrong:0.6482494473457336\n",
            "d_loss:0.5802377015352249\n",
            "g_loss:[0.766057, 0.7624378, 0.0018095988]\n",
            "Batch:134\n",
            "d_loss_real:0.8567719459533691\n",
            "d_loss_fake:0.06532888114452362\n",
            "d_loss_wrong:0.6252138018608093\n",
            "d_loss:0.6010216474533081\n",
            "g_loss:[1.1911732, 1.1875584, 0.0018073973]\n",
            "Batch:135\n",
            "d_loss_real:0.9098435044288635\n",
            "d_loss_fake:0.19653254747390747\n",
            "d_loss_wrong:0.5710334777832031\n",
            "d_loss:0.6468132585287094\n",
            "g_loss:[1.8772887, 1.8734565, 0.0019161198]\n",
            "Batch:136\n",
            "d_loss_real:0.9421758651733398\n",
            "d_loss_fake:0.15721803903579712\n",
            "d_loss_wrong:0.5298703908920288\n",
            "d_loss:0.6428600400686264\n",
            "g_loss:[2.1386645, 2.1351223, 0.0017710752]\n",
            "Batch:137\n",
            "d_loss_real:1.6874873638153076\n",
            "d_loss_fake:0.02349149063229561\n",
            "d_loss_wrong:0.6724129319190979\n",
            "d_loss:1.01771979033947\n",
            "g_loss:[1.4525119, 1.449238, 0.0016369706]\n",
            "Batch:138\n",
            "d_loss_real:0.7997623682022095\n",
            "d_loss_fake:0.07824558019638062\n",
            "d_loss_wrong:0.6591165661811829\n",
            "d_loss:0.5842217206954956\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "g_loss:[2.344422, 2.3405871, 0.0019175065]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "========================================\n",
            "Epoch is: 7\n",
            "Number of batches 138\n",
            "Batch:1\n",
            "d_loss_real:0.9172513484954834\n",
            "d_loss_fake:0.032865915447473526\n",
            "d_loss_wrong:0.6290776133537292\n",
            "d_loss:0.6241115629673004\n",
            "g_loss:[2.1460118, 2.1420016, 0.0020051328]\n",
            "Batch:2\n",
            "d_loss_real:0.9257047772407532\n",
            "d_loss_fake:0.005147060379385948\n",
            "d_loss_wrong:0.6455112099647522\n",
            "d_loss:0.625516951084137\n",
            "g_loss:[1.5511414, 1.5466323, 0.0022545217]\n",
            "Batch:3\n",
            "d_loss_real:0.8850537538528442\n",
            "d_loss_fake:0.016573304310441017\n",
            "d_loss_wrong:0.65024334192276\n",
            "d_loss:0.6092310398817062\n",
            "g_loss:[1.0344864, 1.030682, 0.0019022377]\n",
            "Batch:4\n",
            "d_loss_real:0.9221227169036865\n",
            "d_loss_fake:0.00964306015521288\n",
            "d_loss_wrong:0.6698526740074158\n",
            "d_loss:0.6309352964162827\n",
            "g_loss:[0.9245024, 0.9212296, 0.001636372]\n",
            "Batch:5\n",
            "d_loss_real:0.8800219297409058\n",
            "d_loss_fake:0.010926233604550362\n",
            "d_loss_wrong:0.7226276993751526\n",
            "d_loss:0.6233994513750076\n",
            "g_loss:[0.9815814, 0.9786616, 0.0014598819]\n",
            "Batch:6\n",
            "d_loss_real:0.8778924942016602\n",
            "d_loss_fake:0.009441448375582695\n",
            "d_loss_wrong:0.8006572127342224\n",
            "d_loss:0.6414709091186523\n",
            "g_loss:[0.9570432, 0.95366657, 0.0016882992]\n",
            "Batch:7\n",
            "d_loss_real:0.8289209008216858\n",
            "d_loss_fake:0.0023643733002245426\n",
            "d_loss_wrong:0.6482101678848267\n",
            "d_loss:0.5771040916442871\n",
            "g_loss:[1.0601102, 1.0569551, 0.0015775269]\n",
            "Batch:8\n",
            "d_loss_real:0.8863983154296875\n",
            "d_loss_fake:0.0029004004318267107\n",
            "d_loss_wrong:0.6011541485786438\n",
            "d_loss:0.5942128002643585\n",
            "g_loss:[1.0085227, 1.0025847, 0.0029690522]\n",
            "Batch:9\n",
            "d_loss_real:0.8746895790100098\n",
            "d_loss_fake:0.01696867309510708\n",
            "d_loss_wrong:0.6381346583366394\n",
            "d_loss:0.6011206209659576\n",
            "g_loss:[1.0627267, 1.0563433, 0.003191732]\n",
            "Batch:10\n",
            "d_loss_real:0.8537129759788513\n",
            "d_loss_fake:0.0028398793656378984\n",
            "d_loss_wrong:0.6497440934181213\n",
            "d_loss:0.5900024771690369\n",
            "g_loss:[0.9687526, 0.9645611, 0.002095758]\n",
            "Batch:11\n",
            "d_loss_real:0.8652116656303406\n",
            "d_loss_fake:0.009917809627950191\n",
            "d_loss_wrong:0.6767524480819702\n",
            "d_loss:0.6042733937501907\n",
            "g_loss:[1.0215008, 1.0172794, 0.0021107118]\n",
            "Batch:12\n",
            "d_loss_real:0.8959766030311584\n",
            "d_loss_fake:0.07494065165519714\n",
            "d_loss_wrong:0.479983389377594\n",
            "d_loss:0.5867193043231964\n",
            "g_loss:[3.7531984, 3.749816, 0.0016911955]\n",
            "Batch:13\n",
            "d_loss_real:1.4077067375183105\n",
            "d_loss_fake:0.08796107769012451\n",
            "d_loss_wrong:0.793961763381958\n",
            "d_loss:0.9243340790271759\n",
            "g_loss:[0.88341874, 0.88016343, 0.0016276536]\n",
            "Batch:14\n",
            "d_loss_real:0.7558765411376953\n",
            "d_loss_fake:0.08620387315750122\n",
            "d_loss_wrong:0.6796467304229736\n",
            "d_loss:0.5694009214639664\n",
            "g_loss:[1.1188636, 1.1161296, 0.0013669899]\n",
            "Batch:15\n",
            "d_loss_real:0.8877331018447876\n",
            "d_loss_fake:0.058821942657232285\n",
            "d_loss_wrong:0.6711043119430542\n",
            "d_loss:0.6263481080532074\n",
            "g_loss:[1.258708, 1.254709, 0.0019995188]\n",
            "Batch:16\n",
            "d_loss_real:0.8548651337623596\n",
            "d_loss_fake:0.012200210243463516\n",
            "d_loss_wrong:0.6702389121055603\n",
            "d_loss:0.5980423539876938\n",
            "g_loss:[1.0102165, 1.0063506, 0.0019329424]\n",
            "Batch:17\n",
            "d_loss_real:0.8046478629112244\n",
            "d_loss_fake:0.03990865498781204\n",
            "d_loss_wrong:0.6967049241065979\n",
            "d_loss:0.5864773243665695\n",
            "g_loss:[1.0190732, 1.0160099, 0.0015316429]\n",
            "Batch:18\n",
            "d_loss_real:0.8766995072364807\n",
            "d_loss_fake:0.011956226080656052\n",
            "d_loss_wrong:0.628530740737915\n",
            "d_loss:0.5984714925289154\n",
            "g_loss:[1.0083442, 1.0058782, 0.0012329747]\n",
            "Batch:19\n",
            "d_loss_real:0.8848323822021484\n",
            "d_loss_fake:0.04055362939834595\n",
            "d_loss_wrong:0.6540487408638\n",
            "d_loss:0.6160667836666107\n",
            "g_loss:[1.0257516, 1.0229859, 0.0013828543]\n",
            "Batch:20\n",
            "d_loss_real:0.8841608762741089\n",
            "d_loss_fake:0.005334869027137756\n",
            "d_loss_wrong:0.6608019471168518\n",
            "d_loss:0.6086146384477615\n",
            "g_loss:[1.1140636, 1.1114652, 0.0012992085]\n",
            "Batch:21\n",
            "d_loss_real:0.8680804967880249\n",
            "d_loss_fake:0.06245874613523483\n",
            "d_loss_wrong:0.6032382249832153\n",
            "d_loss:0.6004644930362701\n",
            "g_loss:[1.367962, 1.3649367, 0.001512665]\n",
            "Batch:22\n",
            "d_loss_real:0.9947596788406372\n",
            "d_loss_fake:0.0023231087252497673\n",
            "d_loss_wrong:0.640190839767456\n",
            "d_loss:0.6580083221197128\n",
            "g_loss:[1.0542023, 1.051648, 0.0012771458]\n",
            "Batch:23\n",
            "d_loss_real:1.0899722576141357\n",
            "d_loss_fake:0.041721634566783905\n",
            "d_loss_wrong:0.6878291964530945\n",
            "d_loss:0.7273738384246826\n",
            "g_loss:[0.89924127, 0.89620817, 0.0015165503]\n",
            "Batch:24\n",
            "d_loss_real:0.7719345092773438\n",
            "d_loss_fake:0.01041053980588913\n",
            "d_loss_wrong:0.6796116828918457\n",
            "d_loss:0.5584728121757507\n",
            "g_loss:[0.93807703, 0.93484914, 0.0016139373]\n",
            "Batch:25\n",
            "d_loss_real:0.8939584493637085\n",
            "d_loss_fake:0.07518470287322998\n",
            "d_loss_wrong:0.6704500913619995\n",
            "d_loss:0.6333879232406616\n",
            "g_loss:[1.0212901, 1.0179852, 0.0016524065]\n",
            "Batch:26\n",
            "d_loss_real:0.8413949012756348\n",
            "d_loss_fake:0.004978004842996597\n",
            "d_loss_wrong:0.6328504085540771\n",
            "d_loss:0.5801545530557632\n",
            "g_loss:[0.85626006, 0.85338545, 0.0014373078]\n",
            "Batch:27\n",
            "d_loss_real:0.8503139019012451\n",
            "d_loss_fake:0.01480800099670887\n",
            "d_loss_wrong:0.7192724347114563\n",
            "d_loss:0.6086770594120026\n",
            "g_loss:[0.9674498, 0.96479994, 0.0013249237]\n",
            "Batch:28\n",
            "d_loss_real:0.8009258508682251\n",
            "d_loss_fake:0.0473465621471405\n",
            "d_loss_wrong:0.6274183988571167\n",
            "d_loss:0.5691541731357574\n",
            "g_loss:[1.0883737, 1.0845046, 0.001934518]\n",
            "Batch:29\n",
            "d_loss_real:0.9262242913246155\n",
            "d_loss_fake:0.041455477476119995\n",
            "d_loss_wrong:0.6133680939674377\n",
            "d_loss:0.6268180310726166\n",
            "g_loss:[1.2700948, 1.2666416, 0.0017265392]\n",
            "Batch:30\n",
            "d_loss_real:1.168363094329834\n",
            "d_loss_fake:0.041930072009563446\n",
            "d_loss_wrong:0.8366525173187256\n",
            "d_loss:0.8038271963596344\n",
            "g_loss:[0.95614564, 0.9528591, 0.0016432774]\n",
            "Batch:31\n",
            "d_loss_real:0.8071032762527466\n",
            "d_loss_fake:0.09425279498100281\n",
            "d_loss_wrong:0.6480175256729126\n",
            "d_loss:0.5891192257404327\n",
            "g_loss:[1.0593034, 1.0558414, 0.0017309949]\n",
            "Batch:32\n",
            "d_loss_real:0.9457873106002808\n",
            "d_loss_fake:0.05777551233768463\n",
            "d_loss_wrong:0.5618475675582886\n",
            "d_loss:0.6277994215488434\n",
            "g_loss:[1.0017065, 0.9975014, 0.0021025692]\n",
            "Batch:33\n",
            "d_loss_real:0.8629998564720154\n",
            "d_loss_fake:0.03645732253789902\n",
            "d_loss_wrong:0.5988444089889526\n",
            "d_loss:0.5903253555297852\n",
            "g_loss:[1.5826163, 1.5791159, 0.0017502201]\n",
            "Batch:34\n",
            "d_loss_real:1.0283682346343994\n",
            "d_loss_fake:0.00026604667073115706\n",
            "d_loss_wrong:0.6234607100486755\n",
            "d_loss:0.6701158136129379\n",
            "g_loss:[1.0449128, 1.0417771, 0.0015678292]\n",
            "Batch:35\n",
            "d_loss_real:0.8594735860824585\n",
            "d_loss_fake:0.042351894080638885\n",
            "d_loss_wrong:0.6336960196495056\n",
            "d_loss:0.5987487733364105\n",
            "g_loss:[1.2256819, 1.2229843, 0.0013488103]\n",
            "Batch:36\n",
            "d_loss_real:0.866030752658844\n",
            "d_loss_fake:0.03846822679042816\n",
            "d_loss_wrong:0.6246421337127686\n",
            "d_loss:0.5987929701805115\n",
            "g_loss:[0.95188504, 0.94823384, 0.0018256037]\n",
            "Batch:37\n",
            "d_loss_real:0.8904590606689453\n",
            "d_loss_fake:0.011650236323475838\n",
            "d_loss_wrong:0.6453713774681091\n",
            "d_loss:0.6094849407672882\n",
            "g_loss:[0.9404885, 0.93676174, 0.001863387]\n",
            "Batch:38\n",
            "d_loss_real:0.8739495277404785\n",
            "d_loss_fake:0.01797259785234928\n",
            "d_loss_wrong:0.6700723767280579\n",
            "d_loss:0.6089860051870346\n",
            "g_loss:[0.8964799, 0.8934059, 0.0015369855]\n",
            "Batch:39\n",
            "d_loss_real:0.8897910714149475\n",
            "d_loss_fake:0.009258028119802475\n",
            "d_loss_wrong:0.649932861328125\n",
            "d_loss:0.6096932590007782\n",
            "g_loss:[0.9006543, 0.897052, 0.0018011747]\n",
            "Batch:40\n",
            "d_loss_real:0.8664417266845703\n",
            "d_loss_fake:0.006929283961653709\n",
            "d_loss_wrong:0.6582360863685608\n",
            "d_loss:0.5995122045278549\n",
            "g_loss:[0.9008506, 0.8976969, 0.001576848]\n",
            "Batch:41\n",
            "d_loss_real:0.8500522375106812\n",
            "d_loss_fake:0.0019207223085686564\n",
            "d_loss_wrong:0.6443995833396912\n",
            "d_loss:0.5866061896085739\n",
            "g_loss:[0.82227594, 0.81844914, 0.0019133949]\n",
            "Batch:42\n",
            "d_loss_real:0.8559125065803528\n",
            "d_loss_fake:0.002608578186482191\n",
            "d_loss_wrong:0.6626892685890198\n",
            "d_loss:0.5942807197570801\n",
            "g_loss:[0.82454276, 0.8209617, 0.0017905177]\n",
            "Batch:43\n",
            "d_loss_real:0.8299193382263184\n",
            "d_loss_fake:0.01772882044315338\n",
            "d_loss_wrong:0.6197203397750854\n",
            "d_loss:0.5743219554424286\n",
            "g_loss:[0.8281451, 0.8243692, 0.0018879478]\n",
            "Batch:44\n",
            "d_loss_real:0.8485860228538513\n",
            "d_loss_fake:0.006084224674850702\n",
            "d_loss_wrong:0.6394153833389282\n",
            "d_loss:0.5856679081916809\n",
            "g_loss:[0.8765009, 0.8724568, 0.0020220592]\n",
            "Batch:45\n",
            "d_loss_real:0.8403736352920532\n",
            "d_loss_fake:0.008987480774521828\n",
            "d_loss_wrong:0.599196195602417\n",
            "d_loss:0.5722327381372452\n",
            "g_loss:[0.91016895, 0.9049826, 0.00259316]\n",
            "Batch:46\n",
            "d_loss_real:0.8919245004653931\n",
            "d_loss_fake:0.0017828141571953893\n",
            "d_loss_wrong:0.642055332660675\n",
            "d_loss:0.6069217920303345\n",
            "g_loss:[0.8076745, 0.80360866, 0.0020329384]\n",
            "Batch:47\n",
            "d_loss_real:0.8177013397216797\n",
            "d_loss_fake:0.00565095990896225\n",
            "d_loss_wrong:0.659297525882721\n",
            "d_loss:0.5750877857208252\n",
            "g_loss:[0.8548939, 0.850333, 0.002280462]\n",
            "Batch:48\n",
            "d_loss_real:0.88555908203125\n",
            "d_loss_fake:0.0006574415601789951\n",
            "d_loss_wrong:0.6484922170639038\n",
            "d_loss:0.6050669550895691\n",
            "g_loss:[0.7743995, 0.77005, 0.0021747635]\n",
            "Batch:49\n",
            "d_loss_real:0.8213728666305542\n",
            "d_loss_fake:0.0017386043909937143\n",
            "d_loss_wrong:0.617148756980896\n",
            "d_loss:0.5654082745313644\n",
            "g_loss:[0.793648, 0.7888931, 0.0023774416]\n",
            "Batch:50\n",
            "d_loss_real:0.8499195575714111\n",
            "d_loss_fake:0.002808434423059225\n",
            "d_loss_wrong:0.6461257338523865\n",
            "d_loss:0.5871933251619339\n",
            "g_loss:[0.78635013, 0.78356457, 0.0013927787]\n",
            "Batch:51\n",
            "d_loss_real:0.8770800828933716\n",
            "d_loss_fake:0.03721152991056442\n",
            "d_loss_wrong:0.6727707982063293\n",
            "d_loss:0.6160356253385544\n",
            "g_loss:[0.8120416, 0.80894995, 0.0015458309]\n",
            "Batch:52\n",
            "d_loss_real:0.8621705770492554\n",
            "d_loss_fake:0.0011836013291031122\n",
            "d_loss_wrong:0.6991225481033325\n",
            "d_loss:0.6061618328094482\n",
            "g_loss:[0.7973306, 0.7951281, 0.0011012591]\n",
            "Batch:53\n",
            "d_loss_real:0.8026425838470459\n",
            "d_loss_fake:0.003426205599680543\n",
            "d_loss_wrong:0.6427438259124756\n",
            "d_loss:0.5628637969493866\n",
            "g_loss:[0.8368628, 0.8335736, 0.0016446218]\n",
            "Batch:54\n",
            "d_loss_real:0.8583545684814453\n",
            "d_loss_fake:0.03230845555663109\n",
            "d_loss_wrong:0.6565473079681396\n",
            "d_loss:0.6013912260532379\n",
            "g_loss:[0.89916253, 0.8963449, 0.0014088129]\n",
            "Batch:55\n",
            "d_loss_real:0.9062820076942444\n",
            "d_loss_fake:0.004690167028456926\n",
            "d_loss_wrong:0.6563031077384949\n",
            "d_loss:0.6183893233537674\n",
            "g_loss:[0.8515174, 0.8485282, 0.0014946009]\n",
            "Batch:56\n",
            "d_loss_real:0.8217685222625732\n",
            "d_loss_fake:0.13598905503749847\n",
            "d_loss_wrong:0.6352116465568542\n",
            "d_loss:0.6036844402551651\n",
            "g_loss:[0.9043113, 0.9008064, 0.0017524485]\n",
            "Batch:57\n",
            "d_loss_real:1.1694421768188477\n",
            "d_loss_fake:0.008509178645908833\n",
            "d_loss_wrong:0.6913055181503296\n",
            "d_loss:0.7596747577190399\n",
            "g_loss:[0.81337714, 0.8096955, 0.0018408301]\n",
            "Batch:58\n",
            "d_loss_real:0.7832008600234985\n",
            "d_loss_fake:0.3481923043727875\n",
            "d_loss_wrong:0.6247766613960266\n",
            "d_loss:0.6348426640033722\n",
            "g_loss:[1.1812325, 1.1780847, 0.0015738714]\n",
            "Batch:59\n",
            "d_loss_real:0.9389446973800659\n",
            "d_loss_fake:0.00446123955771327\n",
            "d_loss_wrong:0.622829020023346\n",
            "d_loss:0.6262949109077454\n",
            "g_loss:[1.0916462, 1.0888093, 0.0014184798]\n",
            "Batch:60\n",
            "d_loss_real:0.8798103928565979\n",
            "d_loss_fake:0.01026279665529728\n",
            "d_loss_wrong:0.6338514089584351\n",
            "d_loss:0.6009337455034256\n",
            "g_loss:[0.9862656, 0.9834717, 0.0013969465]\n",
            "Batch:61\n",
            "d_loss_real:0.891096830368042\n",
            "d_loss_fake:0.0015251890290528536\n",
            "d_loss_wrong:0.6177780032157898\n",
            "d_loss:0.6003742069005966\n",
            "g_loss:[0.85788536, 0.85556376, 0.0011607892]\n",
            "Batch:62\n",
            "d_loss_real:0.8430408239364624\n",
            "d_loss_fake:0.002813127590343356\n",
            "d_loss_wrong:0.635000467300415\n",
            "d_loss:0.5809738039970398\n",
            "g_loss:[1.1490263, 1.146394, 0.0013161104]\n",
            "Batch:63\n",
            "d_loss_real:0.8666219711303711\n",
            "d_loss_fake:0.006337705068290234\n",
            "d_loss_wrong:0.6134228706359863\n",
            "d_loss:0.5882511287927628\n",
            "g_loss:[0.83091354, 0.8281333, 0.0013901391]\n",
            "Batch:64\n",
            "d_loss_real:0.7956511974334717\n",
            "d_loss_fake:0.07665540277957916\n",
            "d_loss_wrong:0.6344310641288757\n",
            "d_loss:0.5755972117185593\n",
            "g_loss:[0.9134746, 0.9104992, 0.0014877119]\n",
            "Batch:65\n",
            "d_loss_real:0.9412569999694824\n",
            "d_loss_fake:0.004932327661663294\n",
            "d_loss_wrong:0.6746329665184021\n",
            "d_loss:0.6405198276042938\n",
            "g_loss:[1.0104744, 1.0070039, 0.0017352521]\n",
            "Batch:66\n",
            "d_loss_real:0.8740537166595459\n",
            "d_loss_fake:0.07342526316642761\n",
            "d_loss_wrong:0.5834389328956604\n",
            "d_loss:0.6012428998947144\n",
            "g_loss:[1.2208965, 1.2181373, 0.0013795896]\n",
            "Batch:67\n",
            "d_loss_real:0.8954914212226868\n",
            "d_loss_fake:0.026723284274339676\n",
            "d_loss_wrong:0.6262794137001038\n",
            "d_loss:0.6109963804483414\n",
            "g_loss:[1.2360274, 1.2332652, 0.0013810808]\n",
            "Batch:68\n",
            "d_loss_real:0.9399616122245789\n",
            "d_loss_fake:0.0012877298286184669\n",
            "d_loss_wrong:0.6353831887245178\n",
            "d_loss:0.629148542881012\n",
            "g_loss:[0.8854852, 0.8827858, 0.0013496883]\n",
            "Batch:69\n",
            "d_loss_real:0.895577609539032\n",
            "d_loss_fake:0.009955095127224922\n",
            "d_loss_wrong:0.6503539681434631\n",
            "d_loss:0.612866073846817\n",
            "g_loss:[0.8945415, 0.89213157, 0.0012049817]\n",
            "Batch:70\n",
            "d_loss_real:0.8428353071212769\n",
            "d_loss_fake:0.005934116430580616\n",
            "d_loss_wrong:0.6498244404792786\n",
            "d_loss:0.5853572934865952\n",
            "g_loss:[0.8851013, 0.88208485, 0.0015082441]\n",
            "Batch:71\n",
            "d_loss_real:0.8246212005615234\n",
            "d_loss_fake:0.02130214497447014\n",
            "d_loss_wrong:0.625335156917572\n",
            "d_loss:0.5739699304103851\n",
            "g_loss:[0.9980381, 0.9950043, 0.0015169089]\n",
            "Batch:72\n",
            "d_loss_real:1.1103074550628662\n",
            "d_loss_fake:0.4037097096443176\n",
            "d_loss_wrong:0.6569046974182129\n",
            "d_loss:0.8203073143959045\n",
            "g_loss:[0.97756875, 0.97494197, 0.0013133942]\n",
            "Batch:73\n",
            "d_loss_real:0.8547983169555664\n",
            "d_loss_fake:0.3432599902153015\n",
            "d_loss_wrong:0.5561555624008179\n",
            "d_loss:0.652253046631813\n",
            "g_loss:[1.2356912, 1.2330737, 0.001308724]\n",
            "Batch:74\n",
            "d_loss_real:0.8811913728713989\n",
            "d_loss_fake:0.07745693624019623\n",
            "d_loss_wrong:0.5571205019950867\n",
            "d_loss:0.5992400497198105\n",
            "g_loss:[1.8031696, 1.8003471, 0.001411281]\n",
            "Batch:75\n",
            "d_loss_real:0.9667816758155823\n",
            "d_loss_fake:0.10444854199886322\n",
            "d_loss_wrong:0.574055016040802\n",
            "d_loss:0.6530167311429977\n",
            "g_loss:[2.3346593, 2.3315806, 0.0015393682]\n",
            "Batch:76\n",
            "d_loss_real:1.0475926399230957\n",
            "d_loss_fake:0.007955522276461124\n",
            "d_loss_wrong:0.6015709638595581\n",
            "d_loss:0.6761779487133026\n",
            "g_loss:[1.34094, 1.3378785, 0.0015307863]\n",
            "Batch:77\n",
            "d_loss_real:0.9321401119232178\n",
            "d_loss_fake:0.03902563825249672\n",
            "d_loss_wrong:0.6006740927696228\n",
            "d_loss:0.6259949952363968\n",
            "g_loss:[1.4047987, 1.4009523, 0.0019232214]\n",
            "Batch:78\n",
            "d_loss_real:0.9260910749435425\n",
            "d_loss_fake:0.050631873309612274\n",
            "d_loss_wrong:0.6193832159042358\n",
            "d_loss:0.6305493116378784\n",
            "g_loss:[1.2941331, 1.2907493, 0.0016918792]\n",
            "Batch:79\n",
            "d_loss_real:0.9208662509918213\n",
            "d_loss_fake:0.022263098508119583\n",
            "d_loss_wrong:0.6160857677459717\n",
            "d_loss:0.6200203448534012\n",
            "g_loss:[1.1281959, 1.1245759, 0.0018100401]\n",
            "Batch:80\n",
            "d_loss_real:0.8630385398864746\n",
            "d_loss_fake:0.2287965714931488\n",
            "d_loss_wrong:0.6008056998252869\n",
            "d_loss:0.6389198303222656\n",
            "g_loss:[2.0687675, 2.065516, 0.0016257584]\n",
            "Batch:81\n",
            "d_loss_real:1.0025997161865234\n",
            "d_loss_fake:0.05491136759519577\n",
            "d_loss_wrong:0.5712303519248962\n",
            "d_loss:0.6578352898359299\n",
            "g_loss:[1.3734344, 1.3688858, 0.0022743356]\n",
            "Batch:82\n",
            "d_loss_real:1.0536667108535767\n",
            "d_loss_fake:0.11698192358016968\n",
            "d_loss_wrong:0.6631689071655273\n",
            "d_loss:0.7218710631132126\n",
            "g_loss:[2.2597373, 2.25485, 0.0024436219]\n",
            "Batch:83\n",
            "d_loss_real:0.8485485315322876\n",
            "d_loss_fake:0.06352000683546066\n",
            "d_loss_wrong:0.5946992039680481\n",
            "d_loss:0.5888290703296661\n",
            "g_loss:[1.333914, 1.3283063, 0.0028038346]\n",
            "Batch:84\n",
            "d_loss_real:0.9567691683769226\n",
            "d_loss_fake:0.01614183560013771\n",
            "d_loss_wrong:0.6055231094360352\n",
            "d_loss:0.633800819516182\n",
            "g_loss:[1.040978, 1.0348492, 0.0030643959]\n",
            "Batch:85\n",
            "d_loss_real:0.9666951894760132\n",
            "d_loss_fake:0.015686649829149246\n",
            "d_loss_wrong:0.6134947538375854\n",
            "d_loss:0.6406429409980774\n",
            "g_loss:[0.9937068, 0.9876609, 0.003022957]\n",
            "Batch:86\n",
            "d_loss_real:0.9107545614242554\n",
            "d_loss_fake:0.310332715511322\n",
            "d_loss_wrong:0.5276052951812744\n",
            "d_loss:0.6648617833852768\n",
            "g_loss:[2.0113394, 2.0061915, 0.0025739337]\n",
            "Batch:87\n",
            "d_loss_real:1.0144296884536743\n",
            "d_loss_fake:0.00871360581368208\n",
            "d_loss_wrong:0.5372025966644287\n",
            "d_loss:0.6436938941478729\n",
            "g_loss:[1.3588239, 1.3527656, 0.0030291802]\n",
            "Batch:88\n",
            "d_loss_real:1.2623544931411743\n",
            "d_loss_fake:0.1459077000617981\n",
            "d_loss_wrong:0.5452395081520081\n",
            "d_loss:0.8039640486240387\n",
            "g_loss:[1.2928301, 1.2852573, 0.0037863674]\n",
            "Batch:89\n",
            "d_loss_real:0.9629815220832825\n",
            "d_loss_fake:0.06317109614610672\n",
            "d_loss_wrong:0.64644455909729\n",
            "d_loss:0.6588946729898453\n",
            "g_loss:[1.2707949, 1.2658902, 0.0024523034]\n",
            "Batch:90\n",
            "d_loss_real:0.8875353336334229\n",
            "d_loss_fake:0.0017219064757227898\n",
            "d_loss_wrong:0.6345679759979248\n",
            "d_loss:0.6028401404619217\n",
            "g_loss:[0.961031, 0.9555366, 0.002747222]\n",
            "Batch:91\n",
            "d_loss_real:1.021599531173706\n",
            "d_loss_fake:0.008590707555413246\n",
            "d_loss_wrong:0.6785019040107727\n",
            "d_loss:0.6825729161500931\n",
            "g_loss:[0.8578794, 0.8526549, 0.0026122532]\n",
            "Batch:92\n",
            "d_loss_real:0.8302179574966431\n",
            "d_loss_fake:0.01834207959473133\n",
            "d_loss_wrong:0.714011013507843\n",
            "d_loss:0.5981972515583038\n",
            "g_loss:[0.97913396, 0.972932, 0.0031010062]\n",
            "Batch:93\n",
            "d_loss_real:0.8731749653816223\n",
            "d_loss_fake:0.0007137834327295423\n",
            "d_loss_wrong:0.6732298731803894\n",
            "d_loss:0.6050733923912048\n",
            "g_loss:[0.9465303, 0.9407666, 0.0028818646]\n",
            "Batch:94\n",
            "d_loss_real:0.9067045450210571\n",
            "d_loss_fake:0.004100511781871319\n",
            "d_loss_wrong:0.6490915417671204\n",
            "d_loss:0.6166502833366394\n",
            "g_loss:[1.010335, 1.0067992, 0.0017678505]\n",
            "Batch:95\n",
            "d_loss_real:0.9276202917098999\n",
            "d_loss_fake:0.007328242063522339\n",
            "d_loss_wrong:0.6468146443367004\n",
            "d_loss:0.627345860004425\n",
            "g_loss:[0.9343314, 0.93096286, 0.0016842771]\n",
            "Batch:96\n",
            "d_loss_real:0.8572123050689697\n",
            "d_loss_fake:0.0066055115312337875\n",
            "d_loss_wrong:0.6615525484085083\n",
            "d_loss:0.5956456661224365\n",
            "g_loss:[0.8952509, 0.89172465, 0.001763138]\n",
            "Batch:97\n",
            "d_loss_real:0.8320895433425903\n",
            "d_loss_fake:0.0036780559457838535\n",
            "d_loss_wrong:0.6844510436058044\n",
            "d_loss:0.5880770534276962\n",
            "g_loss:[0.9493624, 0.9459648, 0.0016987978]\n",
            "Batch:98\n",
            "d_loss_real:0.9417268633842468\n",
            "d_loss_fake:0.07836578786373138\n",
            "d_loss_wrong:0.6457094550132751\n",
            "d_loss:0.6518822461366653\n",
            "g_loss:[1.0646904, 1.0612701, 0.0017101143]\n",
            "Batch:99\n",
            "d_loss_real:0.8122190237045288\n",
            "d_loss_fake:0.047169312834739685\n",
            "d_loss_wrong:0.6594234108924866\n",
            "d_loss:0.5827576965093613\n",
            "g_loss:[1.1384567, 1.1336701, 0.002393302]\n",
            "Batch:100\n",
            "d_loss_real:0.821692705154419\n",
            "d_loss_fake:0.0005905028665438294\n",
            "d_loss_wrong:0.6371530294418335\n",
            "d_loss:0.5702822357416153\n",
            "g_loss:[1.1795245, 1.1738374, 0.002843535]\n",
            "Batch:101\n",
            "d_loss_real:0.8811032176017761\n",
            "d_loss_fake:0.0003420460852794349\n",
            "d_loss_wrong:0.6353030800819397\n",
            "d_loss:0.5994628965854645\n",
            "g_loss:[1.0012388, 0.9949862, 0.0031263453]\n",
            "Batch:102\n",
            "d_loss_real:0.8519964218139648\n",
            "d_loss_fake:0.0002483463613316417\n",
            "d_loss_wrong:0.6777638792991638\n",
            "d_loss:0.5955012738704681\n",
            "g_loss:[0.9483853, 0.9444706, 0.0019573453]\n",
            "Batch:103\n",
            "d_loss_real:0.8603713512420654\n",
            "d_loss_fake:0.0004970497102476656\n",
            "d_loss_wrong:0.654823899269104\n",
            "d_loss:0.5940159112215042\n",
            "g_loss:[0.93577737, 0.9317148, 0.0020312867]\n",
            "Batch:104\n",
            "d_loss_real:0.8193706274032593\n",
            "d_loss_fake:0.0005868502194061875\n",
            "d_loss_wrong:0.6871159672737122\n",
            "d_loss:0.5816110223531723\n",
            "g_loss:[0.9427731, 0.93883234, 0.0019703954]\n",
            "Batch:105\n",
            "d_loss_real:0.8567136526107788\n",
            "d_loss_fake:0.0007292305235750973\n",
            "d_loss_wrong:0.6379865407943726\n",
            "d_loss:0.5880357623100281\n",
            "g_loss:[0.89085704, 0.8875778, 0.0016396347]\n",
            "Batch:106\n",
            "d_loss_real:0.8611621260643005\n",
            "d_loss_fake:0.0005527585744857788\n",
            "d_loss_wrong:0.6391410827636719\n",
            "d_loss:0.59050452709198\n",
            "g_loss:[0.93877286, 0.9352493, 0.0017617625]\n",
            "Batch:107\n",
            "d_loss_real:0.8287197947502136\n",
            "d_loss_fake:0.001398846972733736\n",
            "d_loss_wrong:0.6548968553543091\n",
            "d_loss:0.5784338265657425\n",
            "g_loss:[0.84559804, 0.8420254, 0.0017863135]\n",
            "Batch:108\n",
            "d_loss_real:0.8123151063919067\n",
            "d_loss_fake:0.0009942182805389166\n",
            "d_loss_wrong:0.6767743825912476\n",
            "d_loss:0.5755997002124786\n",
            "g_loss:[0.88924694, 0.88629854, 0.0014742003]\n",
            "Batch:109\n",
            "d_loss_real:0.8579878807067871\n",
            "d_loss_fake:0.0009583611972630024\n",
            "d_loss_wrong:0.6442631483078003\n",
            "d_loss:0.5902993232011795\n",
            "g_loss:[0.8438814, 0.8408096, 0.0015359358]\n",
            "Batch:110\n",
            "d_loss_real:0.8429960608482361\n",
            "d_loss_fake:0.0014566988684237003\n",
            "d_loss_wrong:0.6401638984680176\n",
            "d_loss:0.5819031745195389\n",
            "g_loss:[0.9089231, 0.90558755, 0.0016677626]\n",
            "Batch:111\n",
            "d_loss_real:0.8173306584358215\n",
            "d_loss_fake:0.00047643930884078145\n",
            "d_loss_wrong:0.6557566523551941\n",
            "d_loss:0.5727235972881317\n",
            "g_loss:[0.8837762, 0.8801055, 0.0018353319]\n",
            "Batch:112\n",
            "d_loss_real:0.8911283016204834\n",
            "d_loss_fake:0.0017994698137044907\n",
            "d_loss_wrong:0.8011409640312195\n",
            "d_loss:0.6462992578744888\n",
            "g_loss:[0.84936684, 0.84565026, 0.0018582814]\n",
            "Batch:113\n",
            "d_loss_real:0.7846680879592896\n",
            "d_loss_fake:0.0013587010325863957\n",
            "d_loss_wrong:0.6501357555389404\n",
            "d_loss:0.5552076548337936\n",
            "g_loss:[0.86565393, 0.8618387, 0.0019076074]\n",
            "Batch:114\n",
            "d_loss_real:0.8203117251396179\n",
            "d_loss_fake:0.0016021397896111012\n",
            "d_loss_wrong:0.6377901434898376\n",
            "d_loss:0.5700039267539978\n",
            "g_loss:[0.8950992, 0.89164054, 0.001729334]\n",
            "Batch:115\n",
            "d_loss_real:0.8411637544631958\n",
            "d_loss_fake:0.001040642149746418\n",
            "d_loss_wrong:0.633713960647583\n",
            "d_loss:0.579270526766777\n",
            "g_loss:[0.88027, 0.876665, 0.0018025166]\n",
            "Batch:116\n",
            "d_loss_real:0.8957017660140991\n",
            "d_loss_fake:0.000944125815294683\n",
            "d_loss_wrong:0.6621995568275452\n",
            "d_loss:0.6136368066072464\n",
            "g_loss:[0.851763, 0.8484734, 0.001644786]\n",
            "Batch:117\n",
            "d_loss_real:0.833859920501709\n",
            "d_loss_fake:0.0016570375300943851\n",
            "d_loss_wrong:0.6690648794174194\n",
            "d_loss:0.5846104323863983\n",
            "g_loss:[0.86048853, 0.85727346, 0.0016075433]\n",
            "Batch:118\n",
            "d_loss_real:0.8003122806549072\n",
            "d_loss_fake:0.007774928584694862\n",
            "d_loss_wrong:0.6392364501953125\n",
            "d_loss:0.5619089901447296\n",
            "g_loss:[0.83089316, 0.82750064, 0.0016962672]\n",
            "Batch:119\n",
            "d_loss_real:0.8346431851387024\n",
            "d_loss_fake:0.002102864673361182\n",
            "d_loss_wrong:0.6507124900817871\n",
            "d_loss:0.5805254280567169\n",
            "g_loss:[0.8398121, 0.83674085, 0.0015356103]\n",
            "Batch:120\n",
            "d_loss_real:0.8057786226272583\n",
            "d_loss_fake:0.0010388302616775036\n",
            "d_loss_wrong:0.6357303261756897\n",
            "d_loss:0.5620816051959991\n",
            "g_loss:[0.8257508, 0.82194066, 0.001905079]\n",
            "Batch:121\n",
            "d_loss_real:0.8336383700370789\n",
            "d_loss_fake:0.0002488447935320437\n",
            "d_loss_wrong:0.6567029356956482\n",
            "d_loss:0.5810571312904358\n",
            "g_loss:[0.8572688, 0.8539875, 0.0016406411]\n",
            "Batch:122\n",
            "d_loss_real:0.8245508074760437\n",
            "d_loss_fake:0.0004503952222876251\n",
            "d_loss_wrong:0.6452099084854126\n",
            "d_loss:0.5736904740333557\n",
            "g_loss:[0.8263531, 0.82299376, 0.0016796672]\n",
            "Batch:123\n",
            "d_loss_real:0.861197292804718\n",
            "d_loss_fake:0.0010302886366844177\n",
            "d_loss_wrong:0.668338418006897\n",
            "d_loss:0.5979408174753189\n",
            "g_loss:[0.8305772, 0.8279109, 0.0013331436]\n",
            "Batch:124\n",
            "d_loss_real:0.7974650859832764\n",
            "d_loss_fake:0.0016133966855704784\n",
            "d_loss_wrong:0.6329452991485596\n",
            "d_loss:0.5573722124099731\n",
            "g_loss:[0.8568325, 0.85396016, 0.0014361744]\n",
            "Batch:125\n",
            "d_loss_real:0.8228464126586914\n",
            "d_loss_fake:0.0011224305490031838\n",
            "d_loss_wrong:0.6349306106567383\n",
            "d_loss:0.5704364627599716\n",
            "g_loss:[0.83987594, 0.83664507, 0.0016154445]\n",
            "Batch:126\n",
            "d_loss_real:0.8373075127601624\n",
            "d_loss_fake:0.0043046376667916775\n",
            "d_loss_wrong:0.6504000425338745\n",
            "d_loss:0.5823299288749695\n",
            "g_loss:[0.82486224, 0.82157063, 0.0016457941]\n",
            "Batch:127\n",
            "d_loss_real:0.7984493374824524\n",
            "d_loss_fake:0.003474003868177533\n",
            "d_loss_wrong:0.6515041589736938\n",
            "d_loss:0.5629692077636719\n",
            "g_loss:[0.78769314, 0.7847544, 0.001469377]\n",
            "Batch:128\n",
            "d_loss_real:0.8724265098571777\n",
            "d_loss_fake:0.028249874711036682\n",
            "d_loss_wrong:0.6769530177116394\n",
            "d_loss:0.6125139743089676\n",
            "g_loss:[0.8011243, 0.79811597, 0.0015041485]\n",
            "Batch:129\n",
            "d_loss_real:0.8527933359146118\n",
            "d_loss_fake:0.0002706946397665888\n",
            "d_loss_wrong:0.6256988644599915\n",
            "d_loss:0.5828890651464462\n",
            "g_loss:[0.8707865, 0.86774427, 0.0015211252]\n",
            "Batch:130\n",
            "d_loss_real:0.8826910257339478\n",
            "d_loss_fake:0.0014783947262912989\n",
            "d_loss_wrong:0.661508321762085\n",
            "d_loss:0.6070921868085861\n",
            "g_loss:[0.779327, 0.77679265, 0.0012671542]\n",
            "Batch:131\n",
            "d_loss_real:0.8515208959579468\n",
            "d_loss_fake:0.0005928903119638562\n",
            "d_loss_wrong:0.6630130410194397\n",
            "d_loss:0.5916619300842285\n",
            "g_loss:[0.7863619, 0.78365517, 0.0013533582]\n",
            "Batch:132\n",
            "d_loss_real:0.8166235685348511\n",
            "d_loss_fake:0.0009115624707192183\n",
            "d_loss_wrong:0.6477071642875671\n",
            "d_loss:0.5704664587974548\n",
            "g_loss:[0.78661203, 0.7838849, 0.0013635886]\n",
            "Batch:133\n",
            "d_loss_real:0.8359068036079407\n",
            "d_loss_fake:0.000963238999247551\n",
            "d_loss_wrong:0.6440762877464294\n",
            "d_loss:0.5792132765054703\n",
            "g_loss:[0.82719713, 0.8244636, 0.0013667617]\n",
            "Batch:134\n",
            "d_loss_real:0.8598817586898804\n",
            "d_loss_fake:0.005664205178618431\n",
            "d_loss_wrong:0.6615747213363647\n",
            "d_loss:0.5967506170272827\n",
            "g_loss:[0.8330084, 0.8297995, 0.0016044679]\n",
            "Batch:135\n",
            "d_loss_real:0.8260364532470703\n",
            "d_loss_fake:0.0012611959828063846\n",
            "d_loss_wrong:0.6568089723587036\n",
            "d_loss:0.5775357633829117\n",
            "g_loss:[0.855312, 0.85253227, 0.0013898683]\n",
            "Batch:136\n",
            "d_loss_real:0.8226652145385742\n",
            "d_loss_fake:0.0009804186411201954\n",
            "d_loss_wrong:0.6395881175994873\n",
            "d_loss:0.5714747458696365\n",
            "g_loss:[0.801503, 0.79883724, 0.0013328821]\n",
            "Batch:137\n",
            "d_loss_real:0.8533826470375061\n",
            "d_loss_fake:0.0004693546798080206\n",
            "d_loss_wrong:0.6381906270980835\n",
            "d_loss:0.5863563120365143\n",
            "g_loss:[0.80446076, 0.8019608, 0.001249969]\n",
            "Batch:138\n",
            "d_loss_real:0.8158775568008423\n",
            "d_loss_fake:0.0008710932452231646\n",
            "d_loss_wrong:0.6549428105354309\n",
            "d_loss:0.571892261505127\n",
            "g_loss:[0.7877153, 0.78490245, 0.0014064261]\n",
            "========================================\n",
            "Epoch is: 8\n",
            "Number of batches 138\n",
            "Batch:1\n",
            "d_loss_real:0.8998450040817261\n",
            "d_loss_fake:0.0011220737360417843\n",
            "d_loss_wrong:0.6721304059028625\n",
            "d_loss:0.6182356178760529\n",
            "g_loss:[0.77537155, 0.7727818, 0.0012948908]\n",
            "Batch:2\n",
            "d_loss_real:0.8245549201965332\n",
            "d_loss_fake:0.0033625373616814613\n",
            "d_loss_wrong:0.6688749194145203\n",
            "d_loss:0.5803368240594864\n",
            "g_loss:[0.7596853, 0.756979, 0.0013531395]\n",
            "Batch:3\n",
            "d_loss_real:0.8400046825408936\n",
            "d_loss_fake:0.0006677376222796738\n",
            "d_loss_wrong:0.676284670829773\n",
            "d_loss:0.5892404466867447\n",
            "g_loss:[0.7964144, 0.79389966, 0.0012573509]\n",
            "Batch:4\n",
            "d_loss_real:0.8371752500534058\n",
            "d_loss_fake:0.001901690848171711\n",
            "d_loss_wrong:0.6908905506134033\n",
            "d_loss:0.5917856842279434\n",
            "g_loss:[0.7649448, 0.7625193, 0.0012127351]\n",
            "Batch:5\n",
            "d_loss_real:0.8147703409194946\n",
            "d_loss_fake:0.00205161701887846\n",
            "d_loss_wrong:0.7507239580154419\n",
            "d_loss:0.5955790579319\n",
            "g_loss:[0.75854015, 0.75574374, 0.0013982188]\n",
            "Batch:6\n",
            "d_loss_real:0.8402169942855835\n",
            "d_loss_fake:0.06698150932788849\n",
            "d_loss_wrong:0.7476932406425476\n",
            "d_loss:0.6237771809101105\n",
            "g_loss:[1.4210243, 1.4182236, 0.0014003686]\n",
            "Batch:7\n",
            "d_loss_real:0.9031791687011719\n",
            "d_loss_fake:0.0422554686665535\n",
            "d_loss_wrong:0.5553402304649353\n",
            "d_loss:0.600988507270813\n",
            "g_loss:[1.214205, 1.211813, 0.0011960524]\n",
            "Batch:8\n",
            "d_loss_real:1.1120104789733887\n",
            "d_loss_fake:0.007456695660948753\n",
            "d_loss_wrong:0.6119789481163025\n",
            "d_loss:0.7108641564846039\n",
            "g_loss:[0.9278576, 0.92434883, 0.0017543875]\n",
            "Batch:9\n",
            "d_loss_real:0.8855507373809814\n",
            "d_loss_fake:0.31420671939849854\n",
            "d_loss_wrong:0.5885199904441833\n",
            "d_loss:0.6684570461511612\n",
            "g_loss:[1.1081415, 1.1039307, 0.0021054076]\n",
            "Batch:10\n",
            "d_loss_real:0.9190996885299683\n",
            "d_loss_fake:0.023306161165237427\n",
            "d_loss_wrong:0.5597281455993652\n",
            "d_loss:0.6053084135055542\n",
            "g_loss:[1.6355001, 1.6322374, 0.0016313437]\n",
            "Batch:11\n",
            "d_loss_real:1.0717393159866333\n",
            "d_loss_fake:0.05220375955104828\n",
            "d_loss_wrong:0.6861069202423096\n",
            "d_loss:0.7204473316669464\n",
            "g_loss:[1.1909536, 1.1880156, 0.0014690006]\n",
            "Batch:12\n",
            "d_loss_real:1.0280072689056396\n",
            "d_loss_fake:0.23923470079898834\n",
            "d_loss_wrong:0.5531237125396729\n",
            "d_loss:0.7120932340621948\n",
            "g_loss:[1.2114474, 1.208604, 0.0014216794]\n",
            "Batch:13\n",
            "d_loss_real:1.2139967679977417\n",
            "d_loss_fake:0.37280282378196716\n",
            "d_loss_wrong:0.5450711250305176\n",
            "d_loss:0.8364668786525726\n",
            "g_loss:[1.2431779, 1.2402676, 0.0014551107]\n",
            "Batch:14\n",
            "d_loss_real:0.961267352104187\n",
            "d_loss_fake:0.28109627962112427\n",
            "d_loss_wrong:0.49947404861450195\n",
            "d_loss:0.6757762581110001\n",
            "g_loss:[1.2821082, 1.2790091, 0.0015495289]\n",
            "Batch:15\n",
            "d_loss_real:1.1425704956054688\n",
            "d_loss_fake:0.18535664677619934\n",
            "d_loss_wrong:0.499624103307724\n",
            "d_loss:0.7425304353237152\n",
            "g_loss:[1.3248591, 1.3213551, 0.0017520149]\n",
            "Batch:16\n",
            "d_loss_real:1.1236190795898438\n",
            "d_loss_fake:0.24226051568984985\n",
            "d_loss_wrong:0.5283006429672241\n",
            "d_loss:0.7544498294591904\n",
            "g_loss:[1.2837713, 1.2804408, 0.0016652611]\n",
            "Batch:17\n",
            "d_loss_real:1.1211798191070557\n",
            "d_loss_fake:0.09289181977510452\n",
            "d_loss_wrong:0.6109909415245056\n",
            "d_loss:0.7365605980157852\n",
            "g_loss:[1.2211287, 1.217634, 0.0017473486]\n",
            "Batch:18\n",
            "d_loss_real:0.9632951021194458\n",
            "d_loss_fake:0.061787329614162445\n",
            "d_loss_wrong:0.593451738357544\n",
            "d_loss:0.645457312464714\n",
            "g_loss:[1.4802368, 1.4774086, 0.0014140769]\n",
            "Batch:19\n",
            "d_loss_real:1.0313172340393066\n",
            "d_loss_fake:0.020981475710868835\n",
            "d_loss_wrong:0.6202695369720459\n",
            "d_loss:0.6759713739156723\n",
            "g_loss:[1.2270908, 1.2242442, 0.0014232852]\n",
            "Batch:20\n",
            "d_loss_real:0.952897310256958\n",
            "d_loss_fake:0.1325216293334961\n",
            "d_loss_wrong:0.5614880919456482\n",
            "d_loss:0.6499510854482651\n",
            "g_loss:[2.2387826, 2.2354074, 0.0016876375]\n",
            "Batch:21\n",
            "d_loss_real:1.2386763095855713\n",
            "d_loss_fake:0.2846826910972595\n",
            "d_loss_wrong:0.6056827306747437\n",
            "d_loss:0.8419295102357864\n",
            "g_loss:[1.156053, 1.1527271, 0.0016628939]\n",
            "Batch:22\n",
            "d_loss_real:0.9948019981384277\n",
            "d_loss_fake:0.32948702573776245\n",
            "d_loss_wrong:0.5473731160163879\n",
            "d_loss:0.7166160345077515\n",
            "g_loss:[1.6177912, 1.6148027, 0.0014942174]\n",
            "Batch:23\n",
            "d_loss_real:1.2017366886138916\n",
            "d_loss_fake:0.3196222186088562\n",
            "d_loss_wrong:0.4967432916164398\n",
            "d_loss:0.8049597144126892\n",
            "g_loss:[1.2792965, 1.2754974, 0.0018995281]\n",
            "Batch:24\n",
            "d_loss_real:1.0055720806121826\n",
            "d_loss_fake:0.23177312314510345\n",
            "d_loss_wrong:0.5107502937316895\n",
            "d_loss:0.6884168982505798\n",
            "g_loss:[1.3288608, 1.3228657, 0.0029974948]\n",
            "Batch:25\n",
            "d_loss_real:1.2922389507293701\n",
            "d_loss_fake:0.25060752034187317\n",
            "d_loss_wrong:0.4754580557346344\n",
            "d_loss:0.827635869383812\n",
            "g_loss:[1.2550231, 1.2496507, 0.0026861818]\n",
            "Batch:26\n",
            "d_loss_real:1.0792851448059082\n",
            "d_loss_fake:0.23110738396644592\n",
            "d_loss_wrong:0.5664819478988647\n",
            "d_loss:0.7390398979187012\n",
            "g_loss:[1.4033216, 1.3997979, 0.0017618593]\n",
            "Batch:27\n",
            "d_loss_real:1.2636452913284302\n",
            "d_loss_fake:0.11850989609956741\n",
            "d_loss_wrong:0.5641863346099854\n",
            "d_loss:0.8024967014789581\n",
            "g_loss:[1.6323787, 1.6273216, 0.0025285636]\n",
            "Batch:28\n",
            "d_loss_real:1.201237678527832\n",
            "d_loss_fake:0.07856355607509613\n",
            "d_loss_wrong:0.6935413479804993\n",
            "d_loss:0.7936450690031052\n",
            "g_loss:[1.2650677, 1.260496, 0.0022858488]\n",
            "Batch:29\n",
            "d_loss_real:0.8868029117584229\n",
            "d_loss_fake:0.1967233270406723\n",
            "d_loss_wrong:0.6053606867790222\n",
            "d_loss:0.6439224630594254\n",
            "g_loss:[2.100628, 2.0969534, 0.0018372663]\n",
            "Batch:30\n",
            "d_loss_real:1.5807451009750366\n",
            "d_loss_fake:0.3792106807231903\n",
            "d_loss_wrong:0.6627494692802429\n",
            "d_loss:1.050862580537796\n",
            "g_loss:[1.1490844, 1.142978, 0.0030532735]\n",
            "Batch:31\n",
            "d_loss_real:0.9886989593505859\n",
            "d_loss_fake:0.3717387318611145\n",
            "d_loss_wrong:0.509208083152771\n",
            "d_loss:0.7145861834287643\n",
            "g_loss:[1.2495615, 1.2441857, 0.0026879134]\n",
            "Batch:32\n",
            "d_loss_real:1.158918857574463\n",
            "d_loss_fake:0.3255484104156494\n",
            "d_loss_wrong:0.455562561750412\n",
            "d_loss:0.7747371792793274\n",
            "g_loss:[1.2392902, 1.2340109, 0.002639635]\n",
            "Batch:33\n",
            "d_loss_real:1.0640153884887695\n",
            "d_loss_fake:0.3358440399169922\n",
            "d_loss_wrong:0.4652857780456543\n",
            "d_loss:0.7322901487350464\n",
            "g_loss:[1.2625277, 1.2569175, 0.0028051173]\n",
            "Batch:34\n",
            "d_loss_real:1.1265966892242432\n",
            "d_loss_fake:0.32968345284461975\n",
            "d_loss_wrong:0.42614230513572693\n",
            "d_loss:0.7522547841072083\n",
            "g_loss:[1.1582447, 1.1540995, 0.0020726328]\n",
            "Batch:35\n",
            "d_loss_real:1.2053035497665405\n",
            "d_loss_fake:0.3699614405632019\n",
            "d_loss_wrong:0.42981842160224915\n",
            "d_loss:0.8025967478752136\n",
            "g_loss:[1.1188135, 1.1145449, 0.0021343]\n",
            "Batch:36\n",
            "d_loss_real:1.1539580821990967\n",
            "d_loss_fake:0.379578173160553\n",
            "d_loss_wrong:0.4328587055206299\n",
            "d_loss:0.780088260769844\n",
            "g_loss:[1.1479385, 1.1433506, 0.0022939313]\n",
            "Batch:37\n",
            "d_loss_real:1.1108927726745605\n",
            "d_loss_fake:0.3636963963508606\n",
            "d_loss_wrong:0.46841108798980713\n",
            "d_loss:0.7634732574224472\n",
            "g_loss:[1.2855666, 1.2817657, 0.001900445]\n",
            "Batch:38\n",
            "d_loss_real:1.210228681564331\n",
            "d_loss_fake:0.31407004594802856\n",
            "d_loss_wrong:0.5039393305778503\n",
            "d_loss:0.8096166849136353\n",
            "g_loss:[1.27658, 1.2732081, 0.0016858967]\n",
            "Batch:39\n",
            "d_loss_real:1.233964443206787\n",
            "d_loss_fake:0.3190804123878479\n",
            "d_loss_wrong:0.41684451699256897\n",
            "d_loss:0.8009634613990784\n",
            "g_loss:[1.2823225, 1.2788754, 0.0017235738]\n",
            "Batch:40\n",
            "d_loss_real:1.1396336555480957\n",
            "d_loss_fake:0.3127264380455017\n",
            "d_loss_wrong:0.5121724009513855\n",
            "d_loss:0.7760415375232697\n",
            "g_loss:[1.1593155, 1.1561874, 0.0015640329]\n",
            "Batch:41\n",
            "d_loss_real:1.0515161752700806\n",
            "d_loss_fake:0.34196463227272034\n",
            "d_loss_wrong:0.48726126551628113\n",
            "d_loss:0.7330645620822906\n",
            "g_loss:[1.0237083, 1.0203576, 0.0016753804]\n",
            "Batch:42\n",
            "d_loss_real:1.0840673446655273\n",
            "d_loss_fake:0.328044056892395\n",
            "d_loss_wrong:0.4772067964076996\n",
            "d_loss:0.7433463931083679\n",
            "g_loss:[1.011372, 1.0075289, 0.0019215528]\n",
            "Batch:43\n",
            "d_loss_real:1.1819101572036743\n",
            "d_loss_fake:0.3240595757961273\n",
            "d_loss_wrong:0.4359765350818634\n",
            "d_loss:0.7809641063213348\n",
            "g_loss:[0.964721, 0.96099573, 0.0018626421]\n",
            "Batch:44\n",
            "d_loss_real:1.1046397686004639\n",
            "d_loss_fake:0.3649837374687195\n",
            "d_loss_wrong:0.4200368821620941\n",
            "d_loss:0.7485750317573547\n",
            "g_loss:[1.0381753, 1.0344565, 0.0018594401]\n",
            "Batch:45\n",
            "d_loss_real:1.219596266746521\n",
            "d_loss_fake:0.3202210068702698\n",
            "d_loss_wrong:0.39760279655456543\n",
            "d_loss:0.7892540842294693\n",
            "g_loss:[1.1172477, 1.1132807, 0.0019835008]\n",
            "Batch:46\n",
            "d_loss_real:1.0823404788970947\n",
            "d_loss_fake:0.22008872032165527\n",
            "d_loss_wrong:0.466776967048645\n",
            "d_loss:0.7128866612911224\n",
            "g_loss:[1.429445, 1.426219, 0.0016130265]\n",
            "Batch:47\n",
            "d_loss_real:1.0520414113998413\n",
            "d_loss_fake:0.15980415046215057\n",
            "d_loss_wrong:0.4924061894416809\n",
            "d_loss:0.6890732944011688\n",
            "g_loss:[0.99302804, 0.9897644, 0.0016318224]\n",
            "Batch:48\n",
            "d_loss_real:1.1990432739257812\n",
            "d_loss_fake:0.31494927406311035\n",
            "d_loss_wrong:0.6098836064338684\n",
            "d_loss:0.8307298570871353\n",
            "g_loss:[1.065555, 1.0624363, 0.0015593325]\n",
            "Batch:49\n",
            "d_loss_real:1.1138124465942383\n",
            "d_loss_fake:0.2268725037574768\n",
            "d_loss_wrong:0.4379204213619232\n",
            "d_loss:0.7231044471263885\n",
            "g_loss:[1.0817937, 1.0787235, 0.0015350481]\n",
            "Batch:50\n",
            "d_loss_real:1.1192071437835693\n",
            "d_loss_fake:0.31699925661087036\n",
            "d_loss_wrong:0.5486928820610046\n",
            "d_loss:0.7760266065597534\n",
            "g_loss:[1.2494956, 1.2472699, 0.0011128939]\n",
            "Batch:51\n",
            "d_loss_real:1.0644475221633911\n",
            "d_loss_fake:0.2535405457019806\n",
            "d_loss_wrong:0.49448952078819275\n",
            "d_loss:0.7192312777042389\n",
            "g_loss:[1.0151105, 1.0125809, 0.0012648059]\n",
            "Batch:52\n",
            "d_loss_real:1.093191385269165\n",
            "d_loss_fake:0.2732318341732025\n",
            "d_loss_wrong:0.5381094217300415\n",
            "d_loss:0.7494310140609741\n",
            "g_loss:[1.0977141, 1.0958637, 0.000925184]\n",
            "Batch:53\n",
            "d_loss_real:1.0346176624298096\n",
            "d_loss_fake:0.2027967870235443\n",
            "d_loss_wrong:0.46810775995254517\n",
            "d_loss:0.6850349605083466\n",
            "g_loss:[1.035027, 1.0322158, 0.0014056169]\n",
            "Batch:54\n",
            "d_loss_real:1.0462720394134521\n",
            "d_loss_fake:0.189951092004776\n",
            "d_loss_wrong:0.5205328464508057\n",
            "d_loss:0.7007569968700409\n",
            "g_loss:[1.0515071, 1.0489383, 0.0012844057]\n",
            "Batch:55\n",
            "d_loss_real:1.0824007987976074\n",
            "d_loss_fake:0.1296655833721161\n",
            "d_loss_wrong:0.5055662393569946\n",
            "d_loss:0.700008362531662\n",
            "g_loss:[1.1055384, 1.1027261, 0.0014061612]\n",
            "Batch:56\n",
            "d_loss_real:0.9816517233848572\n",
            "d_loss_fake:0.09373484551906586\n",
            "d_loss_wrong:0.66587233543396\n",
            "d_loss:0.6807276606559753\n",
            "g_loss:[1.029415, 1.025879, 0.0017679881]\n",
            "Batch:57\n",
            "d_loss_real:1.0360071659088135\n",
            "d_loss_fake:0.10242240130901337\n",
            "d_loss_wrong:0.5758147835731506\n",
            "d_loss:0.687562882900238\n",
            "g_loss:[0.94665337, 0.9426719, 0.0019907497]\n",
            "Batch:58\n",
            "d_loss_real:1.0685454607009888\n",
            "d_loss_fake:0.057218387722969055\n",
            "d_loss_wrong:0.562673032283783\n",
            "d_loss:0.6892455816268921\n",
            "g_loss:[0.80290973, 0.7998379, 0.0015359235]\n",
            "Batch:59\n",
            "d_loss_real:0.9600316882133484\n",
            "d_loss_fake:0.04496580362319946\n",
            "d_loss_wrong:0.7078834176063538\n",
            "d_loss:0.6682281494140625\n",
            "g_loss:[0.715854, 0.71281016, 0.0015219252]\n",
            "Batch:60\n",
            "d_loss_real:0.9327026605606079\n",
            "d_loss_fake:0.03463166952133179\n",
            "d_loss_wrong:0.6329205632209778\n",
            "d_loss:0.6332393884658813\n",
            "g_loss:[0.7441456, 0.74143803, 0.0013537807]\n",
            "Batch:61\n",
            "d_loss_real:0.992743730545044\n",
            "d_loss_fake:0.008257283829152584\n",
            "d_loss_wrong:0.6119001507759094\n",
            "d_loss:0.6514112204313278\n",
            "g_loss:[0.6629237, 0.66068256, 0.0011205681]\n",
            "Batch:62\n",
            "d_loss_real:0.9887787103652954\n",
            "d_loss_fake:0.024246934801340103\n",
            "d_loss_wrong:0.608646810054779\n",
            "d_loss:0.6526127904653549\n",
            "g_loss:[0.5734528, 0.57148206, 0.0009853516]\n",
            "Batch:63\n",
            "d_loss_real:0.935003399848938\n",
            "d_loss_fake:0.02394712343811989\n",
            "d_loss_wrong:0.6199918985366821\n",
            "d_loss:0.6284864544868469\n",
            "g_loss:[0.5550972, 0.55233616, 0.0013805418]\n",
            "Batch:64\n",
            "d_loss_real:0.9589784145355225\n",
            "d_loss_fake:0.03759752959012985\n",
            "d_loss_wrong:0.5810641050338745\n",
            "d_loss:0.6341546177864075\n",
            "g_loss:[0.5526298, 0.54998124, 0.0013243078]\n",
            "Batch:65\n",
            "d_loss_real:0.9504885673522949\n",
            "d_loss_fake:0.002152706030756235\n",
            "d_loss_wrong:0.6647582054138184\n",
            "d_loss:0.641972005367279\n",
            "g_loss:[0.3857386, 0.38285378, 0.0014424219]\n",
            "Batch:66\n",
            "d_loss_real:0.855154812335968\n",
            "d_loss_fake:0.03997405618429184\n",
            "d_loss_wrong:0.7124947905540466\n",
            "d_loss:0.6156946122646332\n",
            "g_loss:[0.43493357, 0.43249, 0.001221784]\n",
            "Batch:67\n",
            "d_loss_real:0.9415612816810608\n",
            "d_loss_fake:0.028349153697490692\n",
            "d_loss_wrong:0.6891518831253052\n",
            "d_loss:0.6501559019088745\n",
            "g_loss:[0.37235066, 0.3699813, 0.0011846817]\n",
            "Batch:68\n",
            "d_loss_real:0.89332115650177\n",
            "d_loss_fake:0.038203854113817215\n",
            "d_loss_wrong:0.6833637952804565\n",
            "d_loss:0.6270524859428406\n",
            "g_loss:[0.40993664, 0.40766853, 0.0011340585]\n",
            "Batch:69\n",
            "d_loss_real:0.9489080905914307\n",
            "d_loss_fake:0.08219058811664581\n",
            "d_loss_wrong:0.9707950949668884\n",
            "d_loss:0.7377004623413086\n",
            "g_loss:[0.6031266, 0.6004783, 0.0013241353]\n",
            "Batch:70\n",
            "d_loss_real:0.9609020352363586\n",
            "d_loss_fake:0.15021345019340515\n",
            "d_loss_wrong:0.5249622464179993\n",
            "d_loss:0.6492449343204498\n",
            "g_loss:[0.7401209, 0.73737955, 0.001370657]\n",
            "Batch:71\n",
            "d_loss_real:1.033413290977478\n",
            "d_loss_fake:0.11361217498779297\n",
            "d_loss_wrong:0.5187985301017761\n",
            "d_loss:0.6748093217611313\n",
            "g_loss:[0.6277983, 0.6250336, 0.001382343]\n",
            "Batch:72\n",
            "d_loss_real:0.9704189896583557\n",
            "d_loss_fake:0.07736753672361374\n",
            "d_loss_wrong:0.593713641166687\n",
            "d_loss:0.6529797911643982\n",
            "g_loss:[0.51289874, 0.5109657, 0.0009665271]\n",
            "Batch:73\n",
            "d_loss_real:0.9034273028373718\n",
            "d_loss_fake:0.05228016898036003\n",
            "d_loss_wrong:0.6021066308021545\n",
            "d_loss:0.6153103560209274\n",
            "g_loss:[0.677316, 0.67546105, 0.0009274787]\n",
            "Batch:74\n",
            "d_loss_real:0.9700412750244141\n",
            "d_loss_fake:0.03848883509635925\n",
            "d_loss_wrong:0.5541487336158752\n",
            "d_loss:0.6331800222396851\n",
            "g_loss:[0.56944406, 0.5671699, 0.0011370645]\n",
            "Batch:75\n",
            "d_loss_real:1.0281533002853394\n",
            "d_loss_fake:0.02232891507446766\n",
            "d_loss_wrong:0.5742694735527039\n",
            "d_loss:0.6632262468338013\n",
            "g_loss:[0.54572064, 0.5429913, 0.0013646913]\n",
            "Batch:76\n",
            "d_loss_real:0.9187688827514648\n",
            "d_loss_fake:0.039283592253923416\n",
            "d_loss_wrong:0.7324129343032837\n",
            "d_loss:0.6523085683584213\n",
            "g_loss:[0.4366564, 0.43428206, 0.0011871548]\n",
            "Batch:77\n",
            "d_loss_real:0.8962936997413635\n",
            "d_loss_fake:0.002702002413570881\n",
            "d_loss_wrong:0.6273394227027893\n",
            "d_loss:0.6056572049856186\n",
            "g_loss:[0.39849716, 0.39589056, 0.0013033077]\n",
            "Batch:78\n",
            "d_loss_real:0.902234673500061\n",
            "d_loss_fake:0.0003849935601465404\n",
            "d_loss_wrong:0.6893185973167419\n",
            "d_loss:0.6235432326793671\n",
            "g_loss:[0.4127009, 0.41030958, 0.0011956554]\n",
            "Batch:79\n",
            "d_loss_real:0.8847664594650269\n",
            "d_loss_fake:0.02539238892495632\n",
            "d_loss_wrong:0.6221962571144104\n",
            "d_loss:0.6042803972959518\n",
            "g_loss:[0.48810232, 0.48557845, 0.0012619322]\n",
            "Batch:80\n",
            "d_loss_real:0.9024055004119873\n",
            "d_loss_fake:8.903078560251743e-05\n",
            "d_loss_wrong:0.7305612564086914\n",
            "d_loss:0.6338653266429901\n",
            "g_loss:[0.40813026, 0.40559232, 0.0012689629]\n",
            "Batch:81\n",
            "d_loss_real:0.8762261271476746\n",
            "d_loss_fake:0.0023070054594427347\n",
            "d_loss_wrong:0.5690376162528992\n",
            "d_loss:0.58094921708107\n",
            "g_loss:[0.44296235, 0.44001788, 0.0014722345]\n",
            "Batch:82\n",
            "d_loss_real:0.9380703568458557\n",
            "d_loss_fake:0.016035161912441254\n",
            "d_loss_wrong:0.5806671380996704\n",
            "d_loss:0.6182107478380203\n",
            "g_loss:[0.4372996, 0.4349294, 0.0011850971]\n",
            "Batch:83\n",
            "d_loss_real:0.8604820966720581\n",
            "d_loss_fake:0.010767465457320213\n",
            "d_loss_wrong:0.6193382740020752\n",
            "d_loss:0.587767481803894\n",
            "g_loss:[0.39186084, 0.38954192, 0.0011594648]\n",
            "Batch:84\n",
            "d_loss_real:0.8258150815963745\n",
            "d_loss_fake:0.00024885544553399086\n",
            "d_loss_wrong:0.6492229104042053\n",
            "d_loss:0.5752754807472229\n",
            "g_loss:[0.38990632, 0.3877219, 0.0010922109]\n",
            "Batch:85\n",
            "d_loss_real:0.8339135646820068\n",
            "d_loss_fake:0.0001753790129441768\n",
            "d_loss_wrong:0.6799899935722351\n",
            "d_loss:0.5869981199502945\n",
            "g_loss:[0.41864458, 0.41636997, 0.0011372971]\n",
            "Batch:86\n",
            "d_loss_real:0.8094496726989746\n",
            "d_loss_fake:0.00018697851919569075\n",
            "d_loss_wrong:0.6864519715309143\n",
            "d_loss:0.576384574174881\n",
            "g_loss:[0.3942372, 0.39229357, 0.0009718023]\n",
            "Batch:87\n",
            "d_loss_real:0.8538038730621338\n",
            "d_loss_fake:0.0006792126223444939\n",
            "d_loss_wrong:0.6250796914100647\n",
            "d_loss:0.583341658115387\n",
            "g_loss:[0.3665559, 0.36418703, 0.0011844281]\n",
            "Batch:88\n",
            "d_loss_real:0.8993316292762756\n",
            "d_loss_fake:0.00024661709903739393\n",
            "d_loss_wrong:0.726485013961792\n",
            "d_loss:0.631348729133606\n",
            "g_loss:[0.36402854, 0.36136436, 0.0013320954]\n",
            "Batch:89\n",
            "d_loss_real:0.8546842336654663\n",
            "d_loss_fake:0.003017944283783436\n",
            "d_loss_wrong:0.7337679266929626\n",
            "d_loss:0.6115385890007019\n",
            "g_loss:[0.38150293, 0.37855598, 0.0014734706]\n",
            "Batch:90\n",
            "d_loss_real:0.8253822326660156\n",
            "d_loss_fake:0.0050521595403552055\n",
            "d_loss_wrong:0.6459260582923889\n",
            "d_loss:0.5754356682300568\n",
            "g_loss:[0.3903663, 0.38758773, 0.0013892814]\n",
            "Batch:91\n",
            "d_loss_real:0.822522759437561\n",
            "d_loss_fake:0.0007754216785542667\n",
            "d_loss_wrong:0.7454562783241272\n",
            "d_loss:0.5978192985057831\n",
            "g_loss:[0.3761322, 0.3735605, 0.0012858456]\n",
            "Batch:92\n",
            "d_loss_real:0.9113709926605225\n",
            "d_loss_fake:0.0003512724069878459\n",
            "d_loss_wrong:0.6320604681968689\n",
            "d_loss:0.6137884259223938\n",
            "g_loss:[0.40971312, 0.40555823, 0.0020774426]\n",
            "Batch:93\n",
            "d_loss_real:0.9209945201873779\n",
            "d_loss_fake:0.0028980555944144726\n",
            "d_loss_wrong:0.6197547912597656\n",
            "d_loss:0.6161604672670364\n",
            "g_loss:[0.38087684, 0.376904, 0.001986413]\n",
            "Batch:94\n",
            "d_loss_real:0.8648194074630737\n",
            "d_loss_fake:0.003068513935431838\n",
            "d_loss_wrong:0.6667554378509521\n",
            "d_loss:0.5998656898736954\n",
            "g_loss:[0.38817284, 0.38567698, 0.0012479259]\n",
            "Batch:95\n",
            "d_loss_real:0.8240326046943665\n",
            "d_loss_fake:0.0027429598849266768\n",
            "d_loss_wrong:0.6926935315132141\n",
            "d_loss:0.5858754217624664\n",
            "g_loss:[0.40186778, 0.39953882, 0.0011644859]\n",
            "Batch:96\n",
            "d_loss_real:0.7940731644630432\n",
            "d_loss_fake:0.0017609247006475925\n",
            "d_loss_wrong:0.7177863717079163\n",
            "d_loss:0.5769234001636505\n",
            "g_loss:[0.4559097, 0.45326406, 0.0013228275]\n",
            "Batch:97\n",
            "d_loss_real:0.8502131104469299\n",
            "d_loss_fake:0.0001790921960491687\n",
            "d_loss_wrong:0.6598291993141174\n",
            "d_loss:0.5901086330413818\n",
            "g_loss:[0.4267393, 0.42416984, 0.0012847376]\n",
            "Batch:98\n",
            "d_loss_real:0.8407542705535889\n",
            "d_loss_fake:0.0028605302795767784\n",
            "d_loss_wrong:0.6862256526947021\n",
            "d_loss:0.5926486849784851\n",
            "g_loss:[0.41625208, 0.41359258, 0.0013297442]\n",
            "Batch:99\n",
            "d_loss_real:0.9079124927520752\n",
            "d_loss_fake:0.0006523804040625691\n",
            "d_loss_wrong:0.5864548683166504\n",
            "d_loss:0.6007330566644669\n",
            "g_loss:[0.38186738, 0.3790422, 0.0014125924]\n",
            "Batch:100\n",
            "d_loss_real:0.9178961515426636\n",
            "d_loss_fake:0.005334480665624142\n",
            "d_loss_wrong:0.5643583536148071\n",
            "d_loss:0.6013712882995605\n",
            "g_loss:[0.362759, 0.36029384, 0.0012325814]\n",
            "Batch:101\n",
            "d_loss_real:0.8528013825416565\n",
            "d_loss_fake:0.00035162840504199266\n",
            "d_loss_wrong:0.6522262692451477\n",
            "d_loss:0.5895451605319977\n",
            "g_loss:[0.36205027, 0.35974184, 0.0011542079]\n",
            "Batch:102\n",
            "d_loss_real:0.8759522438049316\n",
            "d_loss_fake:0.0005863617407158017\n",
            "d_loss_wrong:0.619827151298523\n",
            "d_loss:0.5930795073509216\n",
            "g_loss:[0.36443993, 0.3621783, 0.0011308226]\n",
            "Batch:103\n",
            "d_loss_real:0.8485674858093262\n",
            "d_loss_fake:0.0012941797031089664\n",
            "d_loss_wrong:0.6633986830711365\n",
            "d_loss:0.5904569625854492\n",
            "g_loss:[0.43084323, 0.4285075, 0.0011678669]\n",
            "Batch:104\n",
            "d_loss_real:0.9083828926086426\n",
            "d_loss_fake:0.00249990401789546\n",
            "d_loss_wrong:0.6148098111152649\n",
            "d_loss:0.6085188686847687\n",
            "g_loss:[0.3480277, 0.34578037, 0.0011236602]\n",
            "Batch:105\n",
            "d_loss_real:0.8405123353004456\n",
            "d_loss_fake:0.01648777723312378\n",
            "d_loss_wrong:0.6313502788543701\n",
            "d_loss:0.5822156816720963\n",
            "g_loss:[0.3887861, 0.38692367, 0.0009312112]\n",
            "Batch:106\n",
            "d_loss_real:0.8298441171646118\n",
            "d_loss_fake:0.00029188790358603\n",
            "d_loss_wrong:0.6905844807624817\n",
            "d_loss:0.5876411497592926\n",
            "g_loss:[0.37442157, 0.3723455, 0.0010380296]\n",
            "Batch:107\n",
            "d_loss_real:0.831433892250061\n",
            "d_loss_fake:0.0004823093768209219\n",
            "d_loss_wrong:0.655431866645813\n",
            "d_loss:0.5796954929828644\n",
            "g_loss:[0.3726389, 0.37035084, 0.0011440307]\n",
            "Batch:108\n",
            "d_loss_real:0.8739464282989502\n",
            "d_loss_fake:0.00046352334902621806\n",
            "d_loss_wrong:0.6337796449661255\n",
            "d_loss:0.595534011721611\n",
            "g_loss:[0.3745945, 0.37261325, 0.0009906276]\n",
            "Batch:109\n",
            "d_loss_real:0.8252756595611572\n",
            "d_loss_fake:0.00013649114407598972\n",
            "d_loss_wrong:0.6746225357055664\n",
            "d_loss:0.5813275873661041\n",
            "g_loss:[0.4103929, 0.40817034, 0.0011112904]\n",
            "Batch:110\n",
            "d_loss_real:0.8305331468582153\n",
            "d_loss_fake:0.0007675212109461427\n",
            "d_loss_wrong:0.6504696011543274\n",
            "d_loss:0.5780758559703827\n",
            "g_loss:[0.38121736, 0.3787525, 0.0012324357]\n",
            "Batch:111\n",
            "d_loss_real:0.8820517063140869\n",
            "d_loss_fake:0.00016072526341304183\n",
            "d_loss_wrong:0.6407145261764526\n",
            "d_loss:0.6012446731328964\n",
            "g_loss:[0.34540546, 0.34287694, 0.0012642537]\n",
            "Batch:112\n",
            "d_loss_real:0.8736491203308105\n",
            "d_loss_fake:0.0007632461492903531\n",
            "d_loss_wrong:0.787437915802002\n",
            "d_loss:0.633874848484993\n",
            "g_loss:[0.3605121, 0.35795933, 0.0012763934]\n",
            "Batch:113\n",
            "d_loss_real:0.8413049578666687\n",
            "d_loss_fake:0.009260914288461208\n",
            "d_loss_wrong:0.5967051386833191\n",
            "d_loss:0.5721439868211746\n",
            "g_loss:[0.36332628, 0.36050874, 0.0014087671]\n",
            "Batch:114\n",
            "d_loss_real:0.8779455423355103\n",
            "d_loss_fake:0.00019560895452741534\n",
            "d_loss_wrong:0.6066623330116272\n",
            "d_loss:0.5906872600317001\n",
            "g_loss:[0.39384764, 0.39142573, 0.0012109593]\n",
            "Batch:115\n",
            "d_loss_real:0.8300105333328247\n",
            "d_loss_fake:0.0004723159072455019\n",
            "d_loss_wrong:0.6412909626960754\n",
            "d_loss:0.5754460841417313\n",
            "g_loss:[0.35103497, 0.34846148, 0.001286739]\n",
            "Batch:116\n",
            "d_loss_real:0.8728489279747009\n",
            "d_loss_fake:0.002801865804940462\n",
            "d_loss_wrong:0.7295954823493958\n",
            "d_loss:0.6195238083600998\n",
            "g_loss:[0.40163267, 0.39927763, 0.0011775129]\n",
            "Batch:117\n",
            "d_loss_real:0.798894464969635\n",
            "d_loss_fake:0.002314083743840456\n",
            "d_loss_wrong:0.666975736618042\n",
            "d_loss:0.5667696893215179\n",
            "g_loss:[0.48187003, 0.47966698, 0.0011015178]\n",
            "Batch:118\n",
            "d_loss_real:0.8300437331199646\n",
            "d_loss_fake:0.07464920729398727\n",
            "d_loss_wrong:0.57631516456604\n",
            "d_loss:0.5777629613876343\n",
            "g_loss:[0.8974725, 0.8949997, 0.0012364106]\n",
            "Batch:119\n",
            "d_loss_real:0.9783416986465454\n",
            "d_loss_fake:0.0004963562823832035\n",
            "d_loss_wrong:0.62807697057724\n",
            "d_loss:0.6463141739368439\n",
            "g_loss:[0.85565895, 0.85359323, 0.001032846]\n",
            "Batch:120\n",
            "d_loss_real:0.8747594356536865\n",
            "d_loss_fake:0.0005764120141975582\n",
            "d_loss_wrong:0.6724818348884583\n",
            "d_loss:0.6056442856788635\n",
            "g_loss:[0.5571086, 0.5545807, 0.0012639549]\n",
            "Batch:121\n",
            "d_loss_real:0.8664607405662537\n",
            "d_loss_fake:0.0013915313174948096\n",
            "d_loss_wrong:0.6254938244819641\n",
            "d_loss:0.5899517089128494\n",
            "g_loss:[0.6199243, 0.61738735, 0.0012684728]\n",
            "Batch:122\n",
            "d_loss_real:0.8515298366546631\n",
            "d_loss_fake:0.0026641699951142073\n",
            "d_loss_wrong:0.6644234657287598\n",
            "d_loss:0.5925368219614029\n",
            "g_loss:[0.4964102, 0.49370039, 0.0013548958]\n",
            "Batch:123\n",
            "d_loss_real:0.9365801811218262\n",
            "d_loss_fake:0.01857879012823105\n",
            "d_loss_wrong:0.7539259791374207\n",
            "d_loss:0.6614162772893906\n",
            "g_loss:[0.52366835, 0.5216508, 0.0010087776]\n",
            "Batch:124\n",
            "d_loss_real:0.8074291944503784\n",
            "d_loss_fake:0.016395512968301773\n",
            "d_loss_wrong:0.6116647720336914\n",
            "d_loss:0.5607296675443649\n",
            "g_loss:[0.6238177, 0.6217225, 0.0010475783]\n",
            "Batch:125\n",
            "d_loss_real:0.8523378968238831\n",
            "d_loss_fake:0.002739082323387265\n",
            "d_loss_wrong:0.6100649237632751\n",
            "d_loss:0.5793699473142624\n",
            "g_loss:[0.5302366, 0.52776325, 0.0012366873]\n",
            "Batch:126\n",
            "d_loss_real:0.8116241693496704\n",
            "d_loss_fake:0.00048072528443299234\n",
            "d_loss_wrong:0.6625894904136658\n",
            "d_loss:0.57157963514328\n",
            "g_loss:[0.49762613, 0.4949907, 0.0013177162]\n",
            "Batch:127\n",
            "d_loss_real:0.8238496780395508\n",
            "d_loss_fake:0.0028820063453167677\n",
            "d_loss_wrong:0.6310906410217285\n",
            "d_loss:0.5704180002212524\n",
            "g_loss:[0.5272704, 0.52504224, 0.0011140826]\n",
            "Batch:128\n",
            "d_loss_real:0.863868772983551\n",
            "d_loss_fake:0.0007620465476065874\n",
            "d_loss_wrong:0.6540065407752991\n",
            "d_loss:0.5956265330314636\n",
            "g_loss:[0.4809145, 0.47815987, 0.0013773108]\n",
            "Batch:129\n",
            "d_loss_real:0.8288211226463318\n",
            "d_loss_fake:0.0011259402381256223\n",
            "d_loss_wrong:0.6401575803756714\n",
            "d_loss:0.5747314393520355\n",
            "g_loss:[0.43338478, 0.4307372, 0.0013237963]\n",
            "Batch:130\n",
            "d_loss_real:0.840557873249054\n",
            "d_loss_fake:0.001236383686773479\n",
            "d_loss_wrong:0.6902759075164795\n",
            "d_loss:0.5931570082902908\n",
            "g_loss:[0.5774619, 0.5754752, 0.0009933494]\n",
            "Batch:131\n",
            "d_loss_real:0.8077752590179443\n",
            "d_loss_fake:0.009324168786406517\n",
            "d_loss_wrong:0.683077871799469\n",
            "d_loss:0.5769881457090378\n",
            "g_loss:[0.7192822, 0.71687734, 0.001202432]\n",
            "Batch:132\n",
            "d_loss_real:0.8132671117782593\n",
            "d_loss_fake:0.0005465972935780883\n",
            "d_loss_wrong:0.6440907120704651\n",
            "d_loss:0.5677928775548935\n",
            "g_loss:[0.5337991, 0.53137064, 0.0012142279]\n",
            "Batch:133\n",
            "d_loss_real:0.8290916681289673\n",
            "d_loss_fake:0.0011007727589458227\n",
            "d_loss_wrong:0.6509736776351929\n",
            "d_loss:0.5775644481182098\n",
            "g_loss:[0.50541914, 0.5033766, 0.0010212634]\n",
            "Batch:134\n",
            "d_loss_real:0.8399556279182434\n",
            "d_loss_fake:0.002485906705260277\n",
            "d_loss_wrong:0.6694532632827759\n",
            "d_loss:0.5879626125097275\n",
            "g_loss:[0.49946082, 0.4971629, 0.0011489603]\n",
            "Batch:135\n",
            "d_loss_real:0.8654547929763794\n",
            "d_loss_fake:0.0018538973527029157\n",
            "d_loss_wrong:0.6574999094009399\n",
            "d_loss:0.5975658446550369\n",
            "g_loss:[0.40384972, 0.4016648, 0.0010924633]\n",
            "Batch:136\n",
            "d_loss_real:0.842144250869751\n",
            "d_loss_fake:0.0044287461787462234\n",
            "d_loss_wrong:0.615151584148407\n",
            "d_loss:0.5759672075510025\n",
            "g_loss:[0.45271733, 0.45070893, 0.0010041993]\n",
            "Batch:137\n",
            "d_loss_real:0.843971312046051\n",
            "d_loss_fake:0.0008600709843449295\n",
            "d_loss_wrong:0.6404275894165039\n",
            "d_loss:0.5823075771331787\n",
            "g_loss:[0.42706516, 0.42508835, 0.0009884067]\n",
            "Batch:138\n",
            "d_loss_real:0.8493638634681702\n",
            "d_loss_fake:0.0066064647398889065\n",
            "d_loss_wrong:0.6149770021438599\n",
            "d_loss:0.5800777971744537\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "g_loss:[0.42543402, 0.42295492, 0.0012395543]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "========================================\n",
            "Epoch is: 9\n",
            "Number of batches 138\n",
            "Batch:1\n",
            "d_loss_real:0.8606074452400208\n",
            "d_loss_fake:0.000966009683907032\n",
            "d_loss_wrong:0.6897499561309814\n",
            "d_loss:0.6029827147722244\n",
            "g_loss:[0.41825205, 0.41616917, 0.0010414469]\n",
            "Batch:2\n",
            "d_loss_real:0.8223055601119995\n",
            "d_loss_fake:0.0014447555877268314\n",
            "d_loss_wrong:0.6688365340232849\n",
            "d_loss:0.5787231028079987\n",
            "g_loss:[0.4983921, 0.49614394, 0.0011240825]\n",
            "Batch:3\n",
            "d_loss_real:0.855417013168335\n",
            "d_loss_fake:0.010417892597615719\n",
            "d_loss_wrong:0.6532155871391296\n",
            "d_loss:0.5936168730258942\n",
            "g_loss:[0.74763834, 0.7456321, 0.0010031263]\n",
            "Batch:4\n",
            "d_loss_real:0.8342103362083435\n",
            "d_loss_fake:0.0023688545916229486\n",
            "d_loss_wrong:0.6641692519187927\n",
            "d_loss:0.583739697933197\n",
            "g_loss:[0.7648098, 0.76217616, 0.0013168225]\n",
            "Batch:5\n",
            "d_loss_real:0.8185745477676392\n",
            "d_loss_fake:0.0011646095663309097\n",
            "d_loss_wrong:0.7150532007217407\n",
            "d_loss:0.5883417278528214\n",
            "g_loss:[0.67891335, 0.6761608, 0.0013762668]\n",
            "Batch:6\n",
            "d_loss_real:0.8197967410087585\n",
            "d_loss_fake:0.0024476442486047745\n",
            "d_loss_wrong:0.7389329075813293\n",
            "d_loss:0.595243513584137\n",
            "g_loss:[0.7793267, 0.77650905, 0.00140882]\n",
            "Batch:7\n",
            "d_loss_real:0.8294596672058105\n",
            "d_loss_fake:0.0013229341711848974\n",
            "d_loss_wrong:0.6388740539550781\n",
            "d_loss:0.5747790783643723\n",
            "g_loss:[0.71397656, 0.71164167, 0.0011674493]\n",
            "Batch:8\n",
            "d_loss_real:0.8718208074569702\n",
            "d_loss_fake:0.024488165974617004\n",
            "d_loss_wrong:0.6103478074073792\n",
            "d_loss:0.5946193933486938\n",
            "g_loss:[0.8752177, 0.8722827, 0.0014675006]\n",
            "Batch:9\n",
            "d_loss_real:0.9224810600280762\n",
            "d_loss_fake:0.007983418181538582\n",
            "d_loss_wrong:0.6301978230476379\n",
            "d_loss:0.6207858473062515\n",
            "g_loss:[0.80160266, 0.79773575, 0.0019334559]\n",
            "Batch:10\n",
            "d_loss_real:0.8595874309539795\n",
            "d_loss_fake:0.0017622841987758875\n",
            "d_loss_wrong:0.6219834089279175\n",
            "d_loss:0.5857301354408264\n",
            "g_loss:[0.7853396, 0.78195417, 0.0016927103]\n",
            "Batch:11\n",
            "d_loss_real:0.9364812970161438\n",
            "d_loss_fake:0.01120544783771038\n",
            "d_loss_wrong:0.6661855578422546\n",
            "d_loss:0.6375883966684341\n",
            "g_loss:[0.6989993, 0.69656193, 0.001218683]\n",
            "Batch:12\n",
            "d_loss_real:0.8287382125854492\n",
            "d_loss_fake:0.0011565489694476128\n",
            "d_loss_wrong:0.6422309279441833\n",
            "d_loss:0.5752159804105759\n",
            "g_loss:[0.6740674, 0.67181116, 0.0011281123]\n",
            "Batch:13\n",
            "d_loss_real:0.8220214247703552\n",
            "d_loss_fake:0.003747045062482357\n",
            "d_loss_wrong:0.6424246430397034\n",
            "d_loss:0.5725536346435547\n",
            "g_loss:[0.6973478, 0.6951199, 0.0011139427]\n",
            "Batch:14\n",
            "d_loss_real:0.8283933401107788\n",
            "d_loss_fake:0.03510912135243416\n",
            "d_loss_wrong:0.6130803823471069\n",
            "d_loss:0.5762440413236618\n",
            "g_loss:[0.74653536, 0.7446124, 0.0009614945]\n",
            "Batch:15\n",
            "d_loss_real:0.8980000019073486\n",
            "d_loss_fake:0.0009126241784542799\n",
            "d_loss_wrong:0.6663362383842468\n",
            "d_loss:0.615812212228775\n",
            "g_loss:[0.8108469, 0.80817914, 0.0013339038]\n",
            "Batch:16\n",
            "d_loss_real:0.8323768377304077\n",
            "d_loss_fake:0.005385351367294788\n",
            "d_loss_wrong:0.6890807747840881\n",
            "d_loss:0.5898049473762512\n",
            "g_loss:[0.7171413, 0.7146392, 0.001251044]\n",
            "Batch:17\n",
            "d_loss_real:0.8308392763137817\n",
            "d_loss_fake:0.018457649275660515\n",
            "d_loss_wrong:0.7293998003005981\n",
            "d_loss:0.6023840010166168\n",
            "g_loss:[0.7854177, 0.7826322, 0.0013927466]\n",
            "Batch:18\n",
            "d_loss_real:0.8594221472740173\n",
            "d_loss_fake:0.0030255704186856747\n",
            "d_loss_wrong:0.6594144105911255\n",
            "d_loss:0.5953210741281509\n",
            "g_loss:[0.7431092, 0.7410742, 0.001017516]\n",
            "Batch:19\n",
            "d_loss_real:0.8696651458740234\n",
            "d_loss_fake:0.004707766696810722\n",
            "d_loss_wrong:0.6249173879623413\n",
            "d_loss:0.5922388583421707\n",
            "g_loss:[0.71032363, 0.70838094, 0.00097133475]\n",
            "Batch:20\n",
            "d_loss_real:0.8613784313201904\n",
            "d_loss_fake:0.0007549996371380985\n",
            "d_loss_wrong:0.6540004014968872\n",
            "d_loss:0.5943780690431595\n",
            "g_loss:[0.8475584, 0.8455474, 0.0010055022]\n",
            "Batch:21\n",
            "d_loss_real:0.8638968467712402\n",
            "d_loss_fake:0.0007853226270526648\n",
            "d_loss_wrong:0.6060854196548462\n",
            "d_loss:0.5836661159992218\n",
            "g_loss:[0.6544077, 0.65255535, 0.0009261538]\n",
            "Batch:22\n",
            "d_loss_real:0.8411683440208435\n",
            "d_loss_fake:0.0024832957424223423\n",
            "d_loss_wrong:0.6879668831825256\n",
            "d_loss:0.5931967198848724\n",
            "g_loss:[0.6479239, 0.64637786, 0.0007730139]\n",
            "Batch:23\n",
            "d_loss_real:0.8286949396133423\n",
            "d_loss_fake:0.0009821676649153233\n",
            "d_loss_wrong:0.7273301482200623\n",
            "d_loss:0.5964255481958389\n",
            "g_loss:[0.5837476, 0.5818955, 0.000926083]\n",
            "Batch:24\n",
            "d_loss_real:0.8285885453224182\n",
            "d_loss_fake:0.001439318642951548\n",
            "d_loss_wrong:0.6301396489143372\n",
            "d_loss:0.5721890181303024\n",
            "g_loss:[0.53582704, 0.53355396, 0.0011365376]\n",
            "Batch:25\n",
            "d_loss_real:0.8683775067329407\n",
            "d_loss_fake:0.0005166978808119893\n",
            "d_loss_wrong:0.728404700756073\n",
            "d_loss:0.616419106721878\n",
            "g_loss:[0.5231566, 0.5210421, 0.001057249]\n",
            "Batch:26\n",
            "d_loss_real:0.8384697437286377\n",
            "d_loss_fake:0.002189002465456724\n",
            "d_loss_wrong:0.6410654187202454\n",
            "d_loss:0.5800484716892242\n",
            "g_loss:[0.5368007, 0.5350316, 0.0008845278]\n",
            "Batch:27\n",
            "d_loss_real:0.8313267230987549\n",
            "d_loss_fake:0.0007890624110586941\n",
            "d_loss_wrong:0.6862629055976868\n",
            "d_loss:0.5874263495206833\n",
            "g_loss:[0.523296, 0.52146876, 0.00091362913]\n",
            "Batch:28\n",
            "d_loss_real:0.845244288444519\n",
            "d_loss_fake:0.001321050338447094\n",
            "d_loss_wrong:0.6096816658973694\n",
            "d_loss:0.5753728300333023\n",
            "g_loss:[0.4606641, 0.45772606, 0.0014690086]\n",
            "Batch:29\n",
            "d_loss_real:0.8550860285758972\n",
            "d_loss_fake:0.004158596508204937\n",
            "d_loss_wrong:0.6349900960922241\n",
            "d_loss:0.5873301923274994\n",
            "g_loss:[0.40565786, 0.4031946, 0.0012316289]\n",
            "Batch:30\n",
            "d_loss_real:0.8668940663337708\n",
            "d_loss_fake:0.0016848320374265313\n",
            "d_loss_wrong:0.7273849844932556\n",
            "d_loss:0.6157144904136658\n",
            "g_loss:[0.42679214, 0.4246266, 0.0010827817]\n",
            "Batch:31\n",
            "d_loss_real:0.8136187791824341\n",
            "d_loss_fake:0.00874271709471941\n",
            "d_loss_wrong:0.6596465110778809\n",
            "d_loss:0.5739066898822784\n",
            "g_loss:[0.49491683, 0.49284917, 0.0010338281]\n",
            "Batch:32\n",
            "d_loss_real:0.8845203518867493\n",
            "d_loss_fake:0.0006555475993081927\n",
            "d_loss_wrong:0.6242737770080566\n",
            "d_loss:0.5984925031661987\n",
            "g_loss:[0.44771737, 0.44513413, 0.001291614]\n",
            "Batch:33\n",
            "d_loss_real:0.8239025473594666\n",
            "d_loss_fake:0.0013404323253780603\n",
            "d_loss_wrong:0.6112825870513916\n",
            "d_loss:0.5651070326566696\n",
            "g_loss:[0.41233766, 0.40985435, 0.001241659]\n",
            "Batch:34\n",
            "d_loss_real:0.8636183142662048\n",
            "d_loss_fake:0.004843343514949083\n",
            "d_loss_wrong:0.6117823719978333\n",
            "d_loss:0.5859655886888504\n",
            "g_loss:[0.44671738, 0.4444772, 0.0011200947]\n",
            "Batch:35\n",
            "d_loss_real:0.8406394720077515\n",
            "d_loss_fake:0.001683290465734899\n",
            "d_loss_wrong:0.6339809894561768\n",
            "d_loss:0.5792358070611954\n",
            "g_loss:[0.45451978, 0.4525303, 0.0009947363]\n",
            "Batch:36\n",
            "d_loss_real:0.8622157573699951\n",
            "d_loss_fake:0.0015100317541509867\n",
            "d_loss_wrong:0.6570002436637878\n",
            "d_loss:0.5957354456186295\n",
            "g_loss:[0.38486102, 0.3825223, 0.0011693607]\n",
            "Batch:37\n",
            "d_loss_real:0.8372782468795776\n",
            "d_loss_fake:0.0010350958909839392\n",
            "d_loss_wrong:0.6377586722373962\n",
            "d_loss:0.5783375650644302\n",
            "g_loss:[0.39435562, 0.39197183, 0.0011919043]\n",
            "Batch:38\n",
            "d_loss_real:0.8408730030059814\n",
            "d_loss_fake:0.0018002645811066031\n",
            "d_loss_wrong:0.6935991644859314\n",
            "d_loss:0.5942863523960114\n",
            "g_loss:[0.3767945, 0.37477267, 0.0010109042]\n",
            "Batch:39\n",
            "d_loss_real:0.8323351144790649\n",
            "d_loss_fake:0.0013481620699167252\n",
            "d_loss_wrong:0.6514388918876648\n",
            "d_loss:0.5793643146753311\n",
            "g_loss:[0.38181424, 0.37960428, 0.0011049868]\n",
            "Batch:40\n",
            "d_loss_real:0.8260352611541748\n",
            "d_loss_fake:0.002280361019074917\n",
            "d_loss_wrong:0.6850957274436951\n",
            "d_loss:0.5848616510629654\n",
            "g_loss:[0.41553372, 0.41358358, 0.00097507035]\n",
            "Batch:41\n",
            "d_loss_real:0.8133071660995483\n",
            "d_loss_fake:0.001616790657863021\n",
            "d_loss_wrong:0.6427477598190308\n",
            "d_loss:0.567744717001915\n",
            "g_loss:[0.36000925, 0.35777348, 0.0011178912]\n",
            "Batch:42\n",
            "d_loss_real:0.8231699466705322\n",
            "d_loss_fake:0.00030870659975335\n",
            "d_loss_wrong:0.6606612205505371\n",
            "d_loss:0.5768274515867233\n",
            "g_loss:[0.35367844, 0.35138947, 0.0011444906]\n",
            "Batch:43\n",
            "d_loss_real:0.8633584976196289\n",
            "d_loss_fake:0.02052379585802555\n",
            "d_loss_wrong:0.6033841967582703\n",
            "d_loss:0.587656244635582\n",
            "g_loss:[0.5891768, 0.5868089, 0.0011839257]\n",
            "Batch:44\n",
            "d_loss_real:0.8474549651145935\n",
            "d_loss_fake:0.0006579987239092588\n",
            "d_loss_wrong:0.6018449068069458\n",
            "d_loss:0.5743532031774521\n",
            "g_loss:[0.61372817, 0.611098, 0.0013150966]\n",
            "Batch:45\n",
            "d_loss_real:0.8695045709609985\n",
            "d_loss_fake:0.0009792190976440907\n",
            "d_loss_wrong:0.5965282320976257\n",
            "d_loss:0.5841291546821594\n",
            "g_loss:[0.4389985, 0.43605232, 0.0014730782]\n",
            "Batch:46\n",
            "d_loss_real:0.8120013475418091\n",
            "d_loss_fake:0.001809569075703621\n",
            "d_loss_wrong:0.666881263256073\n",
            "d_loss:0.573173388838768\n",
            "g_loss:[0.39857775, 0.39623868, 0.001169538]\n",
            "Batch:47\n",
            "d_loss_real:0.807996392250061\n",
            "d_loss_fake:0.0023437724448740482\n",
            "d_loss_wrong:0.644282877445221\n",
            "d_loss:0.5656548589468002\n",
            "g_loss:[0.44294485, 0.4404379, 0.0012534776]\n",
            "Batch:48\n",
            "d_loss_real:0.8447713851928711\n",
            "d_loss_fake:0.004197412170469761\n",
            "d_loss_wrong:0.6496574282646179\n",
            "d_loss:0.585849404335022\n",
            "g_loss:[0.451189, 0.4487493, 0.0012198567]\n",
            "Batch:49\n",
            "d_loss_real:0.8307676315307617\n",
            "d_loss_fake:0.008975562639534473\n",
            "d_loss_wrong:0.6137136816978455\n",
            "d_loss:0.5710561275482178\n",
            "g_loss:[0.46408978, 0.46150404, 0.0012928736]\n",
            "Batch:50\n",
            "d_loss_real:0.8815411329269409\n",
            "d_loss_fake:0.00857418030500412\n",
            "d_loss_wrong:0.6492956280708313\n",
            "d_loss:0.6052380204200745\n",
            "g_loss:[0.51880246, 0.5170158, 0.00089333707]\n",
            "Batch:51\n",
            "d_loss_real:0.8267850875854492\n",
            "d_loss_fake:0.010193927213549614\n",
            "d_loss_wrong:0.6902492046356201\n",
            "d_loss:0.5885033309459686\n",
            "g_loss:[0.56547475, 0.5630951, 0.0011898184]\n",
            "Batch:52\n",
            "d_loss_real:0.8150610327720642\n",
            "d_loss_fake:0.001244356157258153\n",
            "d_loss_wrong:0.7055447697639465\n",
            "d_loss:0.5842278003692627\n",
            "g_loss:[0.4470732, 0.44548044, 0.0007963821]\n",
            "Batch:53\n",
            "d_loss_real:0.810104489326477\n",
            "d_loss_fake:0.0010307934135198593\n",
            "d_loss_wrong:0.6117688417434692\n",
            "d_loss:0.5582521557807922\n",
            "g_loss:[0.42850566, 0.4262923, 0.0011066868]\n",
            "Batch:54\n",
            "d_loss_real:0.8542580008506775\n",
            "d_loss_fake:0.0007125347037799656\n",
            "d_loss_wrong:0.6517419815063477\n",
            "d_loss:0.5902426242828369\n",
            "g_loss:[0.36729264, 0.36505285, 0.0011198951]\n",
            "Batch:55\n",
            "d_loss_real:0.8271389007568359\n",
            "d_loss_fake:0.005949046462774277\n",
            "d_loss_wrong:0.6362654566764832\n",
            "d_loss:0.5741230696439743\n",
            "g_loss:[0.38826576, 0.38610685, 0.0010794494]\n",
            "Batch:56\n",
            "d_loss_real:0.8297886848449707\n",
            "d_loss_fake:0.006636613979935646\n",
            "d_loss_wrong:0.6365829110145569\n",
            "d_loss:0.5756992250680923\n",
            "g_loss:[0.39375696, 0.3911476, 0.001304669]\n",
            "Batch:57\n",
            "d_loss_real:0.850292980670929\n",
            "d_loss_fake:0.0036367331631481647\n",
            "d_loss_wrong:0.6352238059043884\n",
            "d_loss:0.584861621260643\n",
            "g_loss:[0.40698883, 0.40438125, 0.0013037917]\n",
            "Batch:58\n",
            "d_loss_real:0.8360655307769775\n",
            "d_loss_fake:0.0038096075877547264\n",
            "d_loss_wrong:0.639767587184906\n",
            "d_loss:0.57892706990242\n",
            "g_loss:[0.3891644, 0.3866179, 0.0012732442]\n",
            "Batch:59\n",
            "d_loss_real:0.8418333530426025\n",
            "d_loss_fake:0.008731303736567497\n",
            "d_loss_wrong:0.683386504650116\n",
            "d_loss:0.5939461290836334\n",
            "g_loss:[0.5242306, 0.5220609, 0.0010848717]\n",
            "Batch:60\n",
            "d_loss_real:0.8226672410964966\n",
            "d_loss_fake:0.0008512099157087505\n",
            "d_loss_wrong:0.6314027309417725\n",
            "d_loss:0.5693971067667007\n",
            "g_loss:[0.58701265, 0.5849998, 0.0010064257]\n",
            "Batch:61\n",
            "d_loss_real:0.8529413938522339\n",
            "d_loss_fake:0.0034981751814484596\n",
            "d_loss_wrong:0.6415197253227234\n",
            "d_loss:0.5877251774072647\n",
            "g_loss:[0.541919, 0.5401801, 0.00086943933]\n",
            "Batch:62\n",
            "d_loss_real:0.8595870733261108\n",
            "d_loss_fake:0.01909930445253849\n",
            "d_loss_wrong:0.5961808562278748\n",
            "d_loss:0.5836135745048523\n",
            "g_loss:[0.7464195, 0.7447497, 0.0008348818]\n",
            "Batch:63\n",
            "d_loss_real:0.8567702770233154\n",
            "d_loss_fake:0.0006856503314338624\n",
            "d_loss_wrong:0.6149647831916809\n",
            "d_loss:0.5822977423667908\n",
            "g_loss:[0.63866544, 0.6366395, 0.0010129691]\n",
            "Batch:64\n",
            "d_loss_real:0.8440362215042114\n",
            "d_loss_fake:0.0010649441974237561\n",
            "d_loss_wrong:0.6073206067085266\n",
            "d_loss:0.5741145014762878\n",
            "g_loss:[0.57300013, 0.5709925, 0.001003807]\n",
            "Batch:65\n",
            "d_loss_real:0.848726749420166\n",
            "d_loss_fake:0.0006560254842042923\n",
            "d_loss_wrong:0.6573539972305298\n",
            "d_loss:0.5888658761978149\n",
            "g_loss:[0.69880205, 0.69654536, 0.0011283384]\n",
            "Batch:66\n",
            "d_loss_real:0.8202221393585205\n",
            "d_loss_fake:0.0009439352434128523\n",
            "d_loss_wrong:0.6578554511070251\n",
            "d_loss:0.5748109221458435\n",
            "g_loss:[0.5695778, 0.56777453, 0.00090165046]\n",
            "Batch:67\n",
            "d_loss_real:0.8545594811439514\n",
            "d_loss_fake:0.0014438610523939133\n",
            "d_loss_wrong:0.6297512650489807\n",
            "d_loss:0.5850785225629807\n",
            "g_loss:[0.5256825, 0.52393895, 0.0008717892]\n",
            "Batch:68\n",
            "d_loss_real:0.8219059705734253\n",
            "d_loss_fake:0.005953710060566664\n",
            "d_loss_wrong:0.6679765582084656\n",
            "d_loss:0.5794355571269989\n",
            "g_loss:[0.57389635, 0.5720837, 0.0009063327]\n",
            "Batch:69\n",
            "d_loss_real:0.8322551250457764\n",
            "d_loss_fake:0.011035490781068802\n",
            "d_loss_wrong:0.6935805082321167\n",
            "d_loss:0.5922815650701523\n",
            "g_loss:[0.7563253, 0.7542597, 0.0010328037]\n",
            "Batch:70\n",
            "d_loss_real:0.8153063058853149\n",
            "d_loss_fake:0.0016768150962889194\n",
            "d_loss_wrong:0.6500453352928162\n",
            "d_loss:0.5705836862325668\n",
            "g_loss:[0.7111313, 0.7089691, 0.0010810758]\n",
            "Batch:71\n",
            "d_loss_real:0.8319727182388306\n",
            "d_loss_fake:0.0008799352217465639\n",
            "d_loss_wrong:0.6176722049713135\n",
            "d_loss:0.5706243962049484\n",
            "g_loss:[0.67450553, 0.67249346, 0.0010060233]\n",
            "Batch:72\n",
            "d_loss_real:0.8369319438934326\n",
            "d_loss_fake:0.004445048049092293\n",
            "d_loss_wrong:0.6767995953559875\n",
            "d_loss:0.5887771397829056\n",
            "g_loss:[0.6747415, 0.6731701, 0.0007857083]\n",
            "Batch:73\n",
            "d_loss_real:0.7985490560531616\n",
            "d_loss_fake:0.0019012612756341696\n",
            "d_loss_wrong:0.6339837908744812\n",
            "d_loss:0.5582457929849625\n",
            "g_loss:[0.709187, 0.7076528, 0.0007670841]\n",
            "Batch:74\n",
            "d_loss_real:0.8135712146759033\n",
            "d_loss_fake:0.011350162327289581\n",
            "d_loss_wrong:0.6128341555595398\n",
            "d_loss:0.5628316849470139\n",
            "g_loss:[0.9220884, 0.9204141, 0.0008371453]\n",
            "Batch:75\n",
            "d_loss_real:0.857982873916626\n",
            "d_loss_fake:0.008822726085782051\n",
            "d_loss_wrong:0.6131255030632019\n",
            "d_loss:0.584478497505188\n",
            "g_loss:[0.7949782, 0.79296744, 0.0010053897]\n",
            "Batch:76\n",
            "d_loss_real:0.9123061895370483\n",
            "d_loss_fake:0.11240029335021973\n",
            "d_loss_wrong:0.6106305122375488\n",
            "d_loss:0.6369107961654663\n",
            "g_loss:[2.9507363, 2.94901, 0.00086317805]\n",
            "Batch:77\n",
            "d_loss_real:0.8693987131118774\n",
            "d_loss_fake:0.18040132522583008\n",
            "d_loss_wrong:0.5377791523933411\n",
            "d_loss:0.6142444759607315\n",
            "g_loss:[2.6964846, 2.6944652, 0.0010097569]\n",
            "Batch:78\n",
            "d_loss_real:1.086506724357605\n",
            "d_loss_fake:0.2215038388967514\n",
            "d_loss_wrong:0.5415040254592896\n",
            "d_loss:0.734005331993103\n",
            "g_loss:[4.4561033, 4.454013, 0.001045258]\n",
            "Batch:79\n",
            "d_loss_real:1.0435220003128052\n",
            "d_loss_fake:0.2771379351615906\n",
            "d_loss_wrong:0.4680725634098053\n",
            "d_loss:0.7080636322498322\n",
            "g_loss:[9.39255, 9.390367, 0.001091802]\n",
            "Batch:80\n",
            "d_loss_real:1.120513916015625\n",
            "d_loss_fake:0.005176220554858446\n",
            "d_loss_wrong:0.5752483606338501\n",
            "d_loss:0.7053631097078323\n",
            "g_loss:[5.2992506, 5.2971354, 0.0010576064]\n",
            "Batch:81\n",
            "d_loss_real:0.9822800755500793\n",
            "d_loss_fake:0.20360665023326874\n",
            "d_loss_wrong:0.5566956400871277\n",
            "d_loss:0.6812156140804291\n",
            "g_loss:[3.5972757, 3.5942993, 0.0014882208]\n",
            "Batch:82\n",
            "d_loss_real:1.071445345878601\n",
            "d_loss_fake:0.13461044430732727\n",
            "d_loss_wrong:0.549204409122467\n",
            "d_loss:0.7066763937473297\n",
            "g_loss:[2.9992197, 2.9961872, 0.0015161694]\n",
            "Batch:83\n",
            "d_loss_real:0.9402791261672974\n",
            "d_loss_fake:0.03136448934674263\n",
            "d_loss_wrong:0.5853998064994812\n",
            "d_loss:0.6243306398391724\n",
            "g_loss:[3.497796, 3.4946053, 0.0015953976]\n",
            "Batch:84\n",
            "d_loss_real:0.8755092620849609\n",
            "d_loss_fake:0.01174747385084629\n",
            "d_loss_wrong:0.6221451163291931\n",
            "d_loss:0.5962277799844742\n",
            "g_loss:[3.1825397, 3.179131, 0.0017043324]\n",
            "Batch:85\n",
            "d_loss_real:0.8957908153533936\n",
            "d_loss_fake:0.02111276052892208\n",
            "d_loss_wrong:0.6235249042510986\n",
            "d_loss:0.6090548187494278\n",
            "g_loss:[3.471784, 3.4682555, 0.0017642836]\n",
            "Batch:86\n",
            "d_loss_real:0.874781608581543\n",
            "d_loss_fake:0.03910698741674423\n",
            "d_loss_wrong:0.6001399755477905\n",
            "d_loss:0.5972025394439697\n",
            "g_loss:[3.4136665, 3.4101257, 0.0017704078]\n",
            "Batch:87\n",
            "d_loss_real:0.8984410762786865\n",
            "d_loss_fake:0.026734178885817528\n",
            "d_loss_wrong:0.5799153447151184\n",
            "d_loss:0.6008829176425934\n",
            "g_loss:[2.1279917, 2.1243286, 0.0018314994]\n",
            "Batch:88\n",
            "d_loss_real:1.2862212657928467\n",
            "d_loss_fake:0.4245307147502899\n",
            "d_loss_wrong:0.6001060009002686\n",
            "d_loss:0.8992698192596436\n",
            "g_loss:[2.3932645, 2.3891785, 0.0020430484]\n",
            "Batch:89\n",
            "d_loss_real:0.8883539438247681\n",
            "d_loss_fake:0.13141024112701416\n",
            "d_loss_wrong:0.6373303532600403\n",
            "d_loss:0.6363621205091476\n",
            "g_loss:[2.7024987, 2.6997678, 0.0013654223]\n",
            "Batch:90\n",
            "d_loss_real:0.9384786486625671\n",
            "d_loss_fake:0.2051495909690857\n",
            "d_loss_wrong:0.5378538966178894\n",
            "d_loss:0.6549901962280273\n",
            "g_loss:[2.9017818, 2.8986144, 0.001583685]\n",
            "Batch:91\n",
            "d_loss_real:1.0421150922775269\n",
            "d_loss_fake:0.15711714327335358\n",
            "d_loss_wrong:0.5702293515205383\n",
            "d_loss:0.7028941661119461\n",
            "g_loss:[2.1582863, 2.1549273, 0.0016795319]\n",
            "Batch:92\n",
            "d_loss_real:1.0852761268615723\n",
            "d_loss_fake:0.1729203313589096\n",
            "d_loss_wrong:0.504557192325592\n",
            "d_loss:0.7120074480772018\n",
            "g_loss:[1.7724648, 1.7684032, 0.0020307845]\n",
            "Batch:93\n",
            "d_loss_real:1.1695377826690674\n",
            "d_loss_fake:0.11688552796840668\n",
            "d_loss_wrong:0.49048107862472534\n",
            "d_loss:0.736610546708107\n",
            "g_loss:[2.0429718, 2.0363572, 0.0033073977]\n",
            "Batch:94\n",
            "d_loss_real:1.0202524662017822\n",
            "d_loss_fake:0.013347115367650986\n",
            "d_loss_wrong:0.5857599973678589\n",
            "d_loss:0.6599030047655106\n",
            "g_loss:[1.9722741, 1.9684267, 0.0019236992]\n",
            "Batch:95\n",
            "d_loss_real:0.9590727090835571\n",
            "d_loss_fake:0.02942929044365883\n",
            "d_loss_wrong:0.6210012435913086\n",
            "d_loss:0.6421439945697784\n",
            "g_loss:[1.32366, 1.3197788, 0.0019406028]\n",
            "Batch:96\n",
            "d_loss_real:0.8881150484085083\n",
            "d_loss_fake:0.04461636021733284\n",
            "d_loss_wrong:0.6654666662216187\n",
            "d_loss:0.6215782761573792\n",
            "g_loss:[1.789536, 1.782129, 0.0037034536]\n",
            "Batch:97\n",
            "d_loss_real:0.917461633682251\n",
            "d_loss_fake:0.0056035397574305534\n",
            "d_loss_wrong:0.6327515840530396\n",
            "d_loss:0.6183196008205414\n",
            "g_loss:[1.3254602, 1.3136778, 0.0058912206]\n",
            "Batch:98\n",
            "d_loss_real:0.936622679233551\n",
            "d_loss_fake:0.03074631839990616\n",
            "d_loss_wrong:0.6767090559005737\n",
            "d_loss:0.6451751887798309\n",
            "g_loss:[1.1966364, 1.1814353, 0.00760053]\n",
            "Batch:99\n",
            "d_loss_real:0.8787087798118591\n",
            "d_loss_fake:0.03008880466222763\n",
            "d_loss_wrong:0.5992869734764099\n",
            "d_loss:0.5966983288526535\n",
            "g_loss:[1.4049723, 1.3925575, 0.0062074363]\n",
            "Batch:100\n",
            "d_loss_real:0.9597737789154053\n",
            "d_loss_fake:0.12042258679866791\n",
            "d_loss_wrong:0.5395876169204712\n",
            "d_loss:0.6448894441127777\n",
            "g_loss:[1.5954067, 1.5869039, 0.004251343]\n",
            "Batch:101\n",
            "d_loss_real:0.9396769404411316\n",
            "d_loss_fake:0.01883106678724289\n",
            "d_loss_wrong:0.6405372023582458\n",
            "d_loss:0.6346805393695831\n",
            "g_loss:[1.0574523, 1.0507511, 0.003350614]\n",
            "Batch:102\n",
            "d_loss_real:0.9073909521102905\n",
            "d_loss_fake:0.0148610295727849\n",
            "d_loss_wrong:0.6224012970924377\n",
            "d_loss:0.6130110621452332\n",
            "g_loss:[1.044571, 1.0376529, 0.003459122]\n",
            "Batch:103\n",
            "d_loss_real:0.9416310787200928\n",
            "d_loss_fake:0.013438934460282326\n",
            "d_loss_wrong:0.6421517133712769\n",
            "d_loss:0.63471320271492\n",
            "g_loss:[0.824025, 0.81779814, 0.0031134114]\n",
            "Batch:104\n",
            "d_loss_real:0.998282790184021\n",
            "d_loss_fake:0.015264524146914482\n",
            "d_loss_wrong:0.6235941052436829\n",
            "d_loss:0.6588560491800308\n",
            "g_loss:[0.7818994, 0.77538407, 0.0032576509]\n",
            "Batch:105\n",
            "d_loss_real:0.8495233058929443\n",
            "d_loss_fake:0.0008315233280882239\n",
            "d_loss_wrong:0.6494949460029602\n",
            "d_loss:0.5873432755470276\n",
            "g_loss:[0.7656729, 0.76037204, 0.0026504379]\n",
            "Batch:106\n",
            "d_loss_real:0.828865110874176\n",
            "d_loss_fake:0.002461476484313607\n",
            "d_loss_wrong:0.6902280449867249\n",
            "d_loss:0.5876049399375916\n",
            "g_loss:[0.71687806, 0.711147, 0.0028655278]\n",
            "Batch:107\n",
            "d_loss_real:0.837689995765686\n",
            "d_loss_fake:0.0017070206813514233\n",
            "d_loss_wrong:0.648548424243927\n",
            "d_loss:0.5814088582992554\n",
            "g_loss:[0.7244823, 0.71908355, 0.0026993756]\n",
            "Batch:108\n",
            "d_loss_real:0.8503268361091614\n",
            "d_loss_fake:0.001304958714172244\n",
            "d_loss_wrong:0.653812825679779\n",
            "d_loss:0.5889428704977036\n",
            "g_loss:[0.76123846, 0.7559103, 0.002664101]\n",
            "Batch:109\n",
            "d_loss_real:0.8087610006332397\n",
            "d_loss_fake:0.007257568184286356\n",
            "d_loss_wrong:0.6841540336608887\n",
            "d_loss:0.5772334039211273\n",
            "g_loss:[0.73482835, 0.72802734, 0.0034005176]\n",
            "Batch:110\n",
            "d_loss_real:0.8202508687973022\n",
            "d_loss_fake:0.000547601783182472\n",
            "d_loss_wrong:0.6579319834709167\n",
            "d_loss:0.5747453272342682\n",
            "g_loss:[0.72800946, 0.72189444, 0.0030575008]\n",
            "Batch:111\n",
            "d_loss_real:0.8511770963668823\n",
            "d_loss_fake:0.003014403861016035\n",
            "d_loss_wrong:0.6435860395431519\n",
            "d_loss:0.5872386544942856\n",
            "g_loss:[0.72645265, 0.72145635, 0.0024981569]\n",
            "Batch:112\n",
            "d_loss_real:0.9042317867279053\n",
            "d_loss_fake:0.0022216816432774067\n",
            "d_loss_wrong:0.8381739258766174\n",
            "d_loss:0.6622148007154465\n",
            "g_loss:[0.7252997, 0.7193074, 0.0029961588]\n",
            "Batch:113\n",
            "d_loss_real:0.814447283744812\n",
            "d_loss_fake:0.00734902685508132\n",
            "d_loss_wrong:0.6237788796424866\n",
            "d_loss:0.5650056153535843\n",
            "g_loss:[0.7527931, 0.7470659, 0.0028635894]\n",
            "Batch:114\n",
            "d_loss_real:0.8389940857887268\n",
            "d_loss_fake:0.007356623653322458\n",
            "d_loss_wrong:0.6262233853340149\n",
            "d_loss:0.5778920501470566\n",
            "g_loss:[0.7816131, 0.77768207, 0.0019655107]\n",
            "Batch:115\n",
            "d_loss_real:0.8492964506149292\n",
            "d_loss_fake:0.02862052246928215\n",
            "d_loss_wrong:0.6169024109840393\n",
            "d_loss:0.5860289633274078\n",
            "g_loss:[0.8298121, 0.8264494, 0.001681346]\n",
            "Batch:116\n",
            "d_loss_real:0.9462346434593201\n",
            "d_loss_fake:0.00603820476680994\n",
            "d_loss_wrong:0.6708828210830688\n",
            "d_loss:0.6423475742340088\n",
            "g_loss:[0.7644223, 0.7610059, 0.001708207]\n",
            "Batch:117\n",
            "d_loss_real:0.8143695592880249\n",
            "d_loss_fake:0.09094896912574768\n",
            "d_loss_wrong:0.6680622696876526\n",
            "d_loss:0.5969375967979431\n",
            "g_loss:[1.34417, 1.3412318, 0.0014690764]\n",
            "Batch:118\n",
            "d_loss_real:0.8856590986251831\n",
            "d_loss_fake:0.11032633483409882\n",
            "d_loss_wrong:0.5022507309913635\n",
            "d_loss:0.5959738194942474\n",
            "g_loss:[4.0505333, 4.0475674, 0.001482914]\n",
            "Batch:119\n",
            "d_loss_real:1.6480846405029297\n",
            "d_loss_fake:0.020177390426397324\n",
            "d_loss_wrong:0.6600986123085022\n",
            "d_loss:0.9941113144159317\n",
            "g_loss:[0.84366196, 0.8401923, 0.0017348371]\n",
            "Batch:120\n",
            "d_loss_real:0.8058232665061951\n",
            "d_loss_fake:0.02900831773877144\n",
            "d_loss_wrong:0.6397724747657776\n",
            "d_loss:0.5701068341732025\n",
            "g_loss:[0.9114996, 0.9068233, 0.0023381752]\n",
            "Batch:121\n",
            "d_loss_real:0.8162816762924194\n",
            "d_loss_fake:0.0036867866292595863\n",
            "d_loss_wrong:0.6390166878700256\n",
            "d_loss:0.5688167065382004\n",
            "g_loss:[0.94332176, 0.9387641, 0.002278849]\n",
            "Batch:122\n",
            "d_loss_real:0.8201045393943787\n",
            "d_loss_fake:0.0020947768352925777\n",
            "d_loss_wrong:0.649157702922821\n",
            "d_loss:0.5728653967380524\n",
            "g_loss:[0.90383184, 0.8985473, 0.002642272]\n",
            "Batch:123\n",
            "d_loss_real:0.8393924832344055\n",
            "d_loss_fake:0.0008865888812579215\n",
            "d_loss_wrong:0.7088777422904968\n",
            "d_loss:0.5971373170614243\n",
            "g_loss:[0.82752484, 0.82253575, 0.0024945298]\n",
            "Batch:124\n",
            "d_loss_real:0.7914432883262634\n",
            "d_loss_fake:0.0006128301029093564\n",
            "d_loss_wrong:0.6284105777740479\n",
            "d_loss:0.5529775023460388\n",
            "g_loss:[0.90430206, 0.89990354, 0.002199257]\n",
            "Batch:125\n",
            "d_loss_real:0.8172549605369568\n",
            "d_loss_fake:0.0002701878547668457\n",
            "d_loss_wrong:0.6298975944519043\n",
            "d_loss:0.5661694258451462\n",
            "g_loss:[0.8845888, 0.8798039, 0.0023924327]\n",
            "Batch:126\n",
            "d_loss_real:0.8305345177650452\n",
            "d_loss_fake:0.00047955953050404787\n",
            "d_loss_wrong:0.6474204659461975\n",
            "d_loss:0.5772422701120377\n",
            "g_loss:[0.8417342, 0.83680713, 0.0024635205]\n",
            "Batch:127\n",
            "d_loss_real:0.7917752265930176\n",
            "d_loss_fake:0.00036007235758006573\n",
            "d_loss_wrong:0.6470475792884827\n",
            "d_loss:0.5577395260334015\n",
            "g_loss:[0.8568128, 0.85262394, 0.0020944076]\n",
            "Batch:128\n",
            "d_loss_real:0.8819034695625305\n",
            "d_loss_fake:0.0008296488085761666\n",
            "d_loss_wrong:0.6287295818328857\n",
            "d_loss:0.5983415395021439\n",
            "g_loss:[0.83425075, 0.82672715, 0.0037617926]\n",
            "Batch:129\n",
            "d_loss_real:0.8176647424697876\n",
            "d_loss_fake:0.0014949776232242584\n",
            "d_loss_wrong:0.6429120898246765\n",
            "d_loss:0.569934144616127\n",
            "g_loss:[0.80988264, 0.8041454, 0.002868634]\n",
            "Batch:130\n",
            "d_loss_real:0.8700611591339111\n",
            "d_loss_fake:0.0007847618544474244\n",
            "d_loss_wrong:0.650939404964447\n",
            "d_loss:0.5979616194963455\n",
            "g_loss:[0.805926, 0.80247366, 0.0017261922]\n",
            "Batch:131\n",
            "d_loss_real:0.8234454393386841\n",
            "d_loss_fake:0.001066412660293281\n",
            "d_loss_wrong:0.6804282665252686\n",
            "d_loss:0.5820963829755783\n",
            "g_loss:[0.7935962, 0.7879984, 0.0027989133]\n",
            "Batch:132\n",
            "d_loss_real:0.8056318163871765\n",
            "d_loss_fake:0.00019399123266339302\n",
            "d_loss_wrong:0.6431723237037659\n",
            "d_loss:0.5636574923992157\n",
            "g_loss:[0.9144767, 0.91037935, 0.0020486629]\n",
            "Batch:133\n",
            "d_loss_real:0.8202275037765503\n",
            "d_loss_fake:0.0008567771874368191\n",
            "d_loss_wrong:0.6562694907188416\n",
            "d_loss:0.5743953138589859\n",
            "g_loss:[0.82810974, 0.82495415, 0.0015777946]\n",
            "Batch:134\n",
            "d_loss_real:0.848906934261322\n",
            "d_loss_fake:0.000656252377666533\n",
            "d_loss_wrong:0.6660937666893005\n",
            "d_loss:0.5911409705877304\n",
            "g_loss:[0.7645498, 0.7616024, 0.0014736999]\n",
            "Batch:135\n",
            "d_loss_real:0.8134930729866028\n",
            "d_loss_fake:0.0009744979324750602\n",
            "d_loss_wrong:0.6542497873306274\n",
            "d_loss:0.5705526024103165\n",
            "g_loss:[0.8416318, 0.83848166, 0.0015750779]\n",
            "Batch:136\n",
            "d_loss_real:0.8285554647445679\n",
            "d_loss_fake:0.0003573254216462374\n",
            "d_loss_wrong:0.6190727949142456\n",
            "d_loss:0.5691352635622025\n",
            "g_loss:[0.75996536, 0.75689685, 0.0015342432]\n",
            "Batch:137\n",
            "d_loss_real:0.8373268246650696\n",
            "d_loss_fake:0.0004736499977298081\n",
            "d_loss_wrong:0.6419898271560669\n",
            "d_loss:0.579279288649559\n",
            "g_loss:[0.8942852, 0.89126873, 0.0015082299]\n",
            "Batch:138\n",
            "d_loss_real:0.8137379884719849\n",
            "d_loss_fake:0.00022095430176705122\n",
            "d_loss_wrong:0.6320295929908752\n",
            "d_loss:0.5649316310882568\n",
            "g_loss:[0.7818524, 0.77823865, 0.0018068986]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZctOpIHz2Sh7"
      },
      "source": [
        "After the training of Stage I StackGAN is completed, two new files will be created in root directory, naming stage1_gen.h5 and stage1_dis.h5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFdudUzy2exa"
      },
      "source": [
        "Stage 1 over, begin with Stage 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwjVPTe82snt"
      },
      "source": [
        "**Train Stage 2 StackGAN.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSNvM7kq26Ob"
      },
      "source": [
        "Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5JA9Irbg76X"
      },
      "source": [
        "import os\r\n",
        "import pickle\r\n",
        "import random\r\n",
        "import time\r\n",
        "\r\n",
        "import PIL\r\n",
        "import numpy as np\r\n",
        "import pandas as pd"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZ1gxlpihWSZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c68b06d0-f6cc-4a70-cc47-f2a8e868815a"
      },
      "source": [
        "print(tf.version)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<module 'tensorflow._api.v1.version' from '/tensorflow-1.15.2/python3.6/tensorflow_core/_api/v1/version/__init__.py'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeWVBhf1VxlH"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nxV8_L8heVa"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from PIL import Image\r\n",
        "from keras import Input, Model\r\n",
        "from keras import backend as K\r\n",
        "from keras.callbacks import TensorBoard\r\n",
        "from keras.layers import Dense, LeakyReLU, BatchNormalization, ReLU, Reshape, UpSampling2D, Conv2D, Activation, \\\r\n",
        "    concatenate, Flatten, Lambda, Concatenate, ZeroPadding2D\r\n",
        "from keras.layers import add\r\n",
        "from keras.optimizers import Adam\r\n",
        "from matplotlib import pyplot as plt\r\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1NTU9IW0KFp",
        "outputId": "c68b06d0-f6cc-4a70-cc47-f2a8e868815a"
      },
      "source": [
        "print(tf.version)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<module 'tensorflow._api.v1.version' from '/tensorflow-1.15.2/python3.6/tensorflow_core/_api/v1/version/__init__.py'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "G0aLxTVjlAOR",
        "outputId": "69235494-f223-4e56-af99-f894b8d88933"
      },
      "source": [
        "tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tk5AIkrT3SMI"
      },
      "source": [
        "define functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfhSQ12IhpVi"
      },
      "source": [
        "def build_ca_model():\r\n",
        "    \"\"\"\r\n",
        "    Get conditioning augmentation model.\r\n",
        "    Takes an embedding of shape (1024,) and returns a tensor of shape (256,)\r\n",
        "    \"\"\"\r\n",
        "    input_layer = Input(shape=(1024,))\r\n",
        "    x = Dense(256)(input_layer)\r\n",
        "    x = LeakyReLU(alpha=0.2)(x)\r\n",
        "    model = Model(inputs=[input_layer], outputs=[x])\r\n",
        "    return model\r\n",
        "\r\n",
        "def build_embedding_compressor_model():\r\n",
        "    \"\"\"\r\n",
        "    Build embedding compressor model\r\n",
        "    \"\"\"\r\n",
        "    input_layer = Input(shape=(1024,))\r\n",
        "    x = Dense(128)(input_layer)\r\n",
        "    x = ReLU()(x)\r\n",
        "    model = Model(inputs=[input_layer], outputs=[x])\r\n",
        "    return model\r\n",
        "  \r\n",
        "def generate_c(x):\r\n",
        "    mean = x[:, :128]\r\n",
        "    log_sigma = x[:, 128:]\r\n",
        "\r\n",
        "    stddev = K.exp(log_sigma)\r\n",
        "    epsilon = K.random_normal(shape=K.constant((mean.shape[1],), dtype='int32'))\r\n",
        "    c = stddev * epsilon + mean\r\n",
        "\r\n",
        "    return c\r\n",
        "\r\n",
        "def build_stage1_generator():\r\n",
        "    \"\"\"\r\n",
        "    Builds a generator model used in Stage-I\r\n",
        "    \"\"\"\r\n",
        "    input_layer = Input(shape=(1024,))\r\n",
        "    x = Dense(256)(input_layer)\r\n",
        "    mean_logsigma = LeakyReLU(alpha=0.2)(x)\r\n",
        "\r\n",
        "    c = Lambda(generate_c)(mean_logsigma)\r\n",
        "\r\n",
        "    input_layer2 = Input(shape=(100,))\r\n",
        "\r\n",
        "    gen_input = Concatenate(axis=1)([c, input_layer2])\r\n",
        "\r\n",
        "    x = Dense(128 * 8 * 4 * 4, use_bias=False)(gen_input)\r\n",
        "    x = ReLU()(x)\r\n",
        "\r\n",
        "    x = Reshape((4, 4, 128 * 8), input_shape=(128 * 8 * 4 * 4,))(x)\r\n",
        "\r\n",
        "    x = UpSampling2D(size=(2, 2))(x)\r\n",
        "    x = Conv2D(512, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    x = ReLU()(x)\r\n",
        "\r\n",
        "    x = UpSampling2D(size=(2, 2))(x)\r\n",
        "    x = Conv2D(256, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    x = ReLU()(x)\r\n",
        "\r\n",
        "    x = UpSampling2D(size=(2, 2))(x)\r\n",
        "    x = Conv2D(128, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    x = ReLU()(x)\r\n",
        "\r\n",
        "    x = UpSampling2D(size=(2, 2))(x)\r\n",
        "    x = Conv2D(64, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    x = ReLU()(x)\r\n",
        "\r\n",
        "    x = Conv2D(3, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\r\n",
        "    x = Activation(activation='tanh')(x)\r\n",
        "\r\n",
        "    stage1_gen = Model(inputs=[input_layer, input_layer2], outputs=[x, mean_logsigma])\r\n",
        "    return stage1_gen\r\n",
        "  \r\n",
        "def residual_block(input):\r\n",
        "    \"\"\"\r\n",
        "    Residual block in the generator network\r\n",
        "    \"\"\"\r\n",
        "    x = Conv2D(128 * 4, kernel_size=(3, 3), padding='same', strides=1)(input)\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    x = ReLU()(x)\r\n",
        "\r\n",
        "    x = Conv2D(128 * 4, kernel_size=(3, 3), strides=1, padding='same')(x)\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "\r\n",
        "    x = add([x, input])\r\n",
        "    x = ReLU()(x)\r\n",
        "\r\n",
        "    return x\r\n",
        "  \r\n",
        "def joint_block(inputs):\r\n",
        "    c = inputs[0]\r\n",
        "    x = inputs[1]\r\n",
        "\r\n",
        "    c = K.expand_dims(c, axis=1)\r\n",
        "    c = K.expand_dims(c, axis=1)\r\n",
        "    c = K.tile(c, [1, 16, 16, 1])\r\n",
        "    return K.concatenate([c, x], axis=3)\r\n",
        "  \r\n",
        "def build_stage2_generator():\r\n",
        "    \"\"\"\r\n",
        "    Create Stage-II generator containing the CA Augmentation Network,\r\n",
        "    the image encoder and the generator network\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    # 1. CA Augmentation Network\r\n",
        "    input_layer = Input(shape=(1024,))\r\n",
        "    input_lr_images = Input(shape=(64, 64, 3))\r\n",
        "\r\n",
        "    ca = Dense(256)(input_layer)\r\n",
        "    mean_logsigma = LeakyReLU(alpha=0.2)(ca)\r\n",
        "    c = Lambda(generate_c)(mean_logsigma)\r\n",
        "\r\n",
        "    # 2. Image Encoder\r\n",
        "    x = ZeroPadding2D(padding=(1, 1))(input_lr_images)\r\n",
        "    x = Conv2D(128, kernel_size=(3, 3), strides=1, use_bias=False)(x)\r\n",
        "    x = ReLU()(x)\r\n",
        "\r\n",
        "    x = ZeroPadding2D(padding=(1, 1))(x)\r\n",
        "    x = Conv2D(256, kernel_size=(4, 4), strides=2, use_bias=False)(x)\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    x = ReLU()(x)\r\n",
        "\r\n",
        "    x = ZeroPadding2D(padding=(1, 1))(x)\r\n",
        "    x = Conv2D(512, kernel_size=(4, 4), strides=2, use_bias=False)(x)\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    x = ReLU()(x)\r\n",
        "\r\n",
        "    # 3. Joint\r\n",
        "    c_code = Lambda(joint_block)([c, x])\r\n",
        "\r\n",
        "    x = ZeroPadding2D(padding=(1, 1))(c_code)\r\n",
        "    x = Conv2D(512, kernel_size=(3, 3), strides=1, use_bias=False)(x)\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    x = ReLU()(x)\r\n",
        "\r\n",
        "    # 4. Residual blocks\r\n",
        "    x = residual_block(x)\r\n",
        "    x = residual_block(x)\r\n",
        "    x = residual_block(x)\r\n",
        "    x = residual_block(x)\r\n",
        "\r\n",
        "    # 5. Upsampling blocks\r\n",
        "    x = UpSampling2D(size=(2, 2))(x)\r\n",
        "    x = Conv2D(512, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    x = ReLU()(x)\r\n",
        "\r\n",
        "    x = UpSampling2D(size=(2, 2))(x)\r\n",
        "    x = Conv2D(256, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    x = ReLU()(x)\r\n",
        "\r\n",
        "    x = UpSampling2D(size=(2, 2))(x)\r\n",
        "    x = Conv2D(128, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    x = ReLU()(x)\r\n",
        "\r\n",
        "    x = UpSampling2D(size=(2, 2))(x)\r\n",
        "    x = Conv2D(64, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    x = ReLU()(x)\r\n",
        "\r\n",
        "    x = Conv2D(3, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\r\n",
        "    x = Activation('tanh')(x)\r\n",
        "\r\n",
        "    model = Model(inputs=[input_layer, input_lr_images], outputs=[x, mean_logsigma])\r\n",
        "    return model\r\n",
        "  \r\n",
        "def build_stage2_discriminator():\r\n",
        "    \"\"\"\r\n",
        "    Create Stage-II discriminator network\r\n",
        "    \"\"\"\r\n",
        "    input_layer = Input(shape=(256, 256, 3))\r\n",
        "\r\n",
        "    x = Conv2D(64, (4, 4), padding='same', strides=2, input_shape=(256, 256, 3), use_bias=False)(input_layer)\r\n",
        "    x = LeakyReLU(alpha=0.2)(x)\r\n",
        "\r\n",
        "    x = Conv2D(128, (4, 4), padding='same', strides=2, use_bias=False)(x)\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    x = LeakyReLU(alpha=0.2)(x)\r\n",
        "\r\n",
        "    x = Conv2D(256, (4, 4), padding='same', strides=2, use_bias=False)(x)\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    x = LeakyReLU(alpha=0.2)(x)\r\n",
        "\r\n",
        "    x = Conv2D(512, (4, 4), padding='same', strides=2, use_bias=False)(x)\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    x = LeakyReLU(alpha=0.2)(x)\r\n",
        "\r\n",
        "    x = Conv2D(1024, (4, 4), padding='same', strides=2, use_bias=False)(x)\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    x = LeakyReLU(alpha=0.2)(x)\r\n",
        "\r\n",
        "    x = Conv2D(2048, (4, 4), padding='same', strides=2, use_bias=False)(x)\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    x = LeakyReLU(alpha=0.2)(x)\r\n",
        "\r\n",
        "    x = Conv2D(1024, (1, 1), padding='same', strides=1, use_bias=False)(x)\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    x = LeakyReLU(alpha=0.2)(x)\r\n",
        "\r\n",
        "    x = Conv2D(512, (1, 1), padding='same', strides=1, use_bias=False)(x)\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "\r\n",
        "    x2 = Conv2D(128, (1, 1), padding='same', strides=1, use_bias=False)(x)\r\n",
        "    x2 = BatchNormalization()(x2)\r\n",
        "    x2 = LeakyReLU(alpha=0.2)(x2)\r\n",
        "\r\n",
        "    x2 = Conv2D(128, (3, 3), padding='same', strides=1, use_bias=False)(x2)\r\n",
        "    x2 = BatchNormalization()(x2)\r\n",
        "    x2 = LeakyReLU(alpha=0.2)(x2)\r\n",
        "\r\n",
        "    x2 = Conv2D(512, (3, 3), padding='same', strides=1, use_bias=False)(x2)\r\n",
        "    x2 = BatchNormalization()(x2)\r\n",
        "\r\n",
        "    added_x = add([x, x2])\r\n",
        "    added_x = LeakyReLU(alpha=0.2)(added_x)\r\n",
        "\r\n",
        "    input_layer2 = Input(shape=(4, 4, 128))\r\n",
        "\r\n",
        "    merged_input = concatenate([added_x, input_layer2])\r\n",
        "\r\n",
        "    x3 = Conv2D(64 * 8, kernel_size=1, padding=\"same\", strides=1)(merged_input)\r\n",
        "    x3 = BatchNormalization()(x3)\r\n",
        "    x3 = LeakyReLU(alpha=0.2)(x3)\r\n",
        "    x3 = Flatten()(x3)\r\n",
        "    x3 = Dense(1)(x3)\r\n",
        "    x3 = Activation('sigmoid')(x3)\r\n",
        "\r\n",
        "    stage2_dis = Model(inputs=[input_layer, input_layer2], outputs=[x3])\r\n",
        "    return stage2_dis\r\n",
        "  \r\n",
        "def build_adversarial_model(gen_model2, dis_model, gen_model1):\r\n",
        "    \"\"\"\r\n",
        "    Create adversarial model\r\n",
        "    \"\"\"\r\n",
        "    embeddings_input_layer = Input(shape=(1024, ))\r\n",
        "    noise_input_layer = Input(shape=(100, ))\r\n",
        "    compressed_embedding_input_layer = Input(shape=(4, 4, 128))\r\n",
        "\r\n",
        "    gen_model1.trainable = False\r\n",
        "    dis_model.trainable = False\r\n",
        "\r\n",
        "    lr_images, mean_logsigma1 = gen_model1([embeddings_input_layer, noise_input_layer])\r\n",
        "    hr_images, mean_logsigma2 = gen_model2([embeddings_input_layer, lr_images])\r\n",
        "    valid = dis_model([hr_images, compressed_embedding_input_layer])\r\n",
        "\r\n",
        "    model = Model(inputs=[embeddings_input_layer, noise_input_layer, compressed_embedding_input_layer], outputs=[valid, mean_logsigma2])\r\n",
        "    return model\r\n",
        "\r\n",
        "  \r\n",
        "\"\"\"\r\n",
        "Dataset loading related methods\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "\r\n",
        "def load_class_ids(class_info_file_path):\r\n",
        "    \"\"\"\r\n",
        "    Load class ids from class_info.pickle file\r\n",
        "    \"\"\"\r\n",
        "    with open(class_info_file_path, 'rb') as f:\r\n",
        "        class_ids = pickle.load(f, encoding='latin1')\r\n",
        "        return class_ids\r\n",
        "\r\n",
        "\r\n",
        "def load_embeddings(embeddings_file_path):\r\n",
        "    \"\"\"\r\n",
        "    Function to load embeddings\r\n",
        "    \"\"\"\r\n",
        "    with open(embeddings_file_path, 'rb') as f:\r\n",
        "        embeddings = pickle.load(f, encoding='latin1')\r\n",
        "        embeddings = np.array(embeddings)\r\n",
        "        print('embeddings: ', embeddings.shape)\r\n",
        "    return embeddings\r\n",
        "\r\n",
        "\r\n",
        "def load_filenames(filenames_file_path):\r\n",
        "    \"\"\"\r\n",
        "    Load filenames.pickle file and return a list of all file names\r\n",
        "    \"\"\"\r\n",
        "    with open(filenames_file_path, 'rb') as f:\r\n",
        "        filenames = pickle.load(f, encoding='latin1')\r\n",
        "    return filenames\r\n",
        "\r\n",
        "\r\n",
        "def load_bounding_boxes(dataset_dir):\r\n",
        "    \"\"\"\r\n",
        "    Load bounding boxes and return a dictionary of file names and corresponding bounding boxes\r\n",
        "    \"\"\"\r\n",
        "    # Paths\r\n",
        "    bounding_boxes_path = os.path.join(dataset_dir, 'bounding_boxes.txt')\r\n",
        "    file_paths_path = os.path.join(dataset_dir, 'images.txt')\r\n",
        "\r\n",
        "    # Read bounding_boxes.txt and images.txt file\r\n",
        "    df_bounding_boxes = pd.read_csv(bounding_boxes_path,\r\n",
        "                                    delim_whitespace=True, header=None).astype(int)\r\n",
        "    df_file_names = pd.read_csv(file_paths_path, delim_whitespace=True, header=None)\r\n",
        "\r\n",
        "    # Create a list of file names\r\n",
        "    file_names = df_file_names[1].tolist()\r\n",
        "\r\n",
        "    # Create a dictionary of file_names and bounding boxes\r\n",
        "    filename_boundingbox_dict = {img_file[:-4]: [] for img_file in file_names[:2]}\r\n",
        "\r\n",
        "    # Assign a bounding box to the corresponding image\r\n",
        "    for i in range(0, len(file_names)):\r\n",
        "        # Get the bounding box\r\n",
        "        bounding_box = df_bounding_boxes.iloc[i][1:].tolist()\r\n",
        "        key = file_names[i][:-4]\r\n",
        "        filename_boundingbox_dict[key] = bounding_box\r\n",
        "\r\n",
        "    return filename_boundingbox_dict\r\n",
        "\r\n",
        "\r\n",
        "def get_img(img_path, bbox, image_size):\r\n",
        "    \"\"\"\r\n",
        "    Load and resize images\r\n",
        "    \"\"\"\r\n",
        "    img = Image.open(img_path).convert('RGB')\r\n",
        "    width, height = img.size\r\n",
        "    if bbox is not None:\r\n",
        "        R = int(np.maximum(bbox[2], bbox[3]) * 0.75)\r\n",
        "        center_x = int((2 * bbox[0] + bbox[2]) / 2)\r\n",
        "        center_y = int((2 * bbox[1] + bbox[3]) / 2)\r\n",
        "        y1 = np.maximum(0, center_y - R)\r\n",
        "        y2 = np.minimum(height, center_y + R)\r\n",
        "        x1 = np.maximum(0, center_x - R)\r\n",
        "        x2 = np.minimum(width, center_x + R)\r\n",
        "        img = img.crop([x1, y1, x2, y2])\r\n",
        "    img = img.resize(image_size, PIL.Image.BILINEAR)\r\n",
        "    return img\r\n",
        "\r\n",
        "\r\n",
        "def load_dataset(filenames_file_path, class_info_file_path, cub_dataset_dir, embeddings_file_path, image_size):\r\n",
        "    filenames = load_filenames(filenames_file_path)\r\n",
        "    class_ids = load_class_ids(class_info_file_path)\r\n",
        "    bounding_boxes = load_bounding_boxes(cub_dataset_dir)\r\n",
        "    all_embeddings = load_embeddings(embeddings_file_path)\r\n",
        "\r\n",
        "    X, y, embeddings = [], [], []\r\n",
        "\r\n",
        "    print(\"All embeddings shape:\", all_embeddings.shape)\r\n",
        "\r\n",
        "    for index, filename in enumerate(filenames):\r\n",
        "        bounding_box = bounding_boxes[filename]\r\n",
        "\r\n",
        "        try:\r\n",
        "            # Load images\r\n",
        "            img_name = '{}/images/{}.jpg'.format(cub_dataset_dir, filename)\r\n",
        "            img = get_img(img_name, bounding_box, image_size)\r\n",
        "\r\n",
        "            all_embeddings1 = all_embeddings[index, :, :]\r\n",
        "\r\n",
        "            embedding_ix = random.randint(0, all_embeddings1.shape[0] - 1)\r\n",
        "            embedding = all_embeddings1[embedding_ix, :]\r\n",
        "\r\n",
        "            X.append(np.array(img))\r\n",
        "            y.append(class_ids[index])\r\n",
        "            embeddings.append(embedding)\r\n",
        "        except Exception as e:\r\n",
        "            print(e)\r\n",
        "\r\n",
        "    X = np.array(X)\r\n",
        "    y = np.array(y)\r\n",
        "    embeddings = np.array(embeddings)\r\n",
        "\r\n",
        "    return X, y, embeddings\r\n",
        "\r\n",
        "\"\"\"\r\n",
        "Loss functions\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "\r\n",
        "def KL_loss(y_true, y_pred):\r\n",
        "    mean = y_pred[:, :128]\r\n",
        "    logsigma = y_pred[:, :128]\r\n",
        "    loss = -logsigma + .5 * (-1 + K.exp(2. * logsigma) + K.square(mean))\r\n",
        "    loss = K.mean(loss)\r\n",
        "    return loss\r\n",
        "\r\n",
        "\r\n",
        "def custom_generator_loss(y_true, y_pred):\r\n",
        "    # Calculate binary cross entropy loss\r\n",
        "    return K.binary_crossentropy(y_true, y_pred)\r\n",
        "\r\n",
        "\r\n",
        "def write_log(callback, name, loss, batch_no):\r\n",
        "    \"\"\"\r\n",
        "    Write training summary to TensorBoard\r\n",
        "    \"\"\"\r\n",
        "    summary = tf.Summary()\r\n",
        "    summary_value = summary.value.add()\r\n",
        "    summary_value.simple_value = loss\r\n",
        "    summary_value.tag = name\r\n",
        "    callback.writer.add_summary(summary, batch_no)\r\n",
        "    callback.writer.flush()\r\n",
        "\r\n",
        "\r\n",
        "def save_rgb_img(img, path):\r\n",
        "    \"\"\"\r\n",
        "    Save an rgb image\r\n",
        "    \"\"\"\r\n",
        "    fig = plt.figure()\r\n",
        "    ax = fig.add_subplot(1, 1, 1)\r\n",
        "    ax.imshow(img)\r\n",
        "    ax.axis(\"off\")\r\n",
        "    ax.set_title(\"Image\")\r\n",
        "\r\n",
        "    plt.savefig(path)\r\n",
        "    plt.close()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60w5pcqy3Zk-"
      },
      "source": [
        "**Define hyper-parameters and train stage 2 model.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Anprdlmq8lb",
        "outputId": "9422645a-0bd9-4ace-cb2b-2f68fb8ed544"
      },
      "source": [
        "if __name__ == '__main__':\r\n",
        "    data_dir = \"/content/gdrive/My Drive/project_root/birds\"\r\n",
        "    train_dir = data_dir + \"/train\"\r\n",
        "    test_dir = data_dir + \"/test\"\r\n",
        "    hr_image_size = (256, 256)\r\n",
        "    lr_image_size = (64, 64)\r\n",
        "    batch_size = 32\r\n",
        "    z_dim = 100\r\n",
        "    stage1_generator_lr = 0.0002\r\n",
        "    stage1_discriminator_lr = 0.0002\r\n",
        "    stage1_lr_decay_step = 600\r\n",
        "    epochs = 2\r\n",
        "    condition_dim = 128\r\n",
        "\r\n",
        "    embeddings_file_path_train = train_dir + \"/char-CNN-RNN-embeddings.pickle\"\r\n",
        "    embeddings_file_path_test = test_dir + \"/char-CNN-RNN-embeddings.pickle\"\r\n",
        "\r\n",
        "    filenames_file_path_train = train_dir + \"/filenames.pickle\"\r\n",
        "    filenames_file_path_test = test_dir + \"/filenames.pickle\"\r\n",
        "\r\n",
        "    class_info_file_path_train = train_dir + \"/class_info.pickle\"\r\n",
        "    class_info_file_path_test = test_dir + \"/class_info.pickle\"\r\n",
        "\r\n",
        "    cub_dataset_dir = \"/content/gdrive/My Drive/project_root/CUB_200_2011\"\r\n",
        "\r\n",
        "    # Define optimizers\r\n",
        "    dis_optimizer = Adam(lr=stage1_discriminator_lr, beta_1=0.5, beta_2=0.999)\r\n",
        "    gen_optimizer = Adam(lr=stage1_generator_lr, beta_1=0.5, beta_2=0.999)\r\n",
        "\r\n",
        "    \"\"\"\r\n",
        "    Load datasets\r\n",
        "    \"\"\"\r\n",
        "    X_hr_train, y_hr_train, embeddings_train = load_dataset(filenames_file_path=filenames_file_path_train,\r\n",
        "                                                            class_info_file_path=class_info_file_path_train,\r\n",
        "                                                            cub_dataset_dir=cub_dataset_dir,\r\n",
        "                                                            embeddings_file_path=embeddings_file_path_train,\r\n",
        "                                                            image_size=(256, 256))\r\n",
        "\r\n",
        "    X_hr_test, y_hr_test, embeddings_test = load_dataset(filenames_file_path=filenames_file_path_test,\r\n",
        "                                                         class_info_file_path=class_info_file_path_test,\r\n",
        "                                                         cub_dataset_dir=cub_dataset_dir,\r\n",
        "                                                         embeddings_file_path=embeddings_file_path_test,\r\n",
        "                                                         image_size=(256, 256))\r\n",
        "\r\n",
        "    X_lr_train, y_lr_train, _ = load_dataset(filenames_file_path=filenames_file_path_train,\r\n",
        "                                             class_info_file_path=class_info_file_path_train,\r\n",
        "                                             cub_dataset_dir=cub_dataset_dir,\r\n",
        "                                             embeddings_file_path=embeddings_file_path_train,\r\n",
        "                                             image_size=(64, 64))\r\n",
        "\r\n",
        "    X_lr_test, y_lr_test, _ = load_dataset(filenames_file_path=filenames_file_path_test,\r\n",
        "                                           class_info_file_path=class_info_file_path_test,\r\n",
        "                                           cub_dataset_dir=cub_dataset_dir,\r\n",
        "                                           embeddings_file_path=embeddings_file_path_test,\r\n",
        "                                           image_size=(64, 64))\r\n",
        "\r\n",
        "    \"\"\"\r\n",
        "    Build and compile models\r\n",
        "    \"\"\"\r\n",
        "    stage2_dis = build_stage2_discriminator()\r\n",
        "    stage2_dis.compile(loss='binary_crossentropy', optimizer=dis_optimizer)\r\n",
        "\r\n",
        "    stage1_gen = build_stage1_generator()\r\n",
        "    stage1_gen.compile(loss=\"binary_crossentropy\", optimizer=gen_optimizer)\r\n",
        "\r\n",
        "    stage1_gen.load_weights(\"stage1_gen.h5\")\r\n",
        "\r\n",
        "    stage2_gen = build_stage2_generator()\r\n",
        "    stage2_gen.compile(loss=\"binary_crossentropy\", optimizer=gen_optimizer)\r\n",
        "\r\n",
        "    embedding_compressor_model = build_embedding_compressor_model()\r\n",
        "    embedding_compressor_model.compile(loss='binary_crossentropy', optimizer='adam')\r\n",
        "\r\n",
        "    adversarial_model = build_adversarial_model(stage2_gen, stage2_dis, stage1_gen)\r\n",
        "    adversarial_model.compile(loss=['binary_crossentropy', KL_loss], loss_weights=[1.0, 2.0],\r\n",
        "                              optimizer=gen_optimizer, metrics=None)\r\n",
        "\r\n",
        "    tensorboard = TensorBoard(log_dir=\"logs/\".format(time.time()))\r\n",
        "    tensorboard.set_model(stage2_gen)\r\n",
        "    tensorboard.set_model(stage2_dis)\r\n",
        "\r\n",
        "    # Generate an array containing real and fake values\r\n",
        "    # Apply label smoothing\r\n",
        "    real_labels = np.ones((batch_size, 1), dtype=float) * 0.9\r\n",
        "    fake_labels = np.zeros((batch_size, 1), dtype=float) * 0.1\r\n",
        "\r\n",
        "    for epoch in range(epochs):\r\n",
        "        print(\"========================================\")\r\n",
        "        print(\"Epoch is:\", epoch)\r\n",
        "\r\n",
        "        gen_losses = []\r\n",
        "        dis_losses = []\r\n",
        "\r\n",
        "        # Load data and train model\r\n",
        "        number_of_batches = int(X_hr_train.shape[0] / batch_size)\r\n",
        "        print(\"Number of batches:{}\".format(number_of_batches))\r\n",
        "        for index in range(number_of_batches):\r\n",
        "            print(\"Batch:{}\".format(index+1))\r\n",
        "\r\n",
        "            # Create a noise vector\r\n",
        "            z_noise = np.random.normal(0, 1, size=(batch_size, z_dim))\r\n",
        "            X_hr_train_batch = X_hr_train[index * batch_size:(index + 1) * batch_size]\r\n",
        "            embedding_batch = embeddings_train[index * batch_size:(index + 1) * batch_size]\r\n",
        "            X_hr_train_batch = (X_hr_train_batch - 127.5) / 127.5\r\n",
        "\r\n",
        "            # Generate fake images\r\n",
        "            lr_fake_images, _ = stage1_gen.predict([embedding_batch, z_noise], verbose=3)\r\n",
        "            hr_fake_images, _ = stage2_gen.predict([embedding_batch, lr_fake_images], verbose=3)\r\n",
        "\r\n",
        "            \"\"\"\r\n",
        "            4. Generate compressed embeddings\r\n",
        "            \"\"\"\r\n",
        "            compressed_embedding = embedding_compressor_model.predict_on_batch(embedding_batch)\r\n",
        "            compressed_embedding = np.reshape(compressed_embedding, (-1, 1, 1, condition_dim))\r\n",
        "            compressed_embedding = np.tile(compressed_embedding, (1, 4, 4, 1))\r\n",
        "\r\n",
        "            \"\"\"\r\n",
        "            5. Train the discriminator model\r\n",
        "            \"\"\"\r\n",
        "            dis_loss_real = stage2_dis.train_on_batch([X_hr_train_batch, compressed_embedding],\r\n",
        "                                                      np.reshape(real_labels, (batch_size, 1)))\r\n",
        "            dis_loss_fake = stage2_dis.train_on_batch([hr_fake_images, compressed_embedding],\r\n",
        "                                                      np.reshape(fake_labels, (batch_size, 1)))\r\n",
        "            dis_loss_wrong = stage2_dis.train_on_batch([X_hr_train_batch[:(batch_size - 1)], compressed_embedding[1:]],\r\n",
        "                                                       np.reshape(fake_labels[1:], (batch_size-1, 1)))\r\n",
        "            d_loss = 0.5 * np.add(dis_loss_real, 0.5 * np.add(dis_loss_wrong,  dis_loss_fake))\r\n",
        "            print(\"d_loss:{}\".format(d_loss))\r\n",
        "\r\n",
        "            \"\"\"\r\n",
        "            Train the adversarial model\r\n",
        "            \"\"\"\r\n",
        "            g_loss = adversarial_model.train_on_batch([embedding_batch, z_noise, compressed_embedding],\r\n",
        "                                                                [K.ones((batch_size, 1)) * 0.9, K.ones((batch_size, 256)) * 0.9])\r\n",
        "\r\n",
        "            print(\"g_loss:{}\".format(g_loss))\r\n",
        "\r\n",
        "            dis_losses.append(d_loss)\r\n",
        "            gen_losses.append(g_loss)\r\n",
        "\r\n",
        "        \"\"\"\r\n",
        "        Save losses to Tensorboard after each epoch\r\n",
        "        \"\"\"\r\n",
        "        write_log(tensorboard, 'discriminator_loss', np.mean(dis_losses), epoch)\r\n",
        "        write_log(tensorboard, 'generator_loss', np.mean(gen_losses[0]), epoch)\r\n",
        "\r\n",
        "        # Generate and save images after every 2nd epoch\r\n",
        "        if epoch % 2 == 0:\r\n",
        "            # z_noise2 = np.random.uniform(-1, 1, size=(batch_size, z_dim))\r\n",
        "            z_noise2 = np.random.normal(0, 1, size=(batch_size, z_dim))\r\n",
        "            embedding_batch = embeddings_test[0:batch_size]\r\n",
        "\r\n",
        "            lr_fake_images, _ = stage1_gen.predict([embedding_batch, z_noise2], verbose=3)\r\n",
        "            hr_fake_images, _ = stage2_gen.predict([embedding_batch, lr_fake_images], verbose=3)\r\n",
        "\r\n",
        "            # Save images\r\n",
        "            for i, img in enumerate(hr_fake_images[:10]):\r\n",
        "                save_rgb_img(img, \"results2/gen_{}_{}.png\".format(epoch, i))\r\n",
        "\r\n",
        "    # Saving the models\r\n",
        "    stage2_gen.save_weights(\"stage2_gen.h5\")\r\n",
        "    stage2_dis.save_weights(\"stage2_dis.h5\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "embeddings:  (8855, 10, 1024)\n",
            "All embeddings shape: (8855, 10, 1024)\n",
            "embeddings:  (2933, 10, 1024)\n",
            "All embeddings shape: (2933, 10, 1024)\n",
            "embeddings:  (8855, 10, 1024)\n",
            "All embeddings shape: (8855, 10, 1024)\n",
            "embeddings:  (2933, 10, 1024)\n",
            "All embeddings shape: (2933, 10, 1024)\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/keras/callbacks/tensorboard_v1.py:200: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/keras/callbacks/tensorboard_v1.py:203: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "========================================\n",
            "Epoch is: 0\n",
            "Number of batches:276\n",
            "Batch:1\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.6/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n",
            "/tensorflow-1.15.2/python3.6/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "d_loss:5.025212943553925\n",
            "g_loss:[0.64219606, 0.6055728, 0.018311625]\n",
            "Batch:2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.6/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "d_loss:1.517137050628662\n",
            "g_loss:[0.60057425, 0.5656972, 0.017438535]\n",
            "Batch:3\n",
            "d_loss:2.008824348449707\n",
            "g_loss:[0.52628654, 0.48889637, 0.018695077]\n",
            "Batch:4\n",
            "d_loss:1.3122752904891968\n",
            "g_loss:[5.2258058, 5.189183, 0.018311365]\n",
            "Batch:5\n",
            "d_loss:1.535803109407425\n",
            "g_loss:[1.566244, 1.52337, 0.021436986]\n",
            "Batch:6\n",
            "d_loss:1.482713907957077\n",
            "g_loss:[1.197254, 1.1578333, 0.019710274]\n",
            "Batch:7\n",
            "d_loss:1.1976382434368134\n",
            "g_loss:[1.022046, 0.98910576, 0.016470129]\n",
            "Batch:8\n",
            "d_loss:1.235061377286911\n",
            "g_loss:[1.3152411, 1.2819492, 0.016645966]\n",
            "Batch:9\n",
            "d_loss:0.8495272994041443\n",
            "g_loss:[0.787853, 0.7604902, 0.013681403]\n",
            "Batch:10\n",
            "d_loss:1.0028788894414902\n",
            "g_loss:[0.8275809, 0.8021251, 0.012727905]\n",
            "Batch:11\n",
            "d_loss:1.0762857496738434\n",
            "g_loss:[0.68906003, 0.65992236, 0.0145688355]\n",
            "Batch:12\n",
            "d_loss:0.8505304455757141\n",
            "g_loss:[0.84057754, 0.81572115, 0.012428204]\n",
            "Batch:13\n",
            "d_loss:0.8863023221492767\n",
            "g_loss:[1.2730746, 1.2507317, 0.011171476]\n",
            "Batch:14\n",
            "d_loss:0.9863477647304535\n",
            "g_loss:[0.98769826, 0.9690937, 0.0093022995]\n",
            "Batch:15\n",
            "d_loss:0.974009782075882\n",
            "g_loss:[0.6777314, 0.62987185, 0.02392976]\n",
            "Batch:16\n",
            "d_loss:0.8434609025716782\n",
            "g_loss:[0.74746966, 0.70632064, 0.020574518]\n",
            "Batch:17\n",
            "d_loss:0.9669283032417297\n",
            "g_loss:[0.62382525, 0.57163525, 0.026094992]\n",
            "Batch:18\n",
            "d_loss:0.8408798724412918\n",
            "g_loss:[0.81509674, 0.7763002, 0.019398257]\n",
            "Batch:19\n",
            "d_loss:0.8852608650922775\n",
            "g_loss:[0.65646875, 0.6092895, 0.023589611]\n",
            "Batch:20\n",
            "d_loss:0.9994152337312698\n",
            "g_loss:[0.5891952, 0.55907005, 0.015062559]\n",
            "Batch:21\n",
            "d_loss:0.8211046457290649\n",
            "g_loss:[0.5046584, 0.48320872, 0.01072484]\n",
            "Batch:22\n",
            "d_loss:0.8939116299152374\n",
            "g_loss:[0.5042437, 0.4865695, 0.008837101]\n",
            "Batch:23\n",
            "d_loss:0.6877654790878296\n",
            "g_loss:[0.46473578, 0.45072916, 0.0070033073]\n",
            "Batch:24\n",
            "d_loss:0.8320172131061554\n",
            "g_loss:[0.9676899, 0.9519254, 0.007882225]\n",
            "Batch:25\n",
            "d_loss:0.7779417037963867\n",
            "g_loss:[0.9520717, 0.93590343, 0.008084134]\n",
            "Batch:26\n",
            "d_loss:0.8204535841941833\n",
            "g_loss:[0.7622657, 0.7474274, 0.0074191536]\n",
            "Batch:27\n",
            "d_loss:0.7525258362293243\n",
            "g_loss:[0.61710334, 0.600755, 0.0081741735]\n",
            "Batch:28\n",
            "d_loss:0.8071577250957489\n",
            "g_loss:[0.5067128, 0.48814896, 0.0092819305]\n",
            "Batch:29\n",
            "d_loss:0.7840268313884735\n",
            "g_loss:[0.97188085, 0.95153797, 0.010171445]\n",
            "Batch:30\n",
            "d_loss:0.8045934587717056\n",
            "g_loss:[0.94604677, 0.9255226, 0.01026207]\n",
            "Batch:31\n",
            "d_loss:0.8405639082193375\n",
            "g_loss:[0.6869663, 0.66855097, 0.009207676]\n",
            "Batch:32\n",
            "d_loss:0.7810368537902832\n",
            "g_loss:[0.9361806, 0.9171988, 0.009490908]\n",
            "Batch:33\n",
            "d_loss:0.7777201682329178\n",
            "g_loss:[0.8456862, 0.8350176, 0.005334294]\n",
            "Batch:34\n",
            "d_loss:0.7619241774082184\n",
            "g_loss:[0.66238767, 0.6540414, 0.004173139]\n",
            "Batch:35\n",
            "d_loss:0.6875228583812714\n",
            "g_loss:[0.7756358, 0.7676854, 0.003975173]\n",
            "Batch:36\n",
            "d_loss:0.7625752240419388\n",
            "g_loss:[0.6591196, 0.64739007, 0.0058647622]\n",
            "Batch:37\n",
            "d_loss:0.7696927487850189\n",
            "g_loss:[0.70255107, 0.68947685, 0.0065371078]\n",
            "Batch:38\n",
            "d_loss:0.7954098880290985\n",
            "g_loss:[0.7183055, 0.70991087, 0.004197342]\n",
            "Batch:39\n",
            "d_loss:0.7583268880844116\n",
            "g_loss:[0.648673, 0.6422792, 0.0031968965]\n",
            "Batch:40\n",
            "d_loss:0.8634463846683502\n",
            "g_loss:[0.70584726, 0.6960505, 0.0048983805]\n",
            "Batch:41\n",
            "d_loss:0.7997146546840668\n",
            "g_loss:[0.9871322, 0.97508705, 0.0060225856]\n",
            "Batch:42\n",
            "d_loss:0.9053540229797363\n",
            "g_loss:[0.7332458, 0.71960956, 0.006818121]\n",
            "Batch:43\n",
            "d_loss:0.7989637851715088\n",
            "g_loss:[0.7806641, 0.7694092, 0.0056274654]\n",
            "Batch:44\n",
            "d_loss:0.816664308309555\n",
            "g_loss:[1.0088655, 0.997263, 0.00580125]\n",
            "Batch:45\n",
            "d_loss:0.7154421806335449\n",
            "g_loss:[0.91809773, 0.909239, 0.004429378]\n",
            "Batch:46\n",
            "d_loss:0.737987145781517\n",
            "g_loss:[0.6126606, 0.60398275, 0.004338914]\n",
            "Batch:47\n",
            "d_loss:0.6593180596828461\n",
            "g_loss:[0.5452478, 0.5350379, 0.0051049576]\n",
            "Batch:48\n",
            "d_loss:0.6836332082748413\n",
            "g_loss:[0.6660013, 0.65683293, 0.0045841923]\n",
            "Batch:49\n",
            "d_loss:0.808655396103859\n",
            "g_loss:[0.6773291, 0.6692466, 0.0040412447]\n",
            "Batch:50\n",
            "d_loss:0.7379954904317856\n",
            "g_loss:[0.88231176, 0.8731191, 0.0045963274]\n",
            "Batch:51\n",
            "d_loss:0.744345635175705\n",
            "g_loss:[0.64428115, 0.6334214, 0.005429858]\n",
            "Batch:52\n",
            "d_loss:0.7167359590530396\n",
            "g_loss:[0.6714265, 0.66201913, 0.004703681]\n",
            "Batch:53\n",
            "d_loss:0.8114595860242844\n",
            "g_loss:[0.8417918, 0.83217597, 0.0048079127]\n",
            "Batch:54\n",
            "d_loss:0.8426356464624405\n",
            "g_loss:[0.7428855, 0.7334211, 0.004732199]\n",
            "Batch:55\n",
            "d_loss:0.6682779341936111\n",
            "g_loss:[0.6708231, 0.6557562, 0.007533452]\n",
            "Batch:56\n",
            "d_loss:0.7291327714920044\n",
            "g_loss:[0.64027494, 0.62972957, 0.0052727]\n",
            "Batch:57\n",
            "d_loss:0.6766633093357086\n",
            "g_loss:[0.5956825, 0.58721465, 0.0042339326]\n",
            "Batch:58\n",
            "d_loss:0.6894539147615433\n",
            "g_loss:[0.74666536, 0.7384794, 0.0040929834]\n",
            "Batch:59\n",
            "d_loss:0.7278250902891159\n",
            "g_loss:[0.77468413, 0.7660061, 0.004339018]\n",
            "Batch:60\n",
            "d_loss:0.7035543620586395\n",
            "g_loss:[0.7265019, 0.71927816, 0.0036118587]\n",
            "Batch:61\n",
            "d_loss:0.6607178449630737\n",
            "g_loss:[0.67251086, 0.6662426, 0.0031341354]\n",
            "Batch:62\n",
            "d_loss:0.6665493994951248\n",
            "g_loss:[0.82028204, 0.8094332, 0.005424396]\n",
            "Batch:63\n",
            "d_loss:0.6723558157682419\n",
            "g_loss:[0.5675219, 0.5564499, 0.0055360347]\n",
            "Batch:64\n",
            "d_loss:0.7238983362913132\n",
            "g_loss:[0.6085657, 0.6001198, 0.004222917]\n",
            "Batch:65\n",
            "d_loss:0.7204402387142181\n",
            "g_loss:[0.75791174, 0.74767613, 0.005117811]\n",
            "Batch:66\n",
            "d_loss:0.6972768157720566\n",
            "g_loss:[1.4395092, 1.4333797, 0.0030647675]\n",
            "Batch:67\n",
            "d_loss:1.0499612987041473\n",
            "g_loss:[0.9655075, 0.95843726, 0.0035351112]\n",
            "Batch:68\n",
            "d_loss:0.8585548400878906\n",
            "g_loss:[1.0561855, 1.0505198, 0.0028328267]\n",
            "Batch:69\n",
            "d_loss:0.7804955840110779\n",
            "g_loss:[0.74993086, 0.7440047, 0.0029630729]\n",
            "Batch:70\n",
            "d_loss:0.8643445372581482\n",
            "g_loss:[0.7236305, 0.7177916, 0.002919421]\n",
            "Batch:71\n",
            "d_loss:0.7160488665103912\n",
            "g_loss:[0.5926581, 0.58568215, 0.00348796]\n",
            "Batch:72\n",
            "d_loss:0.7291054129600525\n",
            "g_loss:[0.65604115, 0.6466923, 0.004674427]\n",
            "Batch:73\n",
            "d_loss:0.7617752701044083\n",
            "g_loss:[0.73103213, 0.7227504, 0.0041408665]\n",
            "Batch:74\n",
            "d_loss:0.7067463099956512\n",
            "g_loss:[0.91145146, 0.90275747, 0.0043470114]\n",
            "Batch:75\n",
            "d_loss:0.7526067495346069\n",
            "g_loss:[0.7189737, 0.70875573, 0.005108974]\n",
            "Batch:76\n",
            "d_loss:0.9491799771785736\n",
            "g_loss:[0.7116941, 0.70376813, 0.003963006]\n",
            "Batch:77\n",
            "d_loss:0.7295573353767395\n",
            "g_loss:[0.8633107, 0.8564588, 0.0034259674]\n",
            "Batch:78\n",
            "d_loss:0.7685094922780991\n",
            "g_loss:[1.0183121, 1.0120094, 0.0031513546]\n",
            "Batch:79\n",
            "d_loss:0.7183106541633606\n",
            "g_loss:[0.9573354, 0.9505696, 0.0033829042]\n",
            "Batch:80\n",
            "d_loss:0.7445646971464157\n",
            "g_loss:[0.65135515, 0.64503014, 0.0031625]\n",
            "Batch:81\n",
            "d_loss:0.6730375736951828\n",
            "g_loss:[0.59599805, 0.5890249, 0.0034865811]\n",
            "Batch:82\n",
            "d_loss:0.6933098435401917\n",
            "g_loss:[0.849915, 0.84539855, 0.0022582305]\n",
            "Batch:83\n",
            "d_loss:0.6925182044506073\n",
            "g_loss:[0.61765563, 0.61244977, 0.0026029455]\n",
            "Batch:84\n",
            "d_loss:0.6740871071815491\n",
            "g_loss:[0.59457517, 0.58869004, 0.0029425605]\n",
            "Batch:85\n",
            "d_loss:0.6445205211639404\n",
            "g_loss:[0.56978726, 0.5630996, 0.003343827]\n",
            "Batch:86\n",
            "d_loss:0.7256101369857788\n",
            "g_loss:[0.8005157, 0.79163665, 0.004439531]\n",
            "Batch:87\n",
            "d_loss:0.6964244991540909\n",
            "g_loss:[0.73962593, 0.7344523, 0.0025868146]\n",
            "Batch:88\n",
            "d_loss:0.6862363964319229\n",
            "g_loss:[0.62292504, 0.6175813, 0.002671854]\n",
            "Batch:89\n",
            "d_loss:0.6068958640098572\n",
            "g_loss:[0.6310251, 0.62628984, 0.0023676157]\n",
            "Batch:90\n",
            "d_loss:0.7998002469539642\n",
            "g_loss:[0.6742104, 0.66779196, 0.003209232]\n",
            "Batch:91\n",
            "d_loss:0.6803072243928909\n",
            "g_loss:[0.6041366, 0.59871554, 0.0027105217]\n",
            "Batch:92\n",
            "d_loss:0.6337234824895859\n",
            "g_loss:[0.52182806, 0.5173411, 0.0022434928]\n",
            "Batch:93\n",
            "d_loss:0.6256131678819656\n",
            "g_loss:[0.61015224, 0.60613453, 0.0020088519]\n",
            "Batch:94\n",
            "d_loss:0.6791030019521713\n",
            "g_loss:[0.5316934, 0.52358246, 0.004055466]\n",
            "Batch:95\n",
            "d_loss:0.6962505280971527\n",
            "g_loss:[0.5256895, 0.5196049, 0.0030422753]\n",
            "Batch:96\n",
            "d_loss:0.6627389341592789\n",
            "g_loss:[0.5955189, 0.59065056, 0.0024341515]\n",
            "Batch:97\n",
            "d_loss:0.5919871479272842\n",
            "g_loss:[0.5656162, 0.5604501, 0.0025830604]\n",
            "Batch:98\n",
            "d_loss:0.7263398915529251\n",
            "g_loss:[0.5808117, 0.5740884, 0.0033616489]\n",
            "Batch:99\n",
            "d_loss:0.6146381348371506\n",
            "g_loss:[0.5099691, 0.5050581, 0.0024554883]\n",
            "Batch:100\n",
            "d_loss:0.6486435532569885\n",
            "g_loss:[0.5149339, 0.5103495, 0.0022921762]\n",
            "Batch:101\n",
            "d_loss:0.6080252975225449\n",
            "g_loss:[0.52689666, 0.5223706, 0.0022630247]\n",
            "Batch:102\n",
            "d_loss:0.6309199929237366\n",
            "g_loss:[0.5022496, 0.49730146, 0.0024740759]\n",
            "Batch:103\n",
            "d_loss:0.6160796284675598\n",
            "g_loss:[0.45484802, 0.45103472, 0.0019066464]\n",
            "Batch:104\n",
            "d_loss:0.6130076795816422\n",
            "g_loss:[0.40902114, 0.40623236, 0.0013943963]\n",
            "Batch:105\n",
            "d_loss:0.6179190129041672\n",
            "g_loss:[0.43012744, 0.42591083, 0.0021083131]\n",
            "Batch:106\n",
            "d_loss:0.6601891219615936\n",
            "g_loss:[0.42164278, 0.41753453, 0.0020541176]\n",
            "Batch:107\n",
            "d_loss:0.6074007004499435\n",
            "g_loss:[0.44761768, 0.44338766, 0.0021150168]\n",
            "Batch:108\n",
            "d_loss:0.6047530621290207\n",
            "g_loss:[0.47476092, 0.47103435, 0.0018632833]\n",
            "Batch:109\n",
            "d_loss:0.6345655024051666\n",
            "g_loss:[0.6260341, 0.6215274, 0.0022533627]\n",
            "Batch:110\n",
            "d_loss:0.6369265466928482\n",
            "g_loss:[0.6003034, 0.5963437, 0.0019798616]\n",
            "Batch:111\n",
            "d_loss:0.6726894676685333\n",
            "g_loss:[0.51419127, 0.50920945, 0.002490906]\n",
            "Batch:112\n",
            "d_loss:0.6616803258657455\n",
            "g_loss:[0.5952899, 0.5892339, 0.00302802]\n",
            "Batch:113\n",
            "d_loss:0.6630369275808334\n",
            "g_loss:[0.54995364, 0.54203, 0.0039618337]\n",
            "Batch:114\n",
            "d_loss:0.6067763417959213\n",
            "g_loss:[0.5235336, 0.518685, 0.0024243048]\n",
            "Batch:115\n",
            "d_loss:0.6143660694360733\n",
            "g_loss:[0.5476215, 0.5432431, 0.0021891852]\n",
            "Batch:116\n",
            "d_loss:0.6135024577379227\n",
            "g_loss:[0.48427108, 0.48055923, 0.0018559243]\n",
            "Batch:117\n",
            "d_loss:0.648962065577507\n",
            "g_loss:[0.44414032, 0.44066322, 0.0017385494]\n",
            "Batch:118\n",
            "d_loss:0.6071975082159042\n",
            "g_loss:[0.5149403, 0.5101522, 0.0023940369]\n",
            "Batch:119\n",
            "d_loss:0.6433053910732269\n",
            "g_loss:[0.60022634, 0.5958645, 0.002180941]\n",
            "Batch:120\n",
            "d_loss:0.6163141578435898\n",
            "g_loss:[0.42861405, 0.4244941, 0.002059982]\n",
            "Batch:121\n",
            "d_loss:0.681668683886528\n",
            "g_loss:[0.37993, 0.37636387, 0.0017830557]\n",
            "Batch:122\n",
            "d_loss:0.6282525509595871\n",
            "g_loss:[0.3489828, 0.34587926, 0.0015517717]\n",
            "Batch:123\n",
            "d_loss:0.6235258430242538\n",
            "g_loss:[0.37037852, 0.36744824, 0.0014651475]\n",
            "Batch:124\n",
            "d_loss:0.5762010961771011\n",
            "g_loss:[0.37054035, 0.3673622, 0.0015890737]\n",
            "Batch:125\n",
            "d_loss:0.6293620467185974\n",
            "g_loss:[0.4280696, 0.4240343, 0.0020176445]\n",
            "Batch:126\n",
            "d_loss:0.6361995041370392\n",
            "g_loss:[0.4168352, 0.41314825, 0.0018434746]\n",
            "Batch:127\n",
            "d_loss:0.5887305289506912\n",
            "g_loss:[0.410646, 0.4067715, 0.001937244]\n",
            "Batch:128\n",
            "d_loss:0.5822703391313553\n",
            "g_loss:[0.4730777, 0.46888882, 0.0020944462]\n",
            "Batch:129\n",
            "d_loss:0.6704688370227814\n",
            "g_loss:[0.620205, 0.6152665, 0.002469228]\n",
            "Batch:130\n",
            "d_loss:0.6229348927736282\n",
            "g_loss:[0.47299114, 0.46881953, 0.002085803]\n",
            "Batch:131\n",
            "d_loss:0.6154400855302811\n",
            "g_loss:[0.50951916, 0.5059966, 0.0017612886]\n",
            "Batch:132\n",
            "d_loss:0.6362610459327698\n",
            "g_loss:[0.47401172, 0.47146338, 0.0012741662]\n",
            "Batch:133\n",
            "d_loss:0.6338628679513931\n",
            "g_loss:[0.39572033, 0.3919103, 0.0019050034]\n",
            "Batch:134\n",
            "d_loss:0.6327667385339737\n",
            "g_loss:[0.39853597, 0.39507103, 0.0017324621]\n",
            "Batch:135\n",
            "d_loss:0.6203567385673523\n",
            "g_loss:[0.3751619, 0.37191957, 0.0016211517]\n",
            "Batch:136\n",
            "d_loss:0.6147710978984833\n",
            "g_loss:[0.3763464, 0.37377882, 0.001283796]\n",
            "Batch:137\n",
            "d_loss:0.5926670730113983\n",
            "g_loss:[0.49840742, 0.49525553, 0.0015759496]\n",
            "Batch:138\n",
            "d_loss:0.646914541721344\n",
            "g_loss:[0.5596611, 0.55708337, 0.0012888627]\n",
            "Batch:139\n",
            "d_loss:0.6049643605947495\n",
            "g_loss:[0.5091051, 0.50685793, 0.0011235692]\n",
            "Batch:140\n",
            "d_loss:0.6402968466281891\n",
            "g_loss:[0.45709148, 0.4536571, 0.0017171926]\n",
            "Batch:141\n",
            "d_loss:0.6587409973144531\n",
            "g_loss:[0.42522103, 0.42073965, 0.002240686]\n",
            "Batch:142\n",
            "d_loss:0.6149200946092606\n",
            "g_loss:[0.9229031, 0.92010677, 0.0013981732]\n",
            "Batch:143\n",
            "d_loss:0.7043546289205551\n",
            "g_loss:[0.58319837, 0.5802223, 0.0014880376]\n",
            "Batch:144\n",
            "d_loss:0.6834360510110855\n",
            "g_loss:[0.7980166, 0.7951163, 0.0014501475]\n",
            "Batch:145\n",
            "d_loss:0.6312067359685898\n",
            "g_loss:[0.68286544, 0.67978036, 0.0015425432]\n",
            "Batch:146\n",
            "d_loss:0.7037493884563446\n",
            "g_loss:[0.76908875, 0.76559275, 0.0017480071]\n",
            "Batch:147\n",
            "d_loss:0.6530595123767853\n",
            "g_loss:[0.6156415, 0.6128283, 0.0014065823]\n",
            "Batch:148\n",
            "d_loss:0.6339153349399567\n",
            "g_loss:[0.524448, 0.5218068, 0.0013205928]\n",
            "Batch:149\n",
            "d_loss:0.658379465341568\n",
            "g_loss:[0.48026922, 0.4771456, 0.0015618097]\n",
            "Batch:150\n",
            "d_loss:0.6297437250614166\n",
            "g_loss:[0.489339, 0.48629332, 0.0015228458]\n",
            "Batch:151\n",
            "d_loss:0.6590822339057922\n",
            "g_loss:[0.4027378, 0.39972654, 0.001505628]\n",
            "Batch:152\n",
            "d_loss:0.6257000267505646\n",
            "g_loss:[0.49391696, 0.4901492, 0.0018838723]\n",
            "Batch:153\n",
            "d_loss:0.6158193051815033\n",
            "g_loss:[0.4309231, 0.42835832, 0.0012823967]\n",
            "Batch:154\n",
            "d_loss:0.6135570704936981\n",
            "g_loss:[0.42362738, 0.42111716, 0.0012551139]\n",
            "Batch:155\n",
            "d_loss:0.6146147847175598\n",
            "g_loss:[0.36318412, 0.3601523, 0.0015159047]\n",
            "Batch:156\n",
            "d_loss:0.6220976114273071\n",
            "g_loss:[0.39067945, 0.38759685, 0.0015412982]\n",
            "Batch:157\n",
            "d_loss:0.5929941087961197\n",
            "g_loss:[0.36973745, 0.36703816, 0.001349638]\n",
            "Batch:158\n",
            "d_loss:0.5991522818803787\n",
            "g_loss:[0.3766815, 0.37389702, 0.0013922483]\n",
            "Batch:159\n",
            "d_loss:0.595739558339119\n",
            "g_loss:[0.37552583, 0.37283373, 0.0013460455]\n",
            "Batch:160\n",
            "d_loss:0.6255738586187363\n",
            "g_loss:[0.40814722, 0.4054348, 0.001356221]\n",
            "Batch:161\n",
            "d_loss:0.5961271524429321\n",
            "g_loss:[0.413685, 0.41045445, 0.0016152692]\n",
            "Batch:162\n",
            "d_loss:0.5950983017683029\n",
            "g_loss:[0.37922278, 0.3767205, 0.0012511414]\n",
            "Batch:163\n",
            "d_loss:0.6672172397375107\n",
            "g_loss:[0.39476997, 0.39200285, 0.0013835625]\n",
            "Batch:164\n",
            "d_loss:0.6147377043962479\n",
            "g_loss:[0.4340698, 0.4312331, 0.0014183448]\n",
            "Batch:165\n",
            "d_loss:0.6026540696620941\n",
            "g_loss:[0.42331442, 0.42037064, 0.0014718989]\n",
            "Batch:166\n",
            "d_loss:0.6003260016441345\n",
            "g_loss:[0.40885714, 0.4064872, 0.0011849733]\n",
            "Batch:167\n",
            "d_loss:0.6114680618047714\n",
            "g_loss:[0.45552954, 0.45256227, 0.0014836335]\n",
            "Batch:168\n",
            "d_loss:0.5786880701780319\n",
            "g_loss:[0.35678315, 0.3540504, 0.0013663835]\n",
            "Batch:169\n",
            "d_loss:0.6048684567213058\n",
            "g_loss:[0.38859174, 0.38532203, 0.0016348518]\n",
            "Batch:170\n",
            "d_loss:0.584465354681015\n",
            "g_loss:[0.38615426, 0.38364217, 0.0012560518]\n",
            "Batch:171\n",
            "d_loss:0.5861407369375229\n",
            "g_loss:[0.39533234, 0.3929876, 0.0011723593]\n",
            "Batch:172\n",
            "d_loss:0.5990224629640579\n",
            "g_loss:[0.36542392, 0.36304784, 0.0011880326]\n",
            "Batch:173\n",
            "d_loss:0.6052536964416504\n",
            "g_loss:[0.35806924, 0.3551195, 0.0014748792]\n",
            "Batch:174\n",
            "d_loss:0.5831787884235382\n",
            "g_loss:[0.34750125, 0.34435415, 0.0015735477]\n",
            "Batch:175\n",
            "d_loss:0.7049685120582581\n",
            "g_loss:[0.3689671, 0.3655636, 0.001701737]\n",
            "Batch:176\n",
            "d_loss:0.6463851481676102\n",
            "g_loss:[0.38351476, 0.38006788, 0.0017234347]\n",
            "Batch:177\n",
            "d_loss:0.5937376022338867\n",
            "g_loss:[0.4356857, 0.430043, 0.0028213419]\n",
            "Batch:178\n",
            "d_loss:0.6055122166872025\n",
            "g_loss:[0.4019971, 0.39705953, 0.0024687795]\n",
            "Batch:179\n",
            "d_loss:0.619931772351265\n",
            "g_loss:[0.39601588, 0.3924936, 0.0017611439]\n",
            "Batch:180\n",
            "d_loss:0.6031235307455063\n",
            "g_loss:[0.35697213, 0.35378426, 0.0015939362]\n",
            "Batch:181\n",
            "d_loss:0.6108386814594269\n",
            "g_loss:[0.33939686, 0.3360791, 0.0016588919]\n",
            "Batch:182\n",
            "d_loss:0.619927242398262\n",
            "g_loss:[0.34083936, 0.33815596, 0.0013417028]\n",
            "Batch:183\n",
            "d_loss:0.5979011654853821\n",
            "g_loss:[0.36476523, 0.3600893, 0.0023379656]\n",
            "Batch:184\n",
            "d_loss:0.6378704905509949\n",
            "g_loss:[0.36504644, 0.36128652, 0.0018799645]\n",
            "Batch:185\n",
            "d_loss:0.5924763083457947\n",
            "g_loss:[0.34820607, 0.3445481, 0.0018289895]\n",
            "Batch:186\n",
            "d_loss:0.6336512416601181\n",
            "g_loss:[0.34137887, 0.3378808, 0.0017490396]\n",
            "Batch:187\n",
            "d_loss:0.5845788717269897\n",
            "g_loss:[0.3538771, 0.34857747, 0.0026498095]\n",
            "Batch:188\n",
            "d_loss:0.6347007155418396\n",
            "g_loss:[0.35121822, 0.34794235, 0.0016379391]\n",
            "Batch:189\n",
            "d_loss:0.595073476433754\n",
            "g_loss:[0.3479997, 0.34493884, 0.0015304289]\n",
            "Batch:190\n",
            "d_loss:0.5828260183334351\n",
            "g_loss:[0.35298365, 0.34992325, 0.0015301973]\n",
            "Batch:191\n",
            "d_loss:0.6170908361673355\n",
            "g_loss:[0.42369565, 0.41984385, 0.0019259036]\n",
            "Batch:192\n",
            "d_loss:0.5709570348262787\n",
            "g_loss:[0.42746058, 0.42425185, 0.0016043596]\n",
            "Batch:193\n",
            "d_loss:0.5985329896211624\n",
            "g_loss:[0.41489482, 0.4112238, 0.0018355164]\n",
            "Batch:194\n",
            "d_loss:0.6107874810695648\n",
            "g_loss:[0.3874463, 0.38453934, 0.0014534937]\n",
            "Batch:195\n",
            "d_loss:0.5867189466953278\n",
            "g_loss:[0.36958277, 0.36621624, 0.0016832659]\n",
            "Batch:196\n",
            "d_loss:0.6147062182426453\n",
            "g_loss:[0.34721774, 0.3440758, 0.0015709752]\n",
            "Batch:197\n",
            "d_loss:0.5647597908973694\n",
            "g_loss:[0.33415967, 0.33089668, 0.0016314915]\n",
            "Batch:198\n",
            "d_loss:0.5858855694532394\n",
            "g_loss:[0.3480284, 0.34425864, 0.0018848846]\n",
            "Batch:199\n",
            "d_loss:0.5793140828609467\n",
            "g_loss:[0.36227378, 0.3591262, 0.0015737906]\n",
            "Batch:200\n",
            "d_loss:0.6060401499271393\n",
            "g_loss:[0.36425477, 0.36114326, 0.0015557483]\n",
            "Batch:201\n",
            "d_loss:0.6012820899486542\n",
            "g_loss:[0.33536863, 0.33321393, 0.0010773574]\n",
            "Batch:202\n",
            "d_loss:0.5912448763847351\n",
            "g_loss:[0.33698907, 0.3347184, 0.0011353372]\n",
            "Batch:203\n",
            "d_loss:0.5852675288915634\n",
            "g_loss:[0.32822585, 0.3256042, 0.0013108193]\n",
            "Batch:204\n",
            "d_loss:0.5886546224355698\n",
            "g_loss:[0.32822737, 0.32568896, 0.0012692106]\n",
            "Batch:205\n",
            "d_loss:0.6001610606908798\n",
            "g_loss:[0.3320966, 0.3287936, 0.0016515058]\n",
            "Batch:206\n",
            "d_loss:0.588205873966217\n",
            "g_loss:[0.3279327, 0.32546142, 0.0012356295]\n",
            "Batch:207\n",
            "d_loss:0.6542976349592209\n",
            "g_loss:[0.3347027, 0.33192652, 0.0013880911]\n",
            "Batch:208\n",
            "d_loss:0.5985843539237976\n",
            "g_loss:[0.33746654, 0.33485824, 0.0013041552]\n",
            "Batch:209\n",
            "d_loss:0.5900608152151108\n",
            "g_loss:[0.32963845, 0.32766202, 0.0009882152]\n",
            "Batch:210\n",
            "d_loss:0.6453118771314621\n",
            "g_loss:[0.32855815, 0.32633722, 0.001110462]\n",
            "Batch:211\n",
            "d_loss:0.5974856615066528\n",
            "g_loss:[0.32870406, 0.32655197, 0.0010760392]\n",
            "Batch:212\n",
            "d_loss:0.5790971219539642\n",
            "g_loss:[0.3328243, 0.3301859, 0.0013191964]\n",
            "Batch:213\n",
            "d_loss:0.6044440567493439\n",
            "g_loss:[0.3320423, 0.32907826, 0.0014820221]\n",
            "Batch:214\n",
            "d_loss:0.6077655702829361\n",
            "g_loss:[0.33022183, 0.32729393, 0.0014639527]\n",
            "Batch:215\n",
            "d_loss:0.5774026960134506\n",
            "g_loss:[0.32841343, 0.32553697, 0.0014382243]\n",
            "Batch:216\n",
            "d_loss:0.6286687850952148\n",
            "g_loss:[0.33476308, 0.33247048, 0.001146307]\n",
            "Batch:217\n",
            "d_loss:0.5937155187129974\n",
            "g_loss:[0.33736214, 0.33522356, 0.0010692874]\n",
            "Batch:218\n",
            "d_loss:0.6052272170782089\n",
            "g_loss:[0.32908207, 0.3265814, 0.0012503371]\n",
            "Batch:219\n",
            "d_loss:0.5933641195297241\n",
            "g_loss:[0.332252, 0.3296821, 0.0012849408]\n",
            "Batch:220\n",
            "d_loss:0.6085944026708603\n",
            "g_loss:[0.33514905, 0.33207577, 0.0015366364]\n",
            "Batch:221\n",
            "d_loss:0.5727763772010803\n",
            "g_loss:[0.33039707, 0.3274374, 0.0014798392]\n",
            "Batch:222\n",
            "d_loss:0.6096393316984177\n",
            "g_loss:[0.33103946, 0.32760626, 0.0017165988]\n",
            "Batch:223\n",
            "d_loss:0.6288577765226364\n",
            "g_loss:[0.36488804, 0.36140785, 0.0017401009]\n",
            "Batch:224\n",
            "d_loss:0.7197518050670624\n",
            "g_loss:[0.68316656, 0.6804465, 0.0013600368]\n",
            "Batch:225\n",
            "d_loss:0.6034921258687973\n",
            "g_loss:[1.0061996, 1.0032612, 0.001469174]\n",
            "Batch:226\n",
            "d_loss:0.68777035176754\n",
            "g_loss:[0.635468, 0.6322576, 0.0016052262]\n",
            "Batch:227\n",
            "d_loss:0.6045932024717331\n",
            "g_loss:[0.6679588, 0.66483754, 0.0015606144]\n",
            "Batch:228\n",
            "d_loss:0.5832122415304184\n",
            "g_loss:[0.71144474, 0.7084894, 0.0014776585]\n",
            "Batch:229\n",
            "d_loss:0.6581960916519165\n",
            "g_loss:[0.5804729, 0.5771651, 0.0016538857]\n",
            "Batch:230\n",
            "d_loss:0.5885946452617645\n",
            "g_loss:[0.57584393, 0.5723593, 0.0017423135]\n",
            "Batch:231\n",
            "d_loss:0.6216717660427094\n",
            "g_loss:[0.4940185, 0.49113843, 0.0014400374]\n",
            "Batch:232\n",
            "d_loss:0.6262929439544678\n",
            "g_loss:[0.46195915, 0.45863014, 0.0016645006]\n",
            "Batch:233\n",
            "d_loss:0.6251257807016373\n",
            "g_loss:[0.4577425, 0.45520714, 0.0012676814]\n",
            "Batch:234\n",
            "d_loss:0.5905768871307373\n",
            "g_loss:[0.43290013, 0.43029657, 0.001301781]\n",
            "Batch:235\n",
            "d_loss:0.5820454210042953\n",
            "g_loss:[0.41100195, 0.40837467, 0.0013136452]\n",
            "Batch:236\n",
            "d_loss:0.5963672995567322\n",
            "g_loss:[0.41970143, 0.4172902, 0.0012056152]\n",
            "Batch:237\n",
            "d_loss:0.6017897129058838\n",
            "g_loss:[0.3790711, 0.37697822, 0.0010464267]\n",
            "Batch:238\n",
            "d_loss:0.5626316666603088\n",
            "g_loss:[0.38379726, 0.3816826, 0.0010573217]\n",
            "Batch:239\n",
            "d_loss:0.5895114243030548\n",
            "g_loss:[0.3813155, 0.3785081, 0.001403711]\n",
            "Batch:240\n",
            "d_loss:0.6221546977758408\n",
            "g_loss:[0.38944802, 0.3866551, 0.00139646]\n",
            "Batch:241\n",
            "d_loss:0.618122324347496\n",
            "g_loss:[0.36990967, 0.3676789, 0.0011153822]\n",
            "Batch:242\n",
            "d_loss:0.5926861613988876\n",
            "g_loss:[0.34121954, 0.3385346, 0.0013424729]\n",
            "Batch:243\n",
            "d_loss:0.600634753704071\n",
            "g_loss:[0.35654077, 0.35404474, 0.0012480116]\n",
            "Batch:244\n",
            "d_loss:0.6280283480882645\n",
            "g_loss:[0.40485486, 0.40245822, 0.0011983248]\n",
            "Batch:245\n",
            "d_loss:0.641700342297554\n",
            "g_loss:[0.39105964, 0.3886891, 0.0011852728]\n",
            "Batch:246\n",
            "d_loss:0.6558266282081604\n",
            "g_loss:[0.4565267, 0.45468047, 0.0009231176]\n",
            "Batch:247\n",
            "d_loss:0.6012881249189377\n",
            "g_loss:[0.49547923, 0.49379373, 0.00084274623]\n",
            "Batch:248\n",
            "d_loss:0.5784680247306824\n",
            "g_loss:[0.45779943, 0.45567843, 0.001060496]\n",
            "Batch:249\n",
            "d_loss:0.5766569226980209\n",
            "g_loss:[0.4390848, 0.43703598, 0.0010244083]\n",
            "Batch:250\n",
            "d_loss:0.6061461120843887\n",
            "g_loss:[0.41348043, 0.41099477, 0.0012428263]\n",
            "Batch:251\n",
            "d_loss:0.5765509307384491\n",
            "g_loss:[0.43909642, 0.43672666, 0.0011848822]\n",
            "Batch:252\n",
            "d_loss:0.5977723598480225\n",
            "g_loss:[0.41163445, 0.40893728, 0.0013485884]\n",
            "Batch:253\n",
            "d_loss:0.5717400461435318\n",
            "g_loss:[0.4064449, 0.4044767, 0.0009841042]\n",
            "Batch:254\n",
            "d_loss:0.6172211319208145\n",
            "g_loss:[0.44664782, 0.44412813, 0.0012598556]\n",
            "Batch:255\n",
            "d_loss:0.6355753540992737\n",
            "g_loss:[1.7738793, 1.7700794, 0.0018999585]\n",
            "Batch:256\n",
            "d_loss:0.6266562193632126\n",
            "g_loss:[0.7674038, 0.764207, 0.0015984003]\n",
            "Batch:257\n",
            "d_loss:0.6189178973436356\n",
            "g_loss:[0.82641757, 0.8228965, 0.001760533]\n",
            "Batch:258\n",
            "d_loss:0.6078858971595764\n",
            "g_loss:[0.7400631, 0.7368218, 0.0016206456]\n",
            "Batch:259\n",
            "d_loss:0.7154909670352936\n",
            "g_loss:[0.60637563, 0.60387874, 0.0012484354]\n",
            "Batch:260\n",
            "d_loss:0.6301146894693375\n",
            "g_loss:[0.6047984, 0.60275495, 0.0010217003]\n",
            "Batch:261\n",
            "d_loss:0.6573401987552643\n",
            "g_loss:[0.62864566, 0.6255176, 0.0015640183]\n",
            "Batch:262\n",
            "d_loss:0.6513374745845795\n",
            "g_loss:[0.50524807, 0.50256914, 0.0013394746]\n",
            "Batch:263\n",
            "d_loss:0.5798941552639008\n",
            "g_loss:[0.44715893, 0.44478446, 0.0011872301]\n",
            "Batch:264\n",
            "d_loss:0.6136486530303955\n",
            "g_loss:[0.39886674, 0.39692503, 0.00097085]\n",
            "Batch:265\n",
            "d_loss:0.5871843248605728\n",
            "g_loss:[0.39398178, 0.39223433, 0.0008737361]\n",
            "Batch:266\n",
            "d_loss:0.586180105805397\n",
            "g_loss:[0.39927813, 0.39758545, 0.0008463457]\n",
            "Batch:267\n",
            "d_loss:0.6368371397256851\n",
            "g_loss:[0.38916835, 0.3869285, 0.0011199218]\n",
            "Batch:268\n",
            "d_loss:0.5780500322580338\n",
            "g_loss:[0.44166973, 0.4396065, 0.0010316193]\n",
            "Batch:269\n",
            "d_loss:0.6433182507753372\n",
            "g_loss:[0.39576244, 0.3938141, 0.0009741727]\n",
            "Batch:270\n",
            "d_loss:0.623724177479744\n",
            "g_loss:[0.44296676, 0.44137046, 0.0007981448]\n",
            "Batch:271\n",
            "d_loss:0.605935126543045\n",
            "g_loss:[0.38865706, 0.3868322, 0.00091242767]\n",
            "Batch:272\n",
            "d_loss:0.5675824731588364\n",
            "g_loss:[0.4265154, 0.42478296, 0.0008662126]\n",
            "Batch:273\n",
            "d_loss:0.5856224894523621\n",
            "g_loss:[0.40837052, 0.40681976, 0.00077538716]\n",
            "Batch:274\n",
            "d_loss:0.6015458106994629\n",
            "g_loss:[0.3885886, 0.38702172, 0.0007834445]\n",
            "Batch:275\n",
            "d_loss:0.5835834592580795\n",
            "g_loss:[0.60472625, 0.60284287, 0.00094170356]\n",
            "Batch:276\n",
            "d_loss:0.5774272382259369\n",
            "g_loss:[0.67897046, 0.67670643, 0.0011320093]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "========================================\n",
            "Epoch is: 1\n",
            "Number of batches:276\n",
            "Batch:1\n",
            "d_loss:0.6175088286399841\n",
            "g_loss:[0.5677689, 0.5657479, 0.0010104828]\n",
            "Batch:2\n",
            "d_loss:0.597389355301857\n",
            "g_loss:[0.57464445, 0.5728607, 0.0008918596]\n",
            "Batch:3\n",
            "d_loss:0.5959897190332413\n",
            "g_loss:[0.92648304, 0.9244367, 0.0010231638]\n",
            "Batch:4\n",
            "d_loss:0.6421452909708023\n",
            "g_loss:[0.7609241, 0.758953, 0.0009855626]\n",
            "Batch:5\n",
            "d_loss:0.609962522983551\n",
            "g_loss:[0.68459696, 0.6823068, 0.0011450676]\n",
            "Batch:6\n",
            "d_loss:0.6181892305612564\n",
            "g_loss:[0.777894, 0.77548265, 0.0012056939]\n",
            "Batch:7\n",
            "d_loss:0.6077036708593369\n",
            "g_loss:[0.49874255, 0.496577, 0.001082785]\n",
            "Batch:8\n",
            "d_loss:0.6057113856077194\n",
            "g_loss:[0.38926503, 0.38659996, 0.0013325338]\n",
            "Batch:9\n",
            "d_loss:0.5895897895097733\n",
            "g_loss:[0.36020213, 0.35807532, 0.0010634058]\n",
            "Batch:10\n",
            "d_loss:0.596367210149765\n",
            "g_loss:[0.37687403, 0.37517488, 0.00084956916]\n",
            "Batch:11\n",
            "d_loss:0.5949705392122269\n",
            "g_loss:[0.45880166, 0.4567329, 0.0010343842]\n",
            "Batch:12\n",
            "d_loss:0.5981469750404358\n",
            "g_loss:[0.4334257, 0.43140775, 0.0010089761]\n",
            "Batch:13\n",
            "d_loss:0.5879278928041458\n",
            "g_loss:[0.40273082, 0.40073243, 0.0009992009]\n",
            "Batch:14\n",
            "d_loss:0.58681221306324\n",
            "g_loss:[0.39265928, 0.3907951, 0.0009320843]\n",
            "Batch:15\n",
            "d_loss:0.6130683422088623\n",
            "g_loss:[0.40240505, 0.3989731, 0.0017159666]\n",
            "Batch:16\n",
            "d_loss:0.5764576196670532\n",
            "g_loss:[0.37830174, 0.37493917, 0.0016812906]\n",
            "Batch:17\n",
            "d_loss:0.7328910529613495\n",
            "g_loss:[0.43337172, 0.42926988, 0.0020509185]\n",
            "Batch:18\n",
            "d_loss:0.5799111425876617\n",
            "g_loss:[0.4118596, 0.4084593, 0.0017001503]\n",
            "Batch:19\n",
            "d_loss:0.6169950366020203\n",
            "g_loss:[0.422896, 0.41918898, 0.0018535081]\n",
            "Batch:20\n",
            "d_loss:0.665542334318161\n",
            "g_loss:[0.371481, 0.36894387, 0.00126857]\n",
            "Batch:21\n",
            "d_loss:0.6029980480670929\n",
            "g_loss:[0.35145256, 0.34922862, 0.0011119745]\n",
            "Batch:22\n",
            "d_loss:0.6337411403656006\n",
            "g_loss:[0.34191048, 0.34037647, 0.0007670117]\n",
            "Batch:23\n",
            "d_loss:0.5738752484321594\n",
            "g_loss:[0.3395777, 0.33808976, 0.000743964]\n",
            "Batch:24\n",
            "d_loss:0.6104944348335266\n",
            "g_loss:[0.34744382, 0.3456753, 0.0008842692]\n",
            "Batch:25\n",
            "d_loss:0.5784366726875305\n",
            "g_loss:[0.37323862, 0.37117225, 0.0010331859]\n",
            "Batch:26\n",
            "d_loss:0.6010301262140274\n",
            "g_loss:[0.37370712, 0.3718217, 0.0009427036]\n",
            "Batch:27\n",
            "d_loss:0.5970428138971329\n",
            "g_loss:[0.36776, 0.36595297, 0.0009035243]\n",
            "Batch:28\n",
            "d_loss:0.6261243671178818\n",
            "g_loss:[0.34668034, 0.3449597, 0.000860315]\n",
            "Batch:29\n",
            "d_loss:0.5771058946847916\n",
            "g_loss:[0.35696393, 0.3543709, 0.0012965227]\n",
            "Batch:30\n",
            "d_loss:0.6040405929088593\n",
            "g_loss:[0.33558947, 0.33318573, 0.001201864]\n",
            "Batch:31\n",
            "d_loss:0.6070285886526108\n",
            "g_loss:[0.33869433, 0.33623302, 0.0012306606]\n",
            "Batch:32\n",
            "d_loss:0.5784726589918137\n",
            "g_loss:[0.3301101, 0.32759708, 0.0012565166]\n",
            "Batch:33\n",
            "d_loss:0.5757824778556824\n",
            "g_loss:[0.33046305, 0.3286824, 0.00089032203]\n",
            "Batch:34\n",
            "d_loss:0.60428386926651\n",
            "g_loss:[0.32876065, 0.32720372, 0.0007784614]\n",
            "Batch:35\n",
            "d_loss:0.5954000055789948\n",
            "g_loss:[0.33074206, 0.3293305, 0.0007057842]\n",
            "Batch:36\n",
            "d_loss:0.5923384875059128\n",
            "g_loss:[0.32805064, 0.32652926, 0.0007606866]\n",
            "Batch:37\n",
            "d_loss:0.5978789776563644\n",
            "g_loss:[0.3286839, 0.32729813, 0.0006928894]\n",
            "Batch:38\n",
            "d_loss:0.5880705118179321\n",
            "g_loss:[0.3269506, 0.3255486, 0.0007010121]\n",
            "Batch:39\n",
            "d_loss:0.5739863216876984\n",
            "g_loss:[0.32703647, 0.32564452, 0.00069597806]\n",
            "Batch:40\n",
            "d_loss:0.6130389422178268\n",
            "g_loss:[0.32799911, 0.32645106, 0.00077402225]\n",
            "Batch:41\n",
            "d_loss:0.5951025784015656\n",
            "g_loss:[0.33035314, 0.32852453, 0.0009143031]\n",
            "Batch:42\n",
            "d_loss:0.6027910113334656\n",
            "g_loss:[0.32728663, 0.325772, 0.00075731485]\n",
            "Batch:43\n",
            "d_loss:0.5679480880498886\n",
            "g_loss:[0.33699578, 0.3354559, 0.00076995016]\n",
            "Batch:44\n",
            "d_loss:0.5964916050434113\n",
            "g_loss:[0.33939, 0.33794665, 0.00072168076]\n",
            "Batch:45\n",
            "d_loss:0.5773963332176208\n",
            "g_loss:[0.33285967, 0.33135942, 0.0007501227]\n",
            "Batch:46\n",
            "d_loss:0.5928442478179932\n",
            "g_loss:[0.33200544, 0.33018973, 0.00090785907]\n",
            "Batch:47\n",
            "d_loss:0.5770964324474335\n",
            "g_loss:[0.3320827, 0.32995373, 0.0010644784]\n",
            "Batch:48\n",
            "d_loss:0.576254665851593\n",
            "g_loss:[0.32952616, 0.32746497, 0.0010305909]\n",
            "Batch:49\n",
            "d_loss:0.6020616292953491\n",
            "g_loss:[0.32839787, 0.32659703, 0.0009004121]\n",
            "Batch:50\n",
            "d_loss:0.6105892360210419\n",
            "g_loss:[0.33011156, 0.32811505, 0.000998257]\n",
            "Batch:51\n",
            "d_loss:0.5845400094985962\n",
            "g_loss:[0.33132315, 0.32955265, 0.000885252]\n",
            "Batch:52\n",
            "d_loss:0.5960542559623718\n",
            "g_loss:[0.3354285, 0.334011, 0.00070875464]\n",
            "Batch:53\n",
            "d_loss:0.5977107286453247\n",
            "g_loss:[0.36654535, 0.36490768, 0.00081883406]\n",
            "Batch:54\n",
            "d_loss:0.5933030396699905\n",
            "g_loss:[0.5970949, 0.5955124, 0.00079124025]\n",
            "Batch:55\n",
            "d_loss:0.5679346323013306\n",
            "g_loss:[0.4838615, 0.48110795, 0.001376774]\n",
            "Batch:56\n",
            "d_loss:0.5780137628316879\n",
            "g_loss:[0.38388404, 0.3817413, 0.0010713844]\n",
            "Batch:57\n",
            "d_loss:0.5961420834064484\n",
            "g_loss:[0.342185, 0.34015352, 0.001015734]\n",
            "Batch:58\n",
            "d_loss:0.6052699238061905\n",
            "g_loss:[0.35219842, 0.35020107, 0.0009986716]\n",
            "Batch:59\n",
            "d_loss:0.6040299534797668\n",
            "g_loss:[0.35096434, 0.34912002, 0.0009221604]\n",
            "Batch:60\n",
            "d_loss:0.5911895632743835\n",
            "g_loss:[0.34759158, 0.34602427, 0.0007836497]\n",
            "Batch:61\n",
            "d_loss:0.5856447368860245\n",
            "g_loss:[0.33257893, 0.33105835, 0.0007602833]\n",
            "Batch:62\n",
            "d_loss:0.574357882142067\n",
            "g_loss:[0.3321219, 0.3297632, 0.0011793495]\n",
            "Batch:63\n",
            "d_loss:0.586163654923439\n",
            "g_loss:[0.32954845, 0.32676342, 0.0013925201]\n",
            "Batch:64\n",
            "d_loss:0.5814682394266129\n",
            "g_loss:[0.3313048, 0.3291486, 0.0010781047]\n",
            "Batch:65\n",
            "d_loss:0.5907440185546875\n",
            "g_loss:[0.3334877, 0.33105558, 0.0012160576]\n",
            "Batch:66\n",
            "d_loss:0.5606687515974045\n",
            "g_loss:[0.33154294, 0.3298781, 0.0008324272]\n",
            "Batch:67\n",
            "d_loss:0.5798861682415009\n",
            "g_loss:[0.33051616, 0.32851434, 0.0010009044]\n",
            "Batch:68\n",
            "d_loss:0.5979873836040497\n",
            "g_loss:[0.3334988, 0.3318206, 0.00083909783]\n",
            "Batch:69\n",
            "d_loss:0.5859239995479584\n",
            "g_loss:[0.33277285, 0.33100012, 0.0008863686]\n",
            "Batch:70\n",
            "d_loss:0.5823931992053986\n",
            "g_loss:[0.3277632, 0.32626617, 0.00074850896]\n",
            "Batch:71\n",
            "d_loss:0.5813815146684647\n",
            "g_loss:[0.32924876, 0.3275529, 0.0008479265]\n",
            "Batch:72\n",
            "d_loss:0.5847021341323853\n",
            "g_loss:[0.33464703, 0.3326857, 0.0009806594]\n",
            "Batch:73\n",
            "d_loss:0.578403651714325\n",
            "g_loss:[0.329404, 0.32763988, 0.00088206213]\n",
            "Batch:74\n",
            "d_loss:0.5811892300844193\n",
            "g_loss:[0.33612233, 0.33421332, 0.00095450575]\n",
            "Batch:75\n",
            "d_loss:0.5882437080144882\n",
            "g_loss:[0.3296651, 0.3275444, 0.0010603524]\n",
            "Batch:76\n",
            "d_loss:0.5776064097881317\n",
            "g_loss:[0.32923257, 0.32744145, 0.00089556223]\n",
            "Batch:77\n",
            "d_loss:0.5670342445373535\n",
            "g_loss:[0.32761416, 0.32572562, 0.0009442713]\n",
            "Batch:78\n",
            "d_loss:0.5861342698335648\n",
            "g_loss:[0.3274974, 0.3258052, 0.00084609864]\n",
            "Batch:79\n",
            "d_loss:0.5763688534498215\n",
            "g_loss:[0.32781395, 0.32601357, 0.0009001903]\n",
            "Batch:80\n",
            "d_loss:0.5881303250789642\n",
            "g_loss:[0.32799825, 0.3261347, 0.00093176245]\n",
            "Batch:81\n",
            "d_loss:0.5702713578939438\n",
            "g_loss:[0.32735136, 0.3255248, 0.0009132835]\n",
            "Batch:82\n",
            "d_loss:0.6091299653053284\n",
            "g_loss:[0.33086038, 0.3295024, 0.0006789802]\n",
            "Batch:83\n",
            "d_loss:0.5777880698442459\n",
            "g_loss:[0.3271429, 0.32571146, 0.00071571104]\n",
            "Batch:84\n",
            "d_loss:0.5783711522817612\n",
            "g_loss:[0.32961276, 0.32797486, 0.0008189521]\n",
            "Batch:85\n",
            "d_loss:0.5736900568008423\n",
            "g_loss:[0.32843074, 0.32650995, 0.00096039526]\n",
            "Batch:86\n",
            "d_loss:0.5745200365781784\n",
            "g_loss:[0.32809478, 0.32563752, 0.0012286236]\n",
            "Batch:87\n",
            "d_loss:0.575311467051506\n",
            "g_loss:[0.32843187, 0.32666892, 0.0008814763]\n",
            "Batch:88\n",
            "d_loss:0.5748175382614136\n",
            "g_loss:[0.32855332, 0.32684326, 0.0008550277]\n",
            "Batch:89\n",
            "d_loss:0.5499127954244614\n",
            "g_loss:[0.32760328, 0.32601, 0.000796641]\n",
            "Batch:90\n",
            "d_loss:0.6518401801586151\n",
            "g_loss:[0.33390754, 0.3316871, 0.0011102253]\n",
            "Batch:91\n",
            "d_loss:0.6248155683279037\n",
            "g_loss:[0.372353, 0.37044826, 0.0009523685]\n",
            "Batch:92\n",
            "d_loss:0.5979880541563034\n",
            "g_loss:[0.40411288, 0.40264958, 0.00073163956]\n",
            "Batch:93\n",
            "d_loss:0.5800425559282303\n",
            "g_loss:[0.56119174, 0.5597825, 0.0007046017]\n",
            "Batch:94\n",
            "d_loss:0.6553855091333389\n",
            "g_loss:[0.5278305, 0.52544606, 0.0011922207]\n",
            "Batch:95\n",
            "d_loss:0.6116345822811127\n",
            "g_loss:[0.6265426, 0.62464106, 0.00095078023]\n",
            "Batch:96\n",
            "d_loss:0.5876205861568451\n",
            "g_loss:[0.55297625, 0.55139995, 0.0007881648]\n",
            "Batch:97\n",
            "d_loss:0.6006089746952057\n",
            "g_loss:[0.5275736, 0.5258138, 0.00087988144]\n",
            "Batch:98\n",
            "d_loss:0.5988090187311172\n",
            "g_loss:[0.53992635, 0.5375987, 0.0011638096]\n",
            "Batch:99\n",
            "d_loss:0.6083255559206009\n",
            "g_loss:[0.50028217, 0.49861807, 0.0008320365]\n",
            "Batch:100\n",
            "d_loss:0.5765092968940735\n",
            "g_loss:[0.5113227, 0.5099614, 0.0006806181]\n",
            "Batch:101\n",
            "d_loss:0.5824394822120667\n",
            "g_loss:[0.47155192, 0.46997035, 0.0007907946]\n",
            "Batch:102\n",
            "d_loss:0.5860594063997269\n",
            "g_loss:[0.495678, 0.4938498, 0.00091410155]\n",
            "Batch:103\n",
            "d_loss:0.5741673707962036\n",
            "g_loss:[0.5389491, 0.5376945, 0.0006272759]\n",
            "Batch:104\n",
            "d_loss:0.6017102599143982\n",
            "g_loss:[0.4780379, 0.47703415, 0.0005018641]\n",
            "Batch:105\n",
            "d_loss:0.5522044152021408\n",
            "g_loss:[0.43830922, 0.43670803, 0.00080059975]\n",
            "Batch:106\n",
            "d_loss:0.600986048579216\n",
            "g_loss:[0.42882723, 0.4273677, 0.00072976935]\n",
            "Batch:107\n",
            "d_loss:0.5622471123933792\n",
            "g_loss:[0.40382168, 0.40245795, 0.0006818558]\n",
            "Batch:108\n",
            "d_loss:0.579911932349205\n",
            "g_loss:[0.40643892, 0.40508318, 0.0006778687]\n",
            "Batch:109\n",
            "d_loss:0.5741358995437622\n",
            "g_loss:[0.4434096, 0.441662, 0.0008737873]\n",
            "Batch:110\n",
            "d_loss:0.6067544668912888\n",
            "g_loss:[0.4015168, 0.4001757, 0.000670552]\n",
            "Batch:111\n",
            "d_loss:0.596978560090065\n",
            "g_loss:[0.37394837, 0.3724327, 0.00075782364]\n",
            "Batch:112\n",
            "d_loss:0.6141361445188522\n",
            "g_loss:[0.36186624, 0.36015695, 0.00085463875]\n",
            "Batch:113\n",
            "d_loss:0.6044245064258575\n",
            "g_loss:[0.35318574, 0.351018, 0.001083861]\n",
            "Batch:114\n",
            "d_loss:0.5724873691797256\n",
            "g_loss:[0.34581053, 0.34427088, 0.00076981884]\n",
            "Batch:115\n",
            "d_loss:0.5843228548765182\n",
            "g_loss:[0.3929794, 0.39139915, 0.0007901284]\n",
            "Batch:116\n",
            "d_loss:0.5780023485422134\n",
            "g_loss:[0.3909276, 0.38953385, 0.00069688034]\n",
            "Batch:117\n",
            "d_loss:0.5794336795806885\n",
            "g_loss:[0.343972, 0.34273165, 0.00062016776]\n",
            "Batch:118\n",
            "d_loss:0.5944956690073013\n",
            "g_loss:[0.34050822, 0.33895707, 0.00077557913]\n",
            "Batch:119\n",
            "d_loss:0.5695745795965195\n",
            "g_loss:[0.34695536, 0.34541386, 0.0007707519]\n",
            "Batch:120\n",
            "d_loss:0.5601523965597153\n",
            "g_loss:[0.33565453, 0.33434254, 0.0006560004]\n",
            "Batch:121\n",
            "d_loss:0.5886120051145554\n",
            "g_loss:[0.33668584, 0.33550987, 0.00058798277]\n",
            "Batch:122\n",
            "d_loss:0.5724320858716965\n",
            "g_loss:[0.33656663, 0.33532503, 0.0006208042]\n",
            "Batch:123\n",
            "d_loss:0.5667973458766937\n",
            "g_loss:[0.33720607, 0.33605307, 0.00057650014]\n",
            "Batch:124\n",
            "d_loss:0.5637556165456772\n",
            "g_loss:[0.33177155, 0.33057857, 0.00059649034]\n",
            "Batch:125\n",
            "d_loss:0.5744034796953201\n",
            "g_loss:[0.32879728, 0.32727545, 0.00076091127]\n",
            "Batch:126\n",
            "d_loss:0.6190485507249832\n",
            "g_loss:[0.32827282, 0.32685518, 0.0007088125]\n",
            "Batch:127\n",
            "d_loss:0.5660339295864105\n",
            "g_loss:[0.35787457, 0.35643837, 0.0007181032]\n",
            "Batch:128\n",
            "d_loss:0.5743833631277084\n",
            "g_loss:[0.38675678, 0.38539693, 0.0006799193]\n",
            "Batch:129\n",
            "d_loss:0.6010901629924774\n",
            "g_loss:[0.41914293, 0.4174387, 0.000852125]\n",
            "Batch:130\n",
            "d_loss:0.6245546489953995\n",
            "g_loss:[1.7653332, 1.7637986, 0.000767278]\n",
            "Batch:131\n",
            "d_loss:0.6106733977794647\n",
            "g_loss:[1.9025526, 1.9013641, 0.00059426634]\n",
            "Batch:132\n",
            "d_loss:0.6613482981920242\n",
            "g_loss:[1.6048793, 1.6039077, 0.0004857673]\n",
            "Batch:133\n",
            "d_loss:0.6776304692029953\n",
            "g_loss:[1.4248466, 1.4236782, 0.00058422127]\n",
            "Batch:134\n",
            "d_loss:0.6881256848573685\n",
            "g_loss:[1.1308681, 1.129633, 0.00061758666]\n",
            "Batch:135\n",
            "d_loss:0.6532004624605179\n",
            "g_loss:[1.3653009, 1.3640475, 0.00062666246]\n",
            "Batch:136\n",
            "d_loss:0.6621595025062561\n",
            "g_loss:[1.0680175, 1.067029, 0.00049421756]\n",
            "Batch:137\n",
            "d_loss:0.6446469724178314\n",
            "g_loss:[0.87611514, 0.874882, 0.00061658554]\n",
            "Batch:138\n",
            "d_loss:0.7295823395252228\n",
            "g_loss:[1.6477399, 1.646662, 0.00053895666]\n",
            "Batch:139\n",
            "d_loss:0.6404549479484558\n",
            "g_loss:[1.1871097, 1.1861434, 0.0004831591]\n",
            "Batch:140\n",
            "d_loss:0.6289581209421158\n",
            "g_loss:[0.91846955, 0.9170969, 0.0006863257]\n",
            "Batch:141\n",
            "d_loss:0.6640059649944305\n",
            "g_loss:[0.85166496, 0.8500664, 0.0007992593]\n",
            "Batch:142\n",
            "d_loss:0.5866782963275909\n",
            "g_loss:[0.85437274, 0.85321033, 0.0005811929]\n",
            "Batch:143\n",
            "d_loss:0.6150001883506775\n",
            "g_loss:[0.7834754, 0.78223747, 0.0006189759]\n",
            "Batch:144\n",
            "d_loss:0.6610559523105621\n",
            "g_loss:[0.83211744, 0.8309959, 0.00056075375]\n",
            "Batch:145\n",
            "d_loss:0.6510539799928665\n",
            "g_loss:[0.90773886, 0.9065542, 0.000592309]\n",
            "Batch:146\n",
            "d_loss:0.6674206256866455\n",
            "g_loss:[0.9370051, 0.9357823, 0.0006113833]\n",
            "Batch:147\n",
            "d_loss:0.590298131108284\n",
            "g_loss:[0.8850105, 0.8839539, 0.0005282684]\n",
            "Batch:148\n",
            "d_loss:0.6161653995513916\n",
            "g_loss:[0.80573153, 0.8046787, 0.00052641996]\n",
            "Batch:149\n",
            "d_loss:0.6138066202402115\n",
            "g_loss:[0.81427914, 0.81312335, 0.0005778821]\n",
            "Batch:150\n",
            "d_loss:0.5852638632059097\n",
            "g_loss:[0.8261407, 0.8249464, 0.0005971379]\n",
            "Batch:151\n",
            "d_loss:0.625666081905365\n",
            "g_loss:[0.8061003, 0.80495584, 0.0005722393]\n",
            "Batch:152\n",
            "d_loss:0.5995436459779739\n",
            "g_loss:[0.81937, 0.8180618, 0.00065407983]\n",
            "Batch:153\n",
            "d_loss:0.5916813164949417\n",
            "g_loss:[0.7985201, 0.79750264, 0.000508726]\n",
            "Batch:154\n",
            "d_loss:0.5999104231595993\n",
            "g_loss:[0.7111405, 0.710145, 0.0004977632]\n",
            "Batch:155\n",
            "d_loss:0.581450566649437\n",
            "g_loss:[0.6275077, 0.62631327, 0.00059719937]\n",
            "Batch:156\n",
            "d_loss:0.5872113406658173\n",
            "g_loss:[0.46835592, 0.4671887, 0.0005836238]\n",
            "Batch:157\n",
            "d_loss:0.570441335439682\n",
            "g_loss:[0.47109172, 0.47006422, 0.0005137456]\n",
            "Batch:158\n",
            "d_loss:0.5801384150981903\n",
            "g_loss:[0.4334317, 0.432347, 0.00054235343]\n",
            "Batch:159\n",
            "d_loss:0.5686022639274597\n",
            "g_loss:[0.515523, 0.5144459, 0.00053857185]\n",
            "Batch:160\n",
            "d_loss:0.5787044912576675\n",
            "g_loss:[0.45078853, 0.44968122, 0.0005536551]\n",
            "Batch:161\n",
            "d_loss:0.5761264115571976\n",
            "g_loss:[0.40775326, 0.40653887, 0.0006071863]\n",
            "Batch:162\n",
            "d_loss:0.5705052316188812\n",
            "g_loss:[0.3991899, 0.39815027, 0.00051981583]\n",
            "Batch:163\n",
            "d_loss:0.6383521407842636\n",
            "g_loss:[0.3417102, 0.34056956, 0.0005703273]\n",
            "Batch:164\n",
            "d_loss:0.565846860408783\n",
            "g_loss:[0.3683543, 0.36723316, 0.00056056207]\n",
            "Batch:165\n",
            "d_loss:0.5659087747335434\n",
            "g_loss:[0.3782217, 0.37704408, 0.00058880786]\n",
            "Batch:166\n",
            "d_loss:0.5654347240924835\n",
            "g_loss:[0.35489643, 0.3539396, 0.0004784232]\n",
            "Batch:167\n",
            "d_loss:0.5793156772851944\n",
            "g_loss:[0.35925186, 0.3580594, 0.0005962295]\n",
            "Batch:168\n",
            "d_loss:0.55274598300457\n",
            "g_loss:[0.3306653, 0.32957828, 0.0005435011]\n",
            "Batch:169\n",
            "d_loss:0.5954243242740631\n",
            "g_loss:[0.35093758, 0.3496364, 0.000650578]\n",
            "Batch:170\n",
            "d_loss:0.568545401096344\n",
            "g_loss:[0.33935454, 0.3383264, 0.0005140738]\n",
            "Batch:171\n",
            "d_loss:0.5736586153507233\n",
            "g_loss:[0.3382599, 0.33728153, 0.00048918714]\n",
            "Batch:172\n",
            "d_loss:0.5767216980457306\n",
            "g_loss:[0.34450904, 0.34354064, 0.00048419528]\n",
            "Batch:173\n",
            "d_loss:0.5691706836223602\n",
            "g_loss:[0.37884277, 0.3775836, 0.00062959146]\n",
            "Batch:174\n",
            "d_loss:0.5746150314807892\n",
            "g_loss:[0.33447883, 0.3332904, 0.00059420627]\n",
            "Batch:175\n",
            "d_loss:0.6310200542211533\n",
            "g_loss:[0.46469316, 0.46323273, 0.0007302207]\n",
            "Batch:176\n",
            "d_loss:0.6158673465251923\n",
            "g_loss:[1.2302477, 1.2288612, 0.00069325545]\n",
            "Batch:177\n",
            "d_loss:0.5744728147983551\n",
            "g_loss:[0.6032524, 0.6013266, 0.000962918]\n",
            "Batch:178\n",
            "d_loss:0.5970248132944107\n",
            "g_loss:[0.7231953, 0.721357, 0.0009191651]\n",
            "Batch:179\n",
            "d_loss:0.5801987051963806\n",
            "g_loss:[0.6177328, 0.6163124, 0.00071020826]\n",
            "Batch:180\n",
            "d_loss:0.5729189515113831\n",
            "g_loss:[0.5763303, 0.57505864, 0.0006358341]\n",
            "Batch:181\n",
            "d_loss:0.584697812795639\n",
            "g_loss:[0.495618, 0.4942739, 0.0006720441]\n",
            "Batch:182\n",
            "d_loss:0.6115620881319046\n",
            "g_loss:[0.42562044, 0.42449534, 0.0005625506]\n",
            "Batch:183\n",
            "d_loss:0.5710841864347458\n",
            "g_loss:[0.42837638, 0.42657524, 0.0009005737]\n",
            "Batch:184\n",
            "d_loss:0.6054901629686356\n",
            "g_loss:[0.61412233, 0.6125375, 0.0007924039]\n",
            "Batch:185\n",
            "d_loss:0.5828185975551605\n",
            "g_loss:[0.7594837, 0.75798905, 0.00074731023]\n",
            "Batch:186\n",
            "d_loss:0.5939991474151611\n",
            "g_loss:[0.6694861, 0.66806626, 0.00070992997]\n",
            "Batch:187\n",
            "d_loss:0.5802073776721954\n",
            "g_loss:[0.577261, 0.5749136, 0.0011736612]\n",
            "Batch:188\n",
            "d_loss:0.6101677715778351\n",
            "g_loss:[0.64032054, 0.6387436, 0.0007884884]\n",
            "Batch:189\n",
            "d_loss:0.5742974728345871\n",
            "g_loss:[0.5556129, 0.5543144, 0.00064927]\n",
            "Batch:190\n",
            "d_loss:0.5834316462278366\n",
            "g_loss:[0.54598105, 0.5445763, 0.0007023929]\n",
            "Batch:191\n",
            "d_loss:0.5682783126831055\n",
            "g_loss:[0.48463625, 0.48284292, 0.0008966682]\n",
            "Batch:192\n",
            "d_loss:0.5638123005628586\n",
            "g_loss:[0.43723568, 0.43581337, 0.0007111633]\n",
            "Batch:193\n",
            "d_loss:0.5819448530673981\n",
            "g_loss:[0.40169582, 0.40024334, 0.0007262402]\n",
            "Batch:194\n",
            "d_loss:0.5943607985973358\n",
            "g_loss:[0.38655308, 0.38524452, 0.00065427384]\n",
            "Batch:195\n",
            "d_loss:0.5809182971715927\n",
            "g_loss:[0.38565668, 0.384202, 0.0007273376]\n",
            "Batch:196\n",
            "d_loss:0.5909688323736191\n",
            "g_loss:[0.38049737, 0.37913543, 0.0006809663]\n",
            "Batch:197\n",
            "d_loss:0.5615291446447372\n",
            "g_loss:[0.3662495, 0.3648119, 0.0007188]\n",
            "Batch:198\n",
            "d_loss:0.5698252618312836\n",
            "g_loss:[0.417965, 0.41645795, 0.00075351476]\n",
            "Batch:199\n",
            "d_loss:0.5644525438547134\n",
            "g_loss:[0.56294954, 0.5616292, 0.0006601795]\n",
            "Batch:200\n",
            "d_loss:0.5939202755689621\n",
            "g_loss:[0.4074343, 0.4060914, 0.00067145395]\n",
            "Batch:201\n",
            "d_loss:0.5726773589849472\n",
            "g_loss:[0.4125087, 0.4115736, 0.00046754983]\n",
            "Batch:202\n",
            "d_loss:0.5721792131662369\n",
            "g_loss:[0.38592997, 0.3849218, 0.00050409243]\n",
            "Batch:203\n",
            "d_loss:0.5698990374803543\n",
            "g_loss:[0.38984305, 0.38874966, 0.00054669334]\n",
            "Batch:204\n",
            "d_loss:0.5763891637325287\n",
            "g_loss:[0.38063258, 0.37965053, 0.0004910291]\n",
            "Batch:205\n",
            "d_loss:0.575851783156395\n",
            "g_loss:[0.3496065, 0.34822288, 0.0006918102]\n",
            "Batch:206\n",
            "d_loss:0.5697340816259384\n",
            "g_loss:[0.3451233, 0.34412524, 0.0004990183]\n",
            "Batch:207\n",
            "d_loss:0.6190454810857773\n",
            "g_loss:[0.5195908, 0.51843, 0.0005803882]\n",
            "Batch:208\n",
            "d_loss:0.5569082349538803\n",
            "g_loss:[0.68661886, 0.685562, 0.0005284191]\n",
            "Batch:209\n",
            "d_loss:0.5846870094537735\n",
            "g_loss:[0.63763297, 0.6368264, 0.0004032915]\n",
            "Batch:210\n",
            "d_loss:0.5958917140960693\n",
            "g_loss:[0.664073, 0.66314113, 0.00046593416]\n",
            "Batch:211\n",
            "d_loss:0.590616449713707\n",
            "g_loss:[1.0610459, 1.0601213, 0.0004622989]\n",
            "Batch:212\n",
            "d_loss:0.5773995220661163\n",
            "g_loss:[4.524904, 4.523797, 0.00055341114]\n",
            "Batch:213\n",
            "d_loss:0.6590958684682846\n",
            "g_loss:[3.3268232, 3.325574, 0.00062470743]\n",
            "Batch:214\n",
            "d_loss:1.3333399891853333\n",
            "g_loss:[1.6097385, 1.608463, 0.0006377001]\n",
            "Batch:215\n",
            "d_loss:0.6600396782159805\n",
            "g_loss:[2.0662277, 2.0646796, 0.00077406055]\n",
            "Batch:216\n",
            "d_loss:0.736492857336998\n",
            "g_loss:[1.494133, 1.4931221, 0.00050545397]\n",
            "Batch:217\n",
            "d_loss:0.6951702833175659\n",
            "g_loss:[1.3638092, 1.3628509, 0.00047917478]\n",
            "Batch:218\n",
            "d_loss:0.7234237492084503\n",
            "g_loss:[1.4159002, 1.4147966, 0.0005518215]\n",
            "Batch:219\n",
            "d_loss:0.709118202328682\n",
            "g_loss:[1.2393674, 1.2382305, 0.00056847127]\n",
            "Batch:220\n",
            "d_loss:0.7392749786376953\n",
            "g_loss:[1.1202446, 1.1185428, 0.00085089385]\n",
            "Batch:221\n",
            "d_loss:0.6591279655694962\n",
            "g_loss:[1.1826456, 1.1811359, 0.0007548357]\n",
            "Batch:222\n",
            "d_loss:0.7682653963565826\n",
            "g_loss:[1.3609259, 1.3593154, 0.0008052587]\n",
            "Batch:223\n",
            "d_loss:0.7537161260843277\n",
            "g_loss:[1.2506036, 1.248868, 0.0008678135]\n",
            "Batch:224\n",
            "d_loss:0.8941479027271271\n",
            "g_loss:[1.134035, 1.132692, 0.0006715352]\n",
            "Batch:225\n",
            "d_loss:0.6981934458017349\n",
            "g_loss:[1.5223305, 1.5209477, 0.0006914159]\n",
            "Batch:226\n",
            "d_loss:0.7556979656219482\n",
            "g_loss:[1.1688701, 1.1672993, 0.00078542554]\n",
            "Batch:227\n",
            "d_loss:0.6737941056489944\n",
            "g_loss:[1.1164284, 1.1149275, 0.0007503993]\n",
            "Batch:228\n",
            "d_loss:0.6416580379009247\n",
            "g_loss:[0.9005045, 0.8991204, 0.00069207925]\n",
            "Batch:229\n",
            "d_loss:0.6975468397140503\n",
            "g_loss:[0.8127836, 0.81118727, 0.00079815614]\n",
            "Batch:230\n",
            "d_loss:0.636675551533699\n",
            "g_loss:[0.79065967, 0.7889141, 0.00087279174]\n",
            "Batch:231\n",
            "d_loss:0.6774609535932541\n",
            "g_loss:[0.7709941, 0.7696725, 0.00066082145]\n",
            "Batch:232\n",
            "d_loss:0.6418123841285706\n",
            "g_loss:[0.7644381, 0.76289296, 0.0007725719]\n",
            "Batch:233\n",
            "d_loss:0.6396942436695099\n",
            "g_loss:[0.67381245, 0.6726202, 0.00059613626]\n",
            "Batch:234\n",
            "d_loss:0.6072259545326233\n",
            "g_loss:[0.658937, 0.6576267, 0.0006551461]\n",
            "Batch:235\n",
            "d_loss:0.6013113707304001\n",
            "g_loss:[0.6304191, 0.62916386, 0.0006276093]\n",
            "Batch:236\n",
            "d_loss:0.6149699240922928\n",
            "g_loss:[0.6125462, 0.61139417, 0.0005760235]\n",
            "Batch:237\n",
            "d_loss:0.6521463394165039\n",
            "g_loss:[0.5828861, 0.58185244, 0.0005168234]\n",
            "Batch:238\n",
            "d_loss:0.574955478310585\n",
            "g_loss:[0.5791841, 0.57814413, 0.0005199883]\n",
            "Batch:239\n",
            "d_loss:0.6075973510742188\n",
            "g_loss:[0.4860735, 0.4847274, 0.000673038]\n",
            "Batch:240\n",
            "d_loss:0.6383274346590042\n",
            "g_loss:[0.54366195, 0.5423195, 0.0006712365]\n",
            "Batch:241\n",
            "d_loss:0.6428270637989044\n",
            "g_loss:[0.5840228, 0.58291006, 0.00055637216]\n",
            "Batch:242\n",
            "d_loss:0.6185024082660675\n",
            "g_loss:[0.91769135, 0.9164191, 0.00063612586]\n",
            "Batch:243\n",
            "d_loss:0.6377099603414536\n",
            "g_loss:[0.60339165, 0.6022107, 0.00059045857]\n",
            "Batch:244\n",
            "d_loss:0.6198469251394272\n",
            "g_loss:[0.627258, 0.6260444, 0.00060680776]\n",
            "Batch:245\n",
            "d_loss:0.6884213238954544\n",
            "g_loss:[0.63850987, 0.63738674, 0.00056155206]\n",
            "Batch:246\n",
            "d_loss:0.6944389939308167\n",
            "g_loss:[0.5830595, 0.58224016, 0.0004096558]\n",
            "Batch:247\n",
            "d_loss:0.6140422523021698\n",
            "g_loss:[0.56653976, 0.56571066, 0.00041454073]\n",
            "Batch:248\n",
            "d_loss:0.5915865302085876\n",
            "g_loss:[0.613702, 0.6125941, 0.0005539321]\n",
            "Batch:249\n",
            "d_loss:0.5911473333835602\n",
            "g_loss:[0.5608118, 0.55978, 0.00051591336]\n",
            "Batch:250\n",
            "d_loss:0.5940409898757935\n",
            "g_loss:[0.5748835, 0.57361674, 0.00063339435]\n",
            "Batch:251\n",
            "d_loss:0.6031066924333572\n",
            "g_loss:[0.5635294, 0.5623745, 0.0005774568]\n",
            "Batch:252\n",
            "d_loss:0.6059756428003311\n",
            "g_loss:[0.51709527, 0.5157836, 0.00065583753]\n",
            "Batch:253\n",
            "d_loss:0.5972832441329956\n",
            "g_loss:[0.7098177, 0.7088559, 0.0004808973]\n",
            "Batch:254\n",
            "d_loss:0.6805718243122101\n",
            "g_loss:[0.8343037, 0.8331631, 0.00057028275]\n",
            "Batch:255\n",
            "d_loss:0.6333843767642975\n",
            "g_loss:[0.68453467, 0.68273467, 0.0008999896]\n",
            "Batch:256\n",
            "d_loss:0.6679785251617432\n",
            "g_loss:[2.135348, 2.133831, 0.0007585564]\n",
            "Batch:257\n",
            "d_loss:0.831315740942955\n",
            "g_loss:[1.0478908, 1.046301, 0.00079491624]\n",
            "Batch:258\n",
            "d_loss:0.6843615174293518\n",
            "g_loss:[0.86877966, 0.86727977, 0.00074995175]\n",
            "Batch:259\n",
            "d_loss:0.6938996911048889\n",
            "g_loss:[0.8199976, 0.8189177, 0.0005399617]\n",
            "Batch:260\n",
            "d_loss:0.6454781591892242\n",
            "g_loss:[0.9530437, 0.95205986, 0.00049192586]\n",
            "Batch:261\n",
            "d_loss:0.6598524898290634\n",
            "g_loss:[0.9682409, 0.9667425, 0.000749202]\n",
            "Batch:262\n",
            "d_loss:0.6187379211187363\n",
            "g_loss:[1.0323339, 1.0310721, 0.0006308467]\n",
            "Batch:263\n",
            "d_loss:0.6387728452682495\n",
            "g_loss:[0.97210765, 0.9709917, 0.00055799016]\n",
            "Batch:264\n",
            "d_loss:0.6348550319671631\n",
            "g_loss:[1.0116638, 1.0107331, 0.0004653242]\n",
            "Batch:265\n",
            "d_loss:0.6155861616134644\n",
            "g_loss:[1.0147734, 1.0139257, 0.00042384953]\n",
            "Batch:266\n",
            "d_loss:0.6154569089412689\n",
            "g_loss:[0.89274436, 0.8919337, 0.00040533827]\n",
            "Batch:267\n",
            "d_loss:0.6887513548135757\n",
            "g_loss:[0.87002003, 0.8689868, 0.0005166284]\n",
            "Batch:268\n",
            "d_loss:0.5973706394433975\n",
            "g_loss:[0.9439694, 0.9430003, 0.00048454132]\n",
            "Batch:269\n",
            "d_loss:0.7223947197198868\n",
            "g_loss:[0.7716655, 0.7707124, 0.00047655773]\n",
            "Batch:270\n",
            "d_loss:0.5931761413812637\n",
            "g_loss:[0.75585896, 0.7550658, 0.0003965706]\n",
            "Batch:271\n",
            "d_loss:0.589298814535141\n",
            "g_loss:[0.8489982, 0.8481269, 0.0004356574]\n",
            "Batch:272\n",
            "d_loss:0.615828201174736\n",
            "g_loss:[0.80735147, 0.8064645, 0.00044348667]\n",
            "Batch:273\n",
            "d_loss:0.5773375481367111\n",
            "g_loss:[0.74642086, 0.7455921, 0.000414381]\n",
            "Batch:274\n",
            "d_loss:0.6013917028903961\n",
            "g_loss:[0.748251, 0.74746054, 0.00039523732]\n",
            "Batch:275\n",
            "d_loss:0.5850063562393188\n",
            "g_loss:[0.78798425, 0.7870714, 0.00045643686]\n",
            "Batch:276\n",
            "d_loss:0.592435210943222\n",
            "g_loss:[0.70463765, 0.7035551, 0.0005412574]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHbFZmF23lD-"
      },
      "source": [
        "After the training of Stage 2 StackGAN, two new files will be created root directory, naming stage2_gen.h5 and stage2_dis.h5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J12ZLgTd38We"
      },
      "source": [
        "The generated image by Stage I StackGAN and Stage 2 StackGAN is stored in the results and results2 folder respecively and logs in the logs folder."
      ]
    }
  ]
}